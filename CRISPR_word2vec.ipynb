{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRISPR_word2vec",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgUWmNT67Y45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8afb90ad-f648-4524-e55e-c9bc25bf9223"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDNsiP7u2NrJ"
      },
      "source": [
        "import os\n",
        "os.chdir('gdrive/MyDrive/CRISPR_DeepHF')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us11dwZ52VaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7147356c-19d6-4b2e-f4d2-381416faf859"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deephf_data.xlsx  test.csv   Type1  Type3\n",
            "models\t\t  train.csv  Type2  word2vec_model_rnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM8NbDq92f6m"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buDzLLTd2ifX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "81d4e698-c3cd-45ac-8e0e-4f61124d3b45"
      },
      "source": [
        "file_name = \"deephf_data.xlsx\"\n",
        "df = pd.read_excel(file_name, sheet_name=\"Sheet1\")\n",
        "df.columns = df.iloc[0]\n",
        "df.drop(df.index[0], inplace=True)\n",
        "df['Wt_Efficiency'] = pd.to_numeric(df['Wt_Efficiency'])\n",
        "df['eSpCas 9_Efficiency'] = pd.to_numeric(df['eSpCas 9_Efficiency'])\n",
        "df['SpCas9-HF1_Efficiency'] = pd.to_numeric(df['SpCas9-HF1_Efficiency'])\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NaN</th>\n",
              "      <th>gRNA</th>\n",
              "      <th>gRNA_Seq</th>\n",
              "      <th>PAM</th>\n",
              "      <th>21mer</th>\n",
              "      <th>Wt_Efficiency</th>\n",
              "      <th>eSpCas 9_Efficiency</th>\n",
              "      <th>SpCas9-HF1_Efficiency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>gRNA-1</td>\n",
              "      <td>AAAAAAAAACTCCAAAACCC</td>\n",
              "      <td>TGG</td>\n",
              "      <td>AAAAAAAAACTCCAAAACCCT</td>\n",
              "      <td>0.168570</td>\n",
              "      <td>0.142063</td>\n",
              "      <td>0.093147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>gRNA-2</td>\n",
              "      <td>AAAAAACAACAAGAAGCACA</td>\n",
              "      <td>AGG</td>\n",
              "      <td>AAAAAACAACAAGAAGCACAA</td>\n",
              "      <td>0.099624</td>\n",
              "      <td>0.051901</td>\n",
              "      <td>0.064951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>gRNA-3</td>\n",
              "      <td>AAAAAACACAAGCAAGACCG</td>\n",
              "      <td>TGG</td>\n",
              "      <td>AAAAAACACAAGCAAGACCGT</td>\n",
              "      <td>0.247750</td>\n",
              "      <td>0.043573</td>\n",
              "      <td>0.061797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0  NaN    gRNA  ... eSpCas 9_Efficiency SpCas9-HF1_Efficiency\n",
              "1  NaN  gRNA-1  ...            0.142063              0.093147\n",
              "2  NaN  gRNA-2  ...            0.051901              0.064951\n",
              "3  NaN  gRNA-3  ...            0.043573              0.061797\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boWLOwhR2onT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "4c1d81b5-e6ed-4e6a-a412-5192f08a034a"
      },
      "source": [
        "df1 = df[['21mer','Wt_Efficiency','eSpCas 9_Efficiency','SpCas9-HF1_Efficiency']]\n",
        "df1.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>21mer</th>\n",
              "      <th>Wt_Efficiency</th>\n",
              "      <th>eSpCas 9_Efficiency</th>\n",
              "      <th>SpCas9-HF1_Efficiency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAAAAAAAACTCCAAAACCCT</td>\n",
              "      <td>0.168570</td>\n",
              "      <td>0.142063</td>\n",
              "      <td>0.093147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAAAAACAACAAGAAGCACAA</td>\n",
              "      <td>0.099624</td>\n",
              "      <td>0.051901</td>\n",
              "      <td>0.064951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAAAAACACAAGCAAGACCGT</td>\n",
              "      <td>0.247750</td>\n",
              "      <td>0.043573</td>\n",
              "      <td>0.061797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0                  21mer  ...  SpCas9-HF1_Efficiency\n",
              "1  AAAAAAAAACTCCAAAACCCT  ...               0.093147\n",
              "2  AAAAAACAACAAGAAGCACAA  ...               0.064951\n",
              "3  AAAAAACACAAGCAAGACCGT  ...               0.061797\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrj2bRdy2zHl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "c8b413a9-ba59-4dd5-b602-c6c401d5567a"
      },
      "source": [
        "df1 = df1.sample(frac=1).reset_index(drop=True)\n",
        "df1 = df1.dropna().reset_index(drop=True)\n",
        "df1.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>21mer</th>\n",
              "      <th>Wt_Efficiency</th>\n",
              "      <th>eSpCas 9_Efficiency</th>\n",
              "      <th>SpCas9-HF1_Efficiency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ACCAGACCTCGATACAGCATT</td>\n",
              "      <td>0.819149</td>\n",
              "      <td>0.303657</td>\n",
              "      <td>0.513349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GCAGCTCAGAAAGAATCCGTG</td>\n",
              "      <td>0.923457</td>\n",
              "      <td>0.668363</td>\n",
              "      <td>0.767245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GCGGACCCACGAGAGCGCGTC</td>\n",
              "      <td>0.851161</td>\n",
              "      <td>0.529361</td>\n",
              "      <td>0.636398</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0                  21mer  ...  SpCas9-HF1_Efficiency\n",
              "0  ACCAGACCTCGATACAGCATT  ...               0.513349\n",
              "1  GCAGCTCAGAAAGAATCCGTG  ...               0.767245\n",
              "2  GCGGACCCACGAGAGCGCGTC  ...               0.636398\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLZTdQin_xvH"
      },
      "source": [
        "**Individual**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeCsZxKA_pFh"
      },
      "source": [
        "cas_name = 'Wt_Efficiency'\n",
        "\n",
        "# df1 = df[['21mer','Wt_Efficiency','eSpCas 9_Efficiency','SpCas9-HF1_Efficiency']]\n",
        "df1 = df[['21mer', cas_name]]\n",
        "\n",
        "df1 = df1.sample(frac=1).reset_index(drop=True)\n",
        "#df1 = df1.dropna().reset_index(drop=True)\n",
        "\n",
        "df1 = df1[df1[cas_name].notna()]\n",
        "\n",
        "print(df1.shape)\n",
        "df1.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcJPK3cl24Th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28cc7579-24c8-49cf-e80d-53f4eec939dd"
      },
      "source": [
        "print(\"Full dataset size after dropping null: \", df1.shape)\n",
        "train_set_size = int(df1.shape[0]*0.85) # 85% as training set, like deephf paper\n",
        "train_set = df1.iloc[:train_set_size].copy().reset_index(drop=True)\n",
        "test_set = df1.iloc[train_set_size:].copy().reset_index(drop=True)\n",
        "print(\"Train set size: \", train_set.shape)\n",
        "print(\"Test set size: \", test_set.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Full dataset size after dropping null:  (53937, 4)\n",
            "Train set size:  (45846, 4)\n",
            "Test set size:  (8091, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryTCLeCu28sw"
      },
      "source": [
        "train_set.to_csv(\"train.csv\",index=False)\n",
        "test_set.to_csv(\"test.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6yksoEu3G0S"
      },
      "source": [
        "**Load CSV from Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNlbjPsM3TcR"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b1JInE-3WkP"
      },
      "source": [
        "**K-mer split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me9oZWj8jZIA"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJA5RZBKjanj"
      },
      "source": [
        "def Gen_Words(sequence,kmer_len,s):\n",
        "    \n",
        "    kmer_list=[]\n",
        "    for j in range(0,(len(sequence)-kmer_len)+1,s):\n",
        "\n",
        "          kmer_list.append(sequence[j:j+kmer_len])\n",
        "\n",
        "\n",
        "    return kmer_list\n",
        "\n",
        "\n",
        "def word_generation_all_sequences(seq_set,kmer_len,stride):\n",
        "    seq_set_enc = []\n",
        "    for i in tqdm(range(len(seq_set))):\n",
        "        seq_set_enc.append(Gen_Words(seq_set[i],kmer_len,stride))\n",
        "    #seq_set_enc = np.array(seq_set_enc)\n",
        "    return seq_set_enc\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XBiFiZiqQMG"
      },
      "source": [
        "#split all sequences to kmers\n",
        "def splitkmer(data_df):\n",
        "  kmer_len = 3\n",
        "  stride = 2\n",
        "  sequence_words = word_generation_all_sequences(data_df['21mer'],kmer_len,stride)\n",
        "  #print(sequence_words)\n",
        "  #print(len(sequence_words))\n",
        "  return sequence_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuAXRC8o3Drp"
      },
      "source": [
        "**Word2vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ldajeKCrQMC"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "def return_vectors_word2vec(data_df):\n",
        "  sentences_constructed = splitkmer(data_df)\n",
        "  model_ted = Word2Vec(sentences=sentences_constructed, size = 32, window=5, min_count=5, workers=4, sg=1)\n",
        "\n",
        "  vector_list = []\n",
        "  for sentence in sentences_constructed:\n",
        "    vector = []\n",
        "    for word in sentence:\n",
        "      vector.append(model_ted.wv[word])\n",
        "    vector_list.append(vector)\n",
        "  vector_list = np.array(vector_list)\n",
        "  \n",
        "  return model_ted, vector_list\n",
        "def return_vectors_only(data_df,model_word2vec):\n",
        "  sentences_constructed = splitkmer(data_df)\n",
        "  model_ted = model_word2vec\n",
        "  vector_list = []\n",
        "  for sentence in sentences_constructed:\n",
        "    vector = []\n",
        "    for word in sentence:\n",
        "      vector.append(model_ted.wv[word])\n",
        "    vector_list.append(vector)\n",
        "  vector_list = np.array(vector_list)\n",
        "  \n",
        "  return vector_list\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr36fxDpqz76",
        "outputId": "d650a20c-91c6-4091-90b2-2dfc0209b4d2"
      },
      "source": [
        "#test a random kmer\n",
        "#model_testing = return_vectors_word2vec(train_df,1)\n",
        "#model_testing.wv.most_similar('ATG')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 45846/45846 [00:00<00:00, 144111.21it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AAG', 0.922577440738678),\n",
              " ('AGG', 0.8956265449523926),\n",
              " ('ACG', 0.8757708072662354),\n",
              " ('TTG', 0.6343978643417358),\n",
              " ('AAT', 0.6218340992927551),\n",
              " ('GTG', 0.6175557374954224),\n",
              " ('TAG', 0.6112311482429504),\n",
              " ('ATA', 0.6071228384971619),\n",
              " ('GAG', 0.5990007519721985),\n",
              " ('ATC', 0.5986645817756653)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_68OPjfHwad2"
      },
      "source": [
        "**CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V81Y7-G9whRz",
        "outputId": "651fddd1-8b47-4c0e-85fc-cfd12af4bb05"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D, Conv1D\n",
        "from keras.layers.convolutional import MaxPooling2D, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "from scipy import stats\n",
        "\n",
        "def get_model_name(k):\n",
        "    return 'model_'+str(k)+'.h5'\n",
        "\n",
        "\n",
        "def create_new_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(10,32)))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    return model\n",
        "test_model = create_new_model()\n",
        "print(test_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_6 (Conv1D)            (None, 8, 64)             6208      \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 6, 64)             12352     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 64)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 3, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 192)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               19300     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 37,961\n",
            "Trainable params: 37,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxHblm8vw0DB",
        "outputId": "604bbf50-9b28-409f-8e06-e932aa74389d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "\n",
        "target_type = 1\n",
        "target_col = ''\n",
        "if target_type == 1:\n",
        "  target_col = 'Wt_Efficiency'\n",
        "elif target_type == 2:\n",
        "  target_col = 'eSpCas 9_Efficiency'\n",
        "else:\n",
        "  target_col = 'SpCas9-HF1_Efficiency'\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "#word2vec_cnn_model, X = return_vectors_word2vec(train_data)\n",
        "word2vec_cnn_model = Word2Vec.load('word2vec_model_rnn')\n",
        "X = return_vectors_only(train_data,word2vec_cnn_model)\n",
        "Y = train_data[[target_col]]\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 45846/45846 [00:00<00:00, 144308.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(45846, 10, 32)\n",
            "(45846, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjIqjS1t2sMT",
        "outputId": "b7efe953-cd7c-4f15-fc2e-3339c7872f74"
      },
      "source": [
        "kf = KFold(n_splits = 5, shuffle=True, random_state=0)\n",
        "\n",
        "\n",
        "VALIDATION_CORR = []\n",
        "VALIDATION_LOSS = []\n",
        "save_dir_primary = 'Type' + str(target_type) + '/'\n",
        "save_dir = save_dir_primary + 'cnn/'\n",
        "'''\n",
        "try:\n",
        "    os.mkdir(save_dir_primary)\n",
        "except:\n",
        "    pass\n",
        "'''\n",
        "os.chdir(save_dir_primary)\n",
        "\n",
        "try:\n",
        "    os.mkdir('cnn/')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "os.chdir('cnn/')\n",
        "save_dir_2 = 'saved_models/'\n",
        "try:\n",
        "    os.mkdir(save_dir_2)\n",
        "except:\n",
        "    pass\n",
        "os.chdir('..')\n",
        "os.chdir('..')\n",
        "\n",
        "fold_var = 1\n",
        "\n",
        "for train_index, val_index in kf.split(X,Y):\n",
        "    X_train = X[train_index]\n",
        "    Y_train = Y.iloc[train_index]\n",
        "    X_val = X[val_index]\n",
        "    Y_val = Y.iloc[val_index]\n",
        "\n",
        "    #print(X_train.shape)\n",
        "    #print(Y_train.shape)\n",
        "    #print(X_val.shape)\n",
        "    #print(Y_val.shape)\n",
        "    \n",
        "    # CREATE NEW MODEL\n",
        "    model = create_new_model()\n",
        "    # COMPILE NEW MODEL\n",
        "    model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "    \n",
        "    # CREATE CALLBACKS\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+save_dir_2+get_model_name(fold_var), \n",
        "                            monitor='val_loss', verbose=1, \n",
        "                            save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint]\n",
        "    # There can be other callbacks, but just showing one because it involves the model name\n",
        "    # This saves the best model\n",
        "    # FIT THE MODEL\n",
        "    history = model.fit(X_train,Y_train,\n",
        "                epochs=50,\n",
        "                batch_size=64,\n",
        "                callbacks=callbacks_list,\n",
        "                validation_data=(X_val, Y_val))\n",
        "    #PLOT HISTORY\n",
        "    #       :\n",
        "    #       :\n",
        "    \n",
        "    # LOAD BEST MODEL to evaluate the performance of the model\n",
        "    model.load_weights(save_dir + \"saved_models/model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "    results = model.evaluate(X_val, Y_val)\n",
        "    results = dict(zip(model.metrics_names,results))\n",
        "    \n",
        "    Y_pred = model.predict(X_val)\n",
        "    Y_val = np.array(Y_val).reshape(len(Y_val),1)\n",
        "    spearmancorr = (stats.spearmanr(Y_pred,Y_val))\n",
        "\n",
        "    VALIDATION_CORR.append(spearmancorr)\n",
        "    VALIDATION_LOSS.append(results['loss'])\n",
        "    \n",
        "    tf.keras.backend.clear_session()\n",
        "    \n",
        "    fold_var += 1\n",
        "\n",
        "print(VALIDATION_LOSS)\n",
        "print(np.mean(VALIDATION_LOSS))\n",
        "print(VALIDATION_CORR)\n",
        "print(np.mean(VALIDATION_CORR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0319 - mean_squared_error: 0.0319\n",
            "Epoch 00001: val_loss improved from inf to 0.02628, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0263 - val_mean_squared_error: 0.0263\n",
            "Epoch 2/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0257 - mean_squared_error: 0.0257\n",
            "Epoch 00002: val_loss improved from 0.02628 to 0.02153, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0227 - mean_squared_error: 0.0227\n",
            "Epoch 00003: val_loss improved from 0.02153 to 0.01982, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
            "Epoch 4/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0207\n",
            "Epoch 00004: val_loss improved from 0.01982 to 0.01907, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0191 - val_mean_squared_error: 0.0191\n",
            "Epoch 5/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0197 - mean_squared_error: 0.0197\n",
            "Epoch 00005: val_loss improved from 0.01907 to 0.01760, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
            "Epoch 6/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0189\n",
            "Epoch 00006: val_loss improved from 0.01760 to 0.01696, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
            "Epoch 7/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0181\n",
            "Epoch 00007: val_loss improved from 0.01696 to 0.01663, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0176 - mean_squared_error: 0.0176\n",
            "Epoch 00008: val_loss improved from 0.01663 to 0.01625, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
            "Epoch 9/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0173\n",
            "Epoch 00009: val_loss improved from 0.01625 to 0.01587, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 10/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0169\n",
            "Epoch 00010: val_loss did not improve from 0.01587\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
            "Epoch 11/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0165\n",
            "Epoch 00011: val_loss did not improve from 0.01587\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
            "Epoch 12/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0163\n",
            "Epoch 00012: val_loss improved from 0.01587 to 0.01548, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
            "Epoch 13/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0160\n",
            "Epoch 00013: val_loss improved from 0.01548 to 0.01535, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 14/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0159\n",
            "Epoch 00014: val_loss did not improve from 0.01535\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
            "Epoch 15/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0156\n",
            "Epoch 00015: val_loss improved from 0.01535 to 0.01488, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 16/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0156\n",
            "Epoch 00016: val_loss did not improve from 0.01488\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
            "Epoch 17/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0154\n",
            "Epoch 00017: val_loss did not improve from 0.01488\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 18/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0153\n",
            "Epoch 00018: val_loss improved from 0.01488 to 0.01473, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 19/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0151\n",
            "Epoch 00019: val_loss did not improve from 0.01473\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 20/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0150\n",
            "Epoch 00020: val_loss improved from 0.01473 to 0.01466, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 21/50\n",
            "564/574 [============================>.] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0149\n",
            "Epoch 00021: val_loss did not improve from 0.01466\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 22/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 00022: val_loss did not improve from 0.01466\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 23/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 00023: val_loss improved from 0.01466 to 0.01448, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 24/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0145\n",
            "Epoch 00024: val_loss did not improve from 0.01448\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 25/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 00025: val_loss did not improve from 0.01448\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 00026: val_loss did not improve from 0.01448\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 27/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 00027: val_loss did not improve from 0.01448\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 28/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 00028: val_loss did not improve from 0.01448\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 29/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 00029: val_loss did not improve from 0.01448\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 30/50\n",
            "564/574 [============================>.] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 00030: val_loss did not improve from 0.01448\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 31/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 00031: val_loss did not improve from 0.01448\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 32/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138\n",
            "Epoch 00032: val_loss improved from 0.01448 to 0.01447, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 33/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00033: val_loss did not improve from 0.01447\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138\n",
            "Epoch 00034: val_loss did not improve from 0.01447\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 35/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00035: val_loss improved from 0.01447 to 0.01445, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 36/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 00036: val_loss did not improve from 0.01445\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 37/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00037: val_loss did not improve from 0.01445\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 38/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 00038: val_loss improved from 0.01445 to 0.01425, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "Epoch 39/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 00039: val_loss did not improve from 0.01425\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 40/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00040: val_loss did not improve from 0.01425\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00041: val_loss did not improve from 0.01425\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "Epoch 42/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00042: val_loss improved from 0.01425 to 0.01411, saving model to Type2/cnn/saved_models/model_1.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
            "Epoch 43/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00043: val_loss did not improve from 0.01411\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "Epoch 44/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 00044: val_loss did not improve from 0.01411\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 45/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00045: val_loss did not improve from 0.01411\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "Epoch 46/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00046: val_loss did not improve from 0.01411\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 47/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 00047: val_loss did not improve from 0.01411\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 48/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00048: val_loss did not improve from 0.01411\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 49/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00049: val_loss did not improve from 0.01411\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "Epoch 50/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 00050: val_loss did not improve from 0.01411\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "287/287 [==============================] - 0s 2ms/step - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 1/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0331 - mean_squared_error: 0.0331\n",
            "Epoch 00001: val_loss improved from inf to 0.02902, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0290 - val_mean_squared_error: 0.0290\n",
            "Epoch 2/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0262 - mean_squared_error: 0.0262\n",
            "Epoch 00002: val_loss improved from 0.02902 to 0.02381, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.0238 - val_mean_squared_error: 0.0238\n",
            "Epoch 3/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0230 - mean_squared_error: 0.0230\n",
            "Epoch 00003: val_loss improved from 0.02381 to 0.02074, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
            "Epoch 4/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0214 - mean_squared_error: 0.0214\n",
            "Epoch 00004: val_loss improved from 0.02074 to 0.01936, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
            "Epoch 5/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0199\n",
            "Epoch 00005: val_loss did not improve from 0.01936\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
            "Epoch 6/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.0190\n",
            "Epoch 00006: val_loss improved from 0.01936 to 0.01763, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
            "Epoch 7/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0183\n",
            "Epoch 00007: val_loss improved from 0.01763 to 0.01732, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
            "Epoch 8/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0177\n",
            "Epoch 00008: val_loss did not improve from 0.01732\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
            "Epoch 9/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0173\n",
            "Epoch 00009: val_loss improved from 0.01732 to 0.01633, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
            "Epoch 10/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0171\n",
            "Epoch 00010: val_loss improved from 0.01633 to 0.01605, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
            "Epoch 11/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0166\n",
            "Epoch 00011: val_loss did not improve from 0.01605\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
            "Epoch 12/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0163\n",
            "Epoch 00012: val_loss did not improve from 0.01605\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
            "Epoch 13/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0161\n",
            "Epoch 00013: val_loss improved from 0.01605 to 0.01574, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 14/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0159\n",
            "Epoch 00014: val_loss did not improve from 0.01574\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0158\n",
            "Epoch 00015: val_loss improved from 0.01574 to 0.01574, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 16/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0155\n",
            "Epoch 00016: val_loss did not improve from 0.01574\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0154\n",
            "Epoch 00017: val_loss did not improve from 0.01574\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0152\n",
            "Epoch 00018: val_loss did not improve from 0.01574\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
            "Epoch 19/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0151\n",
            "Epoch 00019: val_loss improved from 0.01574 to 0.01563, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "Epoch 20/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 00020: val_loss did not improve from 0.01563\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
            "Epoch 21/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 00021: val_loss did not improve from 0.01563\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
            "Epoch 22/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0146\n",
            "Epoch 00022: val_loss did not improve from 0.01563\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
            "Epoch 23/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0146\n",
            "Epoch 00023: val_loss did not improve from 0.01563\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
            "Epoch 24/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 00024: val_loss improved from 0.01563 to 0.01522, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 25/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 00025: val_loss did not improve from 0.01522\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 26/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 00026: val_loss did not improve from 0.01522\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 27/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 00027: val_loss improved from 0.01522 to 0.01507, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 28/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 00028: val_loss did not improve from 0.01507\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 29/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 00029: val_loss did not improve from 0.01507\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "Epoch 30/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 00030: val_loss improved from 0.01507 to 0.01503, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 31/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00031: val_loss did not improve from 0.01503\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "Epoch 32/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138\n",
            "Epoch 00032: val_loss improved from 0.01503 to 0.01489, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 33/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 00033: val_loss did not improve from 0.01489\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 34/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 00034: val_loss improved from 0.01489 to 0.01471, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 35/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 00035: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 36/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 00036: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 37/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00037: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 38/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00038: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 39/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00039: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 40/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00040: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 41/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 00041: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00042: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "Epoch 43/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00043: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 44/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00044: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 45/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00045: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 46/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00046: val_loss did not improve from 0.01471\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 47/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 00047: val_loss improved from 0.01471 to 0.01465, saving model to Type2/cnn/saved_models/model_2.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 48/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 00048: val_loss did not improve from 0.01465\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 49/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 00049: val_loss did not improve from 0.01465\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 50/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00050: val_loss did not improve from 0.01465\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "287/287 [==============================] - 0s 2ms/step - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 1/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0320 - mean_squared_error: 0.0320\n",
            "Epoch 00001: val_loss improved from inf to 0.02656, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0266 - val_mean_squared_error: 0.0266\n",
            "Epoch 2/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0257 - mean_squared_error: 0.0257\n",
            "Epoch 00002: val_loss improved from 0.02656 to 0.02255, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0226 - val_mean_squared_error: 0.0226\n",
            "Epoch 3/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0224\n",
            "Epoch 00003: val_loss improved from 0.02255 to 0.02096, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
            "Epoch 4/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0207\n",
            "Epoch 00004: val_loss improved from 0.02096 to 0.01963, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
            "Epoch 5/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0193\n",
            "Epoch 00005: val_loss improved from 0.01963 to 0.01769, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
            "Epoch 6/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.0183\n",
            "Epoch 00006: val_loss did not improve from 0.01769\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
            "Epoch 7/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0177\n",
            "Epoch 00007: val_loss improved from 0.01769 to 0.01687, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
            "Epoch 8/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0173\n",
            "Epoch 00008: val_loss improved from 0.01687 to 0.01625, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
            "Epoch 9/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0170\n",
            "Epoch 00009: val_loss did not improve from 0.01625\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
            "Epoch 10/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0165\n",
            "Epoch 00010: val_loss improved from 0.01625 to 0.01582, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
            "Epoch 11/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0162\n",
            "Epoch 00011: val_loss did not improve from 0.01582\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "Epoch 12/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0160\n",
            "Epoch 00012: val_loss did not improve from 0.01582\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 13/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0159\n",
            "Epoch 00013: val_loss improved from 0.01582 to 0.01544, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 14/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0155\n",
            "Epoch 00014: val_loss did not improve from 0.01544\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
            "Epoch 15/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0154\n",
            "Epoch 00015: val_loss did not improve from 0.01544\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 16/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0153\n",
            "Epoch 00016: val_loss did not improve from 0.01544\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 17/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0152\n",
            "Epoch 00017: val_loss improved from 0.01544 to 0.01514, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 18/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0151\n",
            "Epoch 00018: val_loss did not improve from 0.01514\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
            "Epoch 19/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0151\n",
            "Epoch 00019: val_loss did not improve from 0.01514\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 20/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0146\n",
            "Epoch 00020: val_loss did not improve from 0.01514\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 21/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 00021: val_loss did not improve from 0.01514\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 22/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 00022: val_loss did not improve from 0.01514\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "Epoch 23/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 00023: val_loss did not improve from 0.01514\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 24/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 00024: val_loss improved from 0.01514 to 0.01463, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 25/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 00025: val_loss did not improve from 0.01463\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 26/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 00026: val_loss did not improve from 0.01463\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 27/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 00027: val_loss did not improve from 0.01463\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 28/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 00028: val_loss did not improve from 0.01463\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 29/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 00029: val_loss did not improve from 0.01463\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 30/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138\n",
            "Epoch 00030: val_loss did not improve from 0.01463\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 31/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00031: val_loss did not improve from 0.01463\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 32/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00032: val_loss did not improve from 0.01463\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 33/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00033: val_loss improved from 0.01463 to 0.01442, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "Epoch 34/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 00034: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 35/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 00035: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 00036: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 37/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 00037: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 38/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00038: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 39/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00039: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 40/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00040: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 41/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00041: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 42/50\n",
            "564/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00042: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 43/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00043: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00044: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 45/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00045: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 3s 6ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 46/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00046: val_loss did not improve from 0.01442\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 47/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00047: val_loss improved from 0.01442 to 0.01433, saving model to Type2/cnn/saved_models/model_3.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "Epoch 48/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 00048: val_loss did not improve from 0.01433\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00049: val_loss did not improve from 0.01433\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 50/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 00050: val_loss did not improve from 0.01433\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "287/287 [==============================] - 0s 2ms/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 1/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0319 - mean_squared_error: 0.0319\n",
            "Epoch 00001: val_loss improved from inf to 0.03259, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0318 - mean_squared_error: 0.0318 - val_loss: 0.0326 - val_mean_squared_error: 0.0326\n",
            "Epoch 2/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0255 - mean_squared_error: 0.0255\n",
            "Epoch 00002: val_loss improved from 0.03259 to 0.02315, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
            "Epoch 3/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0223 - mean_squared_error: 0.0223\n",
            "Epoch 00003: val_loss improved from 0.02315 to 0.01985, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
            "Epoch 4/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0204 - mean_squared_error: 0.0204\n",
            "Epoch 00004: val_loss improved from 0.01985 to 0.01876, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
            "Epoch 5/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0192\n",
            "Epoch 00005: val_loss improved from 0.01876 to 0.01805, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
            "Epoch 6/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.0186\n",
            "Epoch 00006: val_loss did not improve from 0.01805\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
            "Epoch 7/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0177\n",
            "Epoch 00007: val_loss improved from 0.01805 to 0.01706, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
            "Epoch 8/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0172\n",
            "Epoch 00008: val_loss improved from 0.01706 to 0.01642, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "Epoch 9/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0169\n",
            "Epoch 00009: val_loss did not improve from 0.01642\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
            "Epoch 10/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0166\n",
            "Epoch 00010: val_loss improved from 0.01642 to 0.01635, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "Epoch 11/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0163\n",
            "Epoch 00011: val_loss did not improve from 0.01635\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
            "Epoch 12/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0160\n",
            "Epoch 00012: val_loss improved from 0.01635 to 0.01622, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
            "Epoch 13/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0158\n",
            "Epoch 00013: val_loss improved from 0.01622 to 0.01576, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
            "Epoch 14/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0156\n",
            "Epoch 00014: val_loss did not improve from 0.01576\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
            "Epoch 15/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0154\n",
            "Epoch 00015: val_loss did not improve from 0.01576\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
            "Epoch 16/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0151\n",
            "Epoch 00016: val_loss did not improve from 0.01576\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
            "Epoch 17/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0151 - mean_squared_error: 0.0151\n",
            "Epoch 00017: val_loss improved from 0.01576 to 0.01524, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 18/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0149\n",
            "Epoch 00018: val_loss did not improve from 0.01524\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 19/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 00019: val_loss did not improve from 0.01524\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "Epoch 20/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 00020: val_loss did not improve from 0.01524\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 21/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 00021: val_loss did not improve from 0.01524\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 22/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 00022: val_loss improved from 0.01524 to 0.01492, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 23/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 00023: val_loss improved from 0.01492 to 0.01468, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 24/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 00024: val_loss did not improve from 0.01468\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 00025: val_loss did not improve from 0.01468\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 26/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 00026: val_loss did not improve from 0.01468\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 27/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 00027: val_loss did not improve from 0.01468\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 28/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 00028: val_loss did not improve from 0.01468\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 29/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138\n",
            "Epoch 00029: val_loss did not improve from 0.01468\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 30/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00030: val_loss improved from 0.01468 to 0.01467, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 31/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 00031: val_loss did not improve from 0.01467\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 32/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 00032: val_loss did not improve from 0.01467\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 33/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 00033: val_loss improved from 0.01467 to 0.01450, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 34/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 00034: val_loss did not improve from 0.01450\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 35/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00035: val_loss did not improve from 0.01450\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 36/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00036: val_loss did not improve from 0.01450\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
            "Epoch 37/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00037: val_loss did not improve from 0.01450\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 38/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00038: val_loss did not improve from 0.01450\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 39/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 00039: val_loss did not improve from 0.01450\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 40/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00040: val_loss did not improve from 0.01450\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 41/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00041: val_loss improved from 0.01450 to 0.01432, saving model to Type2/cnn/saved_models/model_4.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "Epoch 42/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00042: val_loss did not improve from 0.01432\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 43/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00043: val_loss did not improve from 0.01432\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 44/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 00044: val_loss did not improve from 0.01432\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "Epoch 45/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 00045: val_loss did not improve from 0.01432\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 46/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00046: val_loss did not improve from 0.01432\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 47/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 00047: val_loss did not improve from 0.01432\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 48/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 00048: val_loss did not improve from 0.01432\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 49/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 00049: val_loss did not improve from 0.01432\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 50/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 00050: val_loss did not improve from 0.01432\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 1/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0327 - mean_squared_error: 0.0327\n",
            "Epoch 00001: val_loss improved from inf to 0.02616, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0262 - val_mean_squared_error: 0.0262\n",
            "Epoch 2/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0257 - mean_squared_error: 0.0257\n",
            "Epoch 00002: val_loss improved from 0.02616 to 0.02324, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
            "Epoch 3/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0227 - mean_squared_error: 0.0227\n",
            "Epoch 00003: val_loss improved from 0.02324 to 0.01937, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
            "Epoch 4/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0207\n",
            "Epoch 00004: val_loss improved from 0.01937 to 0.01835, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
            "Epoch 5/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.0194\n",
            "Epoch 00005: val_loss improved from 0.01835 to 0.01793, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
            "Epoch 6/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.0186\n",
            "Epoch 00006: val_loss improved from 0.01793 to 0.01758, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
            "Epoch 7/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0179 - mean_squared_error: 0.0179\n",
            "Epoch 00007: val_loss improved from 0.01758 to 0.01674, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
            "Epoch 8/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0174\n",
            "Epoch 00008: val_loss improved from 0.01674 to 0.01666, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
            "Epoch 9/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0171\n",
            "Epoch 00009: val_loss did not improve from 0.01666\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
            "Epoch 10/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0166\n",
            "Epoch 00010: val_loss improved from 0.01666 to 0.01584, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
            "Epoch 11/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0164\n",
            "Epoch 00011: val_loss did not improve from 0.01584\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
            "Epoch 12/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0162\n",
            "Epoch 00012: val_loss did not improve from 0.01584\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
            "Epoch 13/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0158 - mean_squared_error: 0.0158\n",
            "Epoch 00013: val_loss did not improve from 0.01584\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
            "Epoch 14/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0156\n",
            "Epoch 00014: val_loss improved from 0.01584 to 0.01524, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 15/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0155\n",
            "Epoch 00015: val_loss did not improve from 0.01524\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 16/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0153\n",
            "Epoch 00016: val_loss improved from 0.01524 to 0.01523, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0152 - mean_squared_error: 0.0152\n",
            "Epoch 00017: val_loss did not improve from 0.01523\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
            "Epoch 18/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0150\n",
            "Epoch 00018: val_loss did not improve from 0.01523\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 19/50\n",
            "565/574 [============================>.] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 00019: val_loss improved from 0.01523 to 0.01496, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 20/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 00020: val_loss did not improve from 0.01496\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 21/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0145\n",
            "Epoch 00021: val_loss did not improve from 0.01496\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 22/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 00022: val_loss did not improve from 0.01496\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 23/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 00023: val_loss improved from 0.01496 to 0.01464, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 24/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 00024: val_loss did not improve from 0.01464\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 25/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 00025: val_loss did not improve from 0.01464\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
            "Epoch 26/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0140 - mean_squared_error: 0.0140\n",
            "Epoch 00026: val_loss did not improve from 0.01464\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "Epoch 27/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 00027: val_loss improved from 0.01464 to 0.01455, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 28/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138\n",
            "Epoch 00028: val_loss did not improve from 0.01455\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 29/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0139\n",
            "Epoch 00029: val_loss did not improve from 0.01455\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00030: val_loss did not improve from 0.01455\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 31/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 00031: val_loss did not improve from 0.01455\n",
            "574/574 [==============================] - 4s 6ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 32/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
            "Epoch 00032: val_loss did not improve from 0.01455\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 33/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 00033: val_loss did not improve from 0.01455\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 34/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 00034: val_loss did not improve from 0.01455\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 35/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00035: val_loss did not improve from 0.01455\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00036: val_loss did not improve from 0.01455\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 37/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 00037: val_loss improved from 0.01455 to 0.01449, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 38/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00038: val_loss did not improve from 0.01449\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 39/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00039: val_loss did not improve from 0.01449\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00040: val_loss did not improve from 0.01449\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 41/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 00041: val_loss did not improve from 0.01449\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 42/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00042: val_loss did not improve from 0.01449\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 43/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00043: val_loss did not improve from 0.01449\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 44/50\n",
            "568/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00044: val_loss did not improve from 0.01449\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 45/50\n",
            "569/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00045: val_loss did not improve from 0.01449\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 46/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 00046: val_loss improved from 0.01449 to 0.01446, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 47/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 00047: val_loss did not improve from 0.01446\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 48/50\n",
            "566/574 [============================>.] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 00048: val_loss improved from 0.01446 to 0.01440, saving model to Type2/cnn/saved_models/model_5.h5\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "Epoch 49/50\n",
            "567/574 [============================>.] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 00049: val_loss did not improve from 0.01440\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 50/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 00050: val_loss did not improve from 0.01440\n",
            "574/574 [==============================] - 4s 7ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "[0.014108186587691307, 0.014652973972260952, 0.014333927072584629, 0.014323313720524311, 0.01439795270562172]\n",
            "0.014363270811736583\n",
            "[SpearmanrResult(correlation=0.7686586054457004, pvalue=0.0), SpearmanrResult(correlation=0.7722603076247583, pvalue=0.0), SpearmanrResult(correlation=0.7738974415116898, pvalue=0.0), SpearmanrResult(correlation=0.7760884483823901, pvalue=0.0), SpearmanrResult(correlation=0.7617988348211773, pvalue=0.0)]\n",
            "0.3852703637785716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "Ior2-c1Lp-Gc",
        "outputId": "3da6de0d-63ea-4e01-f92b-c96824f7487e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "save_dir_primary = 'Type' + str(target_type) + '/'\n",
        "save_dir = save_dir_primary + 'cnn/'\n",
        "model = create_new_model()\n",
        "    # COMPILE NEW MODEL\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "    \n",
        "\n",
        "fold_var = 3\n",
        "model.load_weights(save_dir + \"saved_models/model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "\n",
        "\n",
        "X_ = return_vectors_only(test_data,word2vec_cnn_model)\n",
        "\n",
        "Y_ = test_data[[target_col]] # Y dataframe with single column; use iloc\n",
        "\n",
        "Y_pred = model.predict(X_)\n",
        "Y_ = np.array(Y_).reshape(len(Y_),1)\n",
        "spearmancorr = (stats.spearmanr(Y_pred,Y_))\n",
        "\n",
        "print(spearmancorr)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(Y_, Y_pred, s=0.1)\n",
        "plt.ylim((0,1))\n",
        "plt.xlim((0,1))\n",
        "savefigstring = 'cnn' + str(target_type) + '.png'\n",
        "plt.savefig(savefigstring)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8091/8091 [00:00<00:00, 137771.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SpearmanrResult(correlation=0.7930515235254962, pvalue=0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAHWCAYAAABXF6HSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9f1xUdb74/xwYBmQARUDEUkJHJEQJcTNrvbv0saK9blrXa/5qLbdsb1nLtvej7bb27Ubthnc/XbbUblTu2lpR6+5q626YPdbddY0sFVHCCUcQTRAB+TUDzPDjfP8Y36czhxkYEBTt/Xw8eOjMOed93ud9zpzX+/XzbVAUBYlEIpFIJMOXgMvdAYlEIpFIJL0jhbVEIpFIJMMcKawlEolEIhnmSGEtkUgkEskwRwpriUQikUiGOVJYSyQSiUQyzOlTWBsMhs0Gg+GcwWAo8bHdYDAYXjIYDDaDwXDEYDDMGPxuSiQSiUTy9cUfzfo3QGYv2+8EJl/4WwW8cvHdkkgkEolEIuhTWCuK8g/gfC+7zAfeVNx8AowyGAxxg9VBiUQikUi+7gyGz/oa4LTm85cXvpNIJBKJRDIIGC/lyQwGwyrcpnLMZnN6UlLSpTy9RCKRSCSXjYMHD9YpihIzkGMHQ1ifAcZrPl974bseKIqSB+QBzJw5Uzlw4MAgnF4ikUgkkuGPwWCoHOixg2EGfx/43oWo8JuAJkVRqgehXYlEIpFIJPihWRsMhneAbwPRBoPhS+D/A4IAFEX5X+AvwHcAG9AKPDBUnZVIJBKJ5OtIn8JaUZQlfWxXgEcHrUcSiUQikQwDalucxIQHX+5uALKCmUQikUgkPahtcbJuewm1Lc7L3RVACmuJRCKRSHoQEx5M9oIUqVlLJBKJRDKcGS6CGqSwlkgkEsnXEH/N29IMLpFIJBLJZcBff/Rw8lsb3MHclx5ZFEUikUgklwt/I731+11MhLjBYDioKMrMgRwrNWuJRCKRfO3wV+DqBfXl0rSlsJZIJBKJxA8uZ4S4FNYSiUQikfjJ5YoQl8JaIpFIJJJhjhTWEolEIpH0gT9+6qH0ZUthLZFIJBJJL/gTWDbUwWcydUsikUgkkj7wJ2Wrr31k6pZEIpFIJH4wUM3Xn8CyoQw+k8JaIpFIJFcs/RG+F2OqvtzlSaWwlkgkEslFcbnKceqFb1/9GGie9HAoTyqFtUQikUgGzGAKqP62oRW+/vZD7OvtvL6+91fID2XRFCmsJRKJRDJgBktADVToC+HbVz+0AnnNtmJqW5zq37rtJVirm9Xziz+xX3/7MxRIYS2RSCSSi0JfP3ugbVysibo3Qa2fCNTb3d/V251kL0ghKS6C7AUpAOr33o731+Q+2MjULYlEIpEMCkKoCaF3qUpz+ptWBZ5mcFtNC1sKK8maO5mkuIge+9bbner34rt120vImjuZ3I+O93tyIVO3JBKJRHLZEdox4HdA1kDQa7e9CUytNiz6VG93m7jz9pazYnY8OQXWHn1Zs63Y4/uY8GD1+pLiIsiaO/mS1gmXwloikUgkA8KbsNUKtb6EaH991N58zNbq5l73X7OtmDXbigHUiUTuR8dZm5nE+oWpRJpNuDq7e1zD+oWprF+Y6rPdnAIrhbY6n9sHGymsJRKJRNJvfAlbf7RdsV0Iz/6cD/DQbnM/Ou7Tj1xvd6pCWZxTqx0D5BRYcXV2U293ehwfEx6s+rXF92KCUG934nB28tg7RT0E9lClb0mftUQikUgGhN5XrPVZ+2Mi7s/+3iYBej+08CcnxUVgrW7mvjf2kxgbzuoMC1sKK7360q3VzWTvLAXAZAxgbWYSAFFhwazZVszazCSS4iJ6tF/b4sRW00Le3nLWL0zt0S+tb1xskz5riUQikVxy9AK2vxHd/u6v1ap9fRcTHuyhaSfFRfDS4jRWZ1jI21tO1tzJAD3Ss6LCgsm9sN+i9PFk7yxl6eufcKDiPAANDpcqdLWBaDHhwUSaTV77GhMejLW6WTXBD4aWLTVriUQikVxS/IneFlirm4kKc+/rTasWEdva/cT3wsQNkLs4zUPbXbOtGHt7JyZjAMtnxfOz7UfpVuDnd09j874KwkKM3DIxio1/sxEfHYbZFAjAunnJ6vlyPzruIcC12ndOgZW1mUlEhQVLzVoikUguNZertObVgjZArC+s1c0sf30/WflFPb7Pyi/CVtPCis2f8sGRau57w71fvd1JVn6RKixzF6exbl6yeqzIn16bmYTJGICrs5v3Dp5mzR1JWMaEMTNhNCtvSWBR+nhe+fsJOroVggIMrM6wAG4ft1ZQR4UFq9ciLAVi0qAV1BeL1KwlEonET/rrk70S6I+WezFYq5tVDVQIO3/GUQhC7bHZO0uxVjfz1kM3AW6hKIRwVFgwWflFHhrwuu0lqgb90z8eIXncSHIXp3kUPsneWUpjq4u7b7iGnF1fcMP4Uay8JYHN+ypYeUsCd06PU7V3rYaelV/EsepmNi6dwWxLNOA7yE5q1hKJRHIJGMraz4PFUK1CdTEWBWt1Mys2f+oheLU1vXsjKixY9UNbq5vJKbCybl4yG5bOULcL33XuR8ex1bRgMgaofc7eWcrxcy00trrYvK+CbgWWz4rHVtNC9s5S1m0voaLWQaurE2t1C//z1zKCAhWeuC2RmQmj6ezuZu0fjvD630+QU2BVBbyILF83L5lJMWHk7S3HWt2sTg4GY9y0SGEtkUgkXvD1kh3ugtpfEzP4N/nQ5jb7GhPt99oiJOJzUlwEW1be6FElTAhqXwFYoh1tilf2zlIaHC4ANuyxcd8b+6m3O1kxO56kuAjmp45jS2Eli9LHqylWuYvTWP1tC6EmI0/clkhCtJlff1zBI28dpM7uxHq2mZ9tP8q/psSRNC6C60abCTIa1X60Ojtpbu/kF7usnKp38PQOz/FNiotg0/J01mYmkVNgJafAqhZM6TFuAZqG+4kU1lcZ0p8mkVw8Q7nU4VCij4j29xhfCGEKeBXqekEu9s/KL+qxTSuo+6K2xe13FoJcnNfV2U1lfSsNDhe5i9N49i63EH88v4h395/iqe1HyUiMYfO+Cg6fbuQ/f3eYAxXnydll5djZZhpbO4g0m3jg5gTio8yEmgK5Pi6CNXck8ereckyBBn72r8kkRJnJ21tOvd1JxAgTU2LDsESbqXO4+OJsc49nIyY8mKS4CDWnW6R26VcFM44cM8HvQdAhhfVVxJX6gpFIhhvDwdw90N+x1sQ8mHgT1NoiJcIsLAK3xDG99UVUCvO2XeQ861fVsowJ48XdZRyoOM8zf/qcBoeLa0aNYNuhL3F1dfP+kSqyF6Tw6LcnUd3YzqjQIO6/+TqCAgxs3ldBZvJYNu+rICgwAGNAAD+am0jqhFEsuGEcoSa34hsUGEBm8lgaHC7CQoz8anEaz9yVwrurZvPCPamEhRg9/N3W6mYKbXXkfnTcY2y0E42Y8GA6m86dGuj4ywCzq4xLFSwikUiGjuEUyNbXalbetum/1wZm+Xsubb5yToFVFeofHKnmJ9uPMDVuJKszLESaTWTvLOWu6eNYv8vKhqUziDSbuO+N/YyJCAFF4fg5O2tun8LOo9WcqLUTYDDw0zuv550Dp+no7KKi3kGrq5tJ0aGEjzBxorYFe3sXESOM/DTzelInjGLF5k955rtTee/gaRalj+e9g6fVAirLXvsExQAbl3gGmWkXAoGLCzCTwloikUiGIcNp4u1NiPqLtbqZZa99QlJchBqh7avdNduKPTRtIahdnd3kLk7jr6U1vH+kCldnt+rHfnpHCYri1sRXZ1iwxIarQh7cfu7ls+Jpbutg875yzrY4uXbUCEzGAKzVTRiNRkaGGKlqbGfJjeMprW5m8cwJZP+llCiziea2DjYtS+dUfSsFpWdpcLgwBxvV/O1Ny9NVLVuYv8GdIrZi86cevnoZDS6RSCRXGUMlqPXBX/7sr/VJ+3K1+WorKsztz12dYfHwpYuoadFuvd2pCkDxXU6BlUXp41VB/eQfj1Jnd/LEbYlqFPgXZ5tZeUsCAI2tHazZVkyhrY6osGA13/mLs82s/eNRjtc6eOzbFu6+4Ro6OhXaOmGEMYDGtg6MgfDWp6cpPt0EQEAA1DtcuLq7ef7Px/jvD78gM3ks4C6M8sRtiVTUOVTtWaSJiaplUWHBPYLqLgYprK8SpJ9aIhlcrsTfVF999lfwatFGY4v/a/213trVH79uXjKW2HCPKGlRVEQsV/nk74/Q0dXNgYrzrNlWzIGK8zS2uli3owRbTQsFpWdJHGMmIiSIDXts1NuddHQrGAIMAJw638rPth+lqqGVh986wENvHsBW04Krs5vNhRWEBgUQbDSw9dNTPPeBlbnXj+E7KbGcb3XRrShMjDYzPnIEP70ziQlRoaycncC1I0cwOSYcY6CB5bMmkH/gFJ9XNdHgcGGJDWfrg7M8qpflfnScVXMmqtaBwRLUIIX1VYEMLJN8nRmK5/5S/aYGs31/+uxN8PqrwWvXgtbmTOvb1fdBmLIf2XqQ7J2lHnW2Gxwucj86TmbyWE41tOJwdrL2j8VUNbTy1I6juDq7eXlJGpbYcNZmJvGrJTPIXpCiBrAFBRj4yR3X88sPrZxuaCMzZSwRI0woigHbuWZydn3BE7clMmVMBJkpYzEGBlLvcDIiyMCre0/wl5IaHrj5OhKiw+joUjjd0MaLH5Wx7I395P7VRtk5O99OjOFEnYNf/dWGgoHn5k/DEhvOuu0lPaqXZc2dzJbCyn7cNf+RwvoqYDhErkokl4OhEqqX4jc12H331mdfbesjlfvTtrecaf1+QvMWRUkWpY9XBazQpJ/eUcJj7xQxP3Uce8pq2bhkBqszJhNoCGCEycgj/zKJcy1OGls7yMovUguYAOqSl2XnWth26EvCQ4IYHzmCedPH8cRtieQtT8cyJoLKOjsADQ4nfyiqIio0iB9mTObHc6cQEmTkOymxzJgwmqqGVgyAJTqUhGgzQQEQFhzI47da+NvxOsaEmQgMMLBk5ngKSs8CMD91HPV2J/e9sd9rsZfBRgrrqwQpqL/efF2tKkMpVIf6N9Wfvg8kZ9rXZGCg59XurxfU2nNpBVi93V11bOv+StbNSyZ3cZqaj7xxWTpbH5zFndPjyJo7GUtsOJv3VfDzBdMICgxgV2kNz96VwuZ9Fbg6u8lIjKGspkUtdtLgcBFoMLBwxrV0dndT72jnB1sP8oO3DhJpNvHCPdNIHjeSz880ERwUiAFwdnbzwi4rv9pjI8QYwF9Kanhi2yHCQoKoqG+lU4GbJ0Xh7IIl3xjPx+X1HD3dSPgIEy8vTiN1wihcnW5TfdZ7h6modZAYG+6xgMhQIYW1RHKFc7Ea2pUi6AdaUexirm+ox6Y/az73ty+9CWVtBLb+XN7O21uFMe25BImx4YA7uOyth27yiAIXdcEBNSgre2cpfy2toejLRgCa21ycuKAV28610Nzm4uU9Njq6u2l1dfLk74/w4u4y1t6RxDufneJ0QxvGgEAWzbyWQINBrXKWHBfO8x9YsTs7mRRjptbu5IGbryMpNpyxI0MIDoQJo8w0t3cQNzKEk/WtvHvwNPekjcNW6+CBmxOYER/JC/dMY2bCaHXd64QYM7mLbuDO6XHqal5iTAZrSUw9UlhLJFcIvQmrgWqXV0q8w0D7eTHXN1zGxt+SoL6O9bWv/vr0n7UCWC+ARIUxUalMIFa7Wj4rnpwCK2u2Fat+abFSlijHaatpUc3kR6sayT9wCnNQIGcaWimvb+Xf0q5hZsJoxkWGMjLUxNiIYAINBjAYKK+z80VNC29+cpKKOgcPzL6OidFmth+u4t9mXMOLu8u499VCNu87ya1J0TS1d/Dj26ZgiTFjq3XwxG2JfGtyDF2KgX9PH0/imHAey5jM1HERrJydwPvFVdQ2O9m6v5LsBSkkxUVgq2kB3HXF120vYfO+CgptdX7VNx8MpLCWSK4A+hIcvRWt6A0RFDPc3SgDnZBczERmsE3sF/NC700geHs2ettXCN56u9Pj+rTX629tcW2qlUi9WjVnIjuKq1ibmcTazCS2FFayYnY8DQ6XWpWsotbB/b/5DFtNCxmJMUwbN4pVcybxwj3T2VNWy7iRIWzed5Idh76kpqmdB25OIGKEiaSxEfzsO9fz6vKZTLmgvXejsKWwknnT4vjP26bwm8JKzjucPJZhwWQ08PeyOrq6FM40tHK2xcktE6N47i/H2Pj3E1w7KoRdpTV0dCus32UFReFvx+sINgZw303xqp+90FbHo+8cwuHs5NW95ZTVtGA928zqtw9RaKvziAHwVZENkLXBJZKrnYEIDn80Q5Fucrm1R3/or9DUaohDdU5/x81fLb0/AlnbR+2z4Y8pVqwDLbRFbVtihSwhhOrtTtYvTPVI1xLpWGEhRjXV6sfvHcZ2roVIs4msuZNJiosgKiyYFbPj2bDHxuq3D7EofTxRYcHsKK4id9ENNLZ28PMCKyNHGPnZ9qP8+uMKGts6CDEGoAC7SmvInp/CzITRhIUYWXlLAhv22ABYeUsCoSYj6+9JZUy4iZwPvyBiRBDXjAzhZF0r73x2CoMB4keH8sNbJ7Pp7ydwdXTzqz02TtbbefRbk9wVzoB5KWN5bsE0Qk1GOjq7MAYEsPnjClbNmUhOgZUNe2zEjRzBw/8yiaAAAy/cM53f/eBm3nroJncFNT9+m7Utsja4RPK1YCi0yislk+BSmr+H4hy9jbPWDL1mW7FXrdafGtv+9mP9wlRmW6J55rtT2VJY2eM4Ee092xKtLgpiq2nxiHoWrJozkWf+9DmZyWOpbm5nXGSoavYutNWx6s3PyNtbzuoMCxNjwnjv4GnAXUv8zulxzEwYzZJvjOeDkhpiwk3cPDGKM42tAIQHu4WzOGbVnIls3lfBkTONrPrtZzz5hyOUXZhsjAw1MTUuglGhQZyzOxkTEcw5u5M2l8K5Fic7j1bzyLcmERAIUWYTrc5u/nSkCkWBWruT5z6w8kLBMTq7uzEHG5k3PY6yGjufn2li/cJUls+K52xjG6/+4wTWmha27q8kKiyYiloHKzZ/6hH9rnctaMf+YmqDS2EtGTSuBO3s64Y/QvhKENT9FbxDMQm52KhqX4Jae22uzm5yCqxeX/Z9td+XKVZraahtcbKjuIoVs+O97ieCwaLCLiyeERuuRj3XtjhV7Rsg994buHfWBDYumUFoUCB5e8uZnzqOF3eXUVLVzKL08cy2RLNpeTqr5kxUF/wQPuyT9a28cPc0Hrh5Ihv/doLYsGBGhpr43+XpADQ4XNTbneTtLaejq5v4SDNJY0fywj3TmRhjZuv+SoIC3eb1/eX1tLq6qW52ctf0cQQGGFj8jfHYau3sPFqNooCiKBiAyvOtxISbONfsnhycbmijo6ubplYXH5bWsPTG8bz2zwoOVJxnR3EVzy2YpmrWy2fFU2938syfPueJuYk9Vtnydm8B6O7s9OuGekEKa8mgMFyCcSRDw+W8r76Eoj/+eG9cTLCZv75cLdqymt76qF2xKndxmipo9dHYfcUs6P3P+j5oTeMx4W7z9JbCSo9r0u4nzinIXZxGvd2pFgPJvfcG8vaWk7e3nNoWJ5bYcEzGABalj2dHcRVP3JbIc3e5NWhwm96z3j1Moa1ODSxranPhcHWROmEU2w59SYgpgJW3TMTV2U1jaweP5RdR/GUTFbUO1mYmuVfKCjSQvSCFhBgzxgB3PfDVGRZyCqy89s9yxo0MITAADlaeZ1J0KHvL6rA7u5g6LgIUA3X2dhKiQ/lWYjR/KamhS3GLwYSoUBakXsP51g6W3TiBqqZ2HvqmW7OfnzqOjXtsbN5XwfMLprGjuIqosGCe+e5UCkrP9rjH+tXIVKTPWnK5uVLMqRL/8RUlfDnwJqgvZXS4CMTTa719BXaJmIDegvj0JmxvAV/+mNF9ta9dDEPsX9viZEthJRmJMWqkdm2L02M/cc2iiEm93fNaZluiWb8wVZ1cCP/3ewdPs2J2PC/uLiNnlxVrdTPW6mY27LGppndRBvRkfSuVdXY1+MwSE8bmjyv4vKqZ5rYOJsWYGWEK4NV/nFCvp6LOQfGpRrePvNbOM++X8F/vf471bBMOVzcZU2JIGB1KdZMTY2AAgYEGLNGh7DxSTaurC0UxcKahlX8cr+c7KbFMHmMmPMSIAXh1bznLbpzAm59UUtvsZOPfbNQ2O9mw5zgl1c0cO+uuGy6i2d87eBp7e6dqgRD3SoyRPu9d+qwlwwIpqK8e9GbV4TYRG4ro8L4EuL7whbfALr3wFvv0ViNaq7V7O17s480v3dfkQ0wW1mYmkbs4DfhK61sxO57//vAL5qeOU/OH1y9MZd28ZPVcOQVWsneW4ursJiosWA0cA/ckQGvSfjy/iNUZFtZmJhFpNtHm6mJSTBgNDhfrtpdQWtVMQoxZFeR3JMcSEAA/v3s6kWYT6+Yls2rOJOpanEyKCWXboS8ZYTJiQKGi3gHALZOiAHj2z59jrWkhY0oMtloHZbV2XJ1gCoB3D5ymurmduIgQDAZ3zfDF35jAC/dMZ9PSGcSEB+Psgu9Oj6PwxHkAfphh4XxbBw/PmchnlQ1YxoTx1L9eT3yUmRGmQP7foht4ZekM/vvfbuDp90t48vdHeDy/iMzksYSFGHvcK29Bmxfrs5ZLZF4GfPmvJJLhxNfpORVCTwjf3nzMegHqa3tv3+m36YWxt0pkItjLW0nRvvzT3vYXudKrMyw89k4RWx+cBeCxdrRop97udAvr/CLWzUsGUJd/FJOYVW9+xi/umU5OgZUGh4uSqiaenz+NgtKz2NvdrtqVtySweV8FRacbCDYGYAwI4IV7pvP0+yVcF2UmLMTIqjkTAcjbW86i9PG8+o8TBAUGcMukKH71Vxs/vNXCx+X11NudVDW1YgwM5IcZk/ndwdOMCA6ipc1dEGW0OZjmNhe2WgeKAuEhgfz0zmR+ufsLFtwwjs8qGzl+rplAg4EJkWYUFEJNRgwGeHZ+inq9gEfhk0JbHZbYcGw1LWwprCRr7uQea3X7uudyicxB4FKZ+IaDSVFy9TEUz9PVLKh7Cxbry8csjvcW9avXfn393vV+aO1Y633jWu3cmzldLyREVLnwPXszs4vvcxenMdsSzdYHZxEVFkxOgRV7e6ca3SzazimwYqtpUauNAWxZeaPa37+W1nD6fBsAazOTePhfJpE2PpIJUaGsX5jKpuXpPHFbIs/86XNW3pJA0thwkuNG8liGhTunx/Hb789i0/J0teb3hj02MpPH8t7B05iMAay8JYFff1zBlFgzy2Zfx7PzUwgJCqS9AxbPHM/Ua0ZS63Dx7cnR1NpdnKxvZeGMa4kODyFuZAjJcRFcGxnKO5+dcmvPJxs4fq6Z60abeTxjMifP23F2dtPR1U1Q4Fc1zEWJVDG21upmdaEOS2w42QvcQl0bD6Cf0A0WV72w9mewLqUAHY4mRcmVjZwA9g9f4yWEmC8fszfzdl+BYN5+79rALf15hL9Tb0bVmqV93WcRHAZ4+JK9TSy0EwIR/R0THszazCRMxgByCqyqHxtQl4TcsHSGW4BdKBeaU2Bl5oRRvPhRGdkXtNEn/3CUdTtKWDjjWrLePUy93S28LLHhbFl5IzMTRmMMCGDhjGv5791l6trT4BaQj759iCNnmvjFrmMsSh+PokBzWwd2ZxcP3OyOJk+Ki+A3K2fx1J1J/L7oDM/9uRRzUCBv7KsgJszEtGtGkjphFBmJMZxpbGfu9WMAOHKmidy/Huf4uRbaXW7f/O8OfUmbq5sTtQ7aOrq4a/o4fvKHI9z76sc8vaNE9dln5Rfx9I4S1Y8vtG5fz5b+/xfLVW0G15u2+tpXClDJlYp8fvuHP6Zp/XdrthX7rE5lrW72WNfYn/cN4PP91J8+iLbWbCvG1dmtaoLezLLW6maiwoKpt38VTGYyBvQwe9tqWsjbWw7AovTxPJZ/iJcXz2BHcZXHqlrrtpdQXmtnzR1J3DtrAtbqZpa/vp//e/sU7p01QTUZi33Fspjf+/WnvPmAWzO3xIaTlV+EyRjAqjkTiTSbaHC43IVUMiys2nqQMWEmTtS1csO1I3ltxTfU6yu01fFffyrhdEM7DlcXBiDUZOBH/2cKO49WYzC4Bf3YkSNwODtp6+iivaOLR75l4c1PTrI6YzJP7ThKjNmEwQBnmtpBUcAQACgkxUaw6UIK2YGK86zbUcLLS9L4n4/KOHHOzlsP3aRONLy5MfT3eUxEiDSDe6M/Wqx80UmuZOTz2z96Gy9/x1Krqfa3ClxfEd6+vlubmeQhFLRa+vqFqR7pVXrN3FrdzH1v7OeRrQeJCgtWg8lE7rNoS+Q0L0ofz/qFqSTEmAkPDmJUaJAqqHMKrOQUWHnitkSiw4MpKD2raugvL0mjoPQshbY68vaWq9q+sBhEmk2kjIsg0mwC3BODjq5uMpPH8nh+EQ0OF7Mt0eQuTuNUfSutTre/O+fuaazNTFI13df/foIH3zxAdZOT66JCiR89ghFBgCGAFz8q48iZJr4428SIICOrMyyq4K4830be3hNUN7eTEGPm7QdvYutDs8ldPIMJkaHEjw5j/T3TyVs+k03L09V7saO4Sl1b2xxs5LkF01QTuP5e+Huf+8NVLaxBvsQklwdpkh48LvVY+vJVazVafT1ovb+7t3xsb+ZtfxCrVWl96vr0Ln16lfacSXERvLQ4TY1eBsjeWcpj7xSpC1IIH6y9vZOn33cL7qS4CDYtm0He3nJsNS3kfnScVXMmsjYzicbWDirqHCxKH6+ezxIbjsPZyYY9NtZmJql+6KS4CFbMjicqLJhQk5Ef5hex/I39fH/Lpxw728w7n53imlEjyNtbjrW6GVtNC+t3WTEGGKioa6WlvYNH3znEk78/QlVjG899YMXh6mLe9DhWZ0xmTHgIibEj+dGtk3F1KQQHgsEQwJdNrTS2dnD8nJ1zLU7uSRvHxmXpbFwyQ+2X6HtVYzuVDQ4276tgwx4b9favTNjzU8cx2xKtTpp2FFepFgZh6s+aO1m9V9qxHww5dFWbwSWSy0F/3C+S3rnUY+nP+UT1rtx7b2C2JbrHsaLYiC/zttaUrcobLXYAACAASURBVD0f9F7IRZiRtdWyettHmOaFkPcW6V7b4lQrdGn7a61upqLWwZ3T41RhpTVV5+0tV03oi9LHq4VPRJuPbD1IR1c3azOTsMSGs2ZbMavmTOTx/CIenjORqdeM5D/ePoizoxNFMXBtZCjhIUZ+cc90KmrdwrKjq5tvJ8bw8h4bJmMAU2LD6ejqxoCBEaZAWju6aGp10djWgTHQwHWjzZiMATw7P4UGh4vG1g4SYsz8s6yWbybG8O//+zGjRgTR5OxgfKSZ0KBATtY7eOlCkJ0Yi637K1mdYeF/PipDUcBkDMDh6qK0qoktD9yo3nOta0FMkESaW0WdQw3a0z5PFxMNPuBqKhKJxDsyiHDwuJRjqddUfSFqZ+tzp7XHWmLD/Y6TEYJaP0nQClXtfuKzXmALzU4I6BWbP+WZ707lvYOnPczn+mPFdm2/1m0v4WS9g1GhQerEQ6RsJcW5Tdi9+WrbXF1Unnfwg60H+d/l6bg6u4k0m4gIMfL8B1ZeuHsaryxNZ92OEmy1Ds40OAg2GSk+1cgvCo7h7Oyio0vBYIDHMiz8raxWFdSnGh28umwmja0d5H70BWdbnDz/nRRSJ4zih+8cIntnKaszLDz9fgnLbpzAS3ts/BToUhQa2jpQFIWqhjY2LXNr1iK6e8OFScG6eck0OFxqVPi6eclEhbmLvmgnZ9qxF/dGHC/GSWwbjOf3qjeDXyqk2VOiZTB+nEPxTF2Jz+lgCerert1XGpUvfBU50QpXb+cU5nSgx/n6KrACqAt9eNuujRZPiosg994beO/gabWgidZEL44Vy1qK/lirm6m3OwkLMaoap/BTP72jRI0SF+lb2nxt7dKbpxtaGTdqBAoKp+pbMRkDqKh1EBUWzIggA29+cpJIs4nIUBOTokOZdm0kv1gwnYLSs0SHBRMcFMiTdyRhDAjgt59U0u7qoqqxHQUFpVuhsbWDp3Yc5XRjG6u/NYlbk2OpqHVQds5B04U866hQE8VnmvjFgmlcExlKR6fCNSND+OXCG9i0bAaW2HBmW6LVVcEAddKS9e5h7po+jnXzklUzuQiU0453oa1OXchD3NukuAiP52Ownl8prAcBmTojGWyG4pn6Oj6n+kAsX9c+UA1en2et36ZPkRLn8pb65as/2tQfsdCHfi1qLcKPaokN96hcJky1Il8b4Okd7vM2OFyqGTenwMrazCRVi6y3u+t4nzhnVwuWHLsg1LXXLQRdRa0DY4CBlTcnMGF0KL/c/QW3TIzimT99zgM3JzB+tJmymhYqat1VyUabg/nR3ERmJoxm1ZyJnGtp5yd3XM+D35rEpuXpbFg6g7jIEfz87mncfcM1BBkDOdPQyp1Tx9Lq6ub1j8t59K2DjAoNIiw4kAWp1/Dcn0s5XmdnUfp4UieMYvO+Cu6/OZ4RJiNb91eyfpeVR7YexFrdrEa9azXiZ747lZwP3dXbRC1zbc10MUHJ21tO7r03qMJ5KC1AUlgPAlei2fNKeGFfCX0cKvTP1GCMxZX4nPqiLy1Z/OtPyVTx8h2IoPZVJhQ8c6a9BZ7pTdz6ey0EtShwAu5KWqvmTFTznPXnXJuZRE6BlUJbHVn5ReQUWD3OIVbNEstenjhn567p48h69zAVtQ5MRvfqVdo0tJwCK+vmJatrNwMeZUTr7U5MxgC3wM8v4un3S1hzRxLvH6kiKDCAZ+9K4cCpRnLvvYGZCaMZOSKI5+ZPIyHGjMEAHV3d/M9HZWTlF9HY2kFbRzfvfHZK1dJnW6JZm5nE5n0VrP/wC76dGMPzH1h569PThJoCWHfnVNVkHR8Vyoa/2TjV0EZoUCDgthgUnW7k9X+e5ESdg2/ER3Ki1kFZjdsvvyh9PLmL02hwuNR1vEeFBjEpOozls+LJevcwByrO4+rsxlbTwrrtJdhqWlT/vfB365+N3j4PBCmsB4kr6QV4KTSsi23766gF6unLJHoxbV7J9DYevgS0L2GsFYb9fcGK9pPiInxOBMQ2oc36SvHS32sh1IVpVRuJLpaghK9M6Vrt3N7e6WHW1fqUhXDNXpBCpNnExJgwbk2OJffeG9hRXOUhqL1FtN/3xn5+/N5hDAa3j1eU2lw1ZyJbCitZNy+ZlxankTphFA5nJ5XnWxkVGsSK2fFEmk3YalqwnbPz+6Ivyd5ZiqJAZ5eCiHMeFRrE2tunqPuu2PypGij3xG2JZN+VQkNrB3enua9/1TcnkjphFB1d3WzYY2PkCBOvLEsnb3k6effN5L2Dp8lekMLqb08iIsTIuIhg3vj4JN1KN2NHjuA/tx3msXcOcaDiPHl7y3nmu1PZsMfGD7YewGCAmQmjeea7U9m6vxJXZzcv7i5TAwhFoJ02M0B7D/216viLjAb/mjJY6QS+2h6MCN6h7OOVhrfAoK8zvY2Dfpu351E7ngJ9AFZvRVD87Utv+/o6Th+9rd8mgr9++/1ZHjWpxbWs2VbM2swkdZv2+kWxE6GB29s71VxiockKRO3vBodLrYFdfKqRX+7+gmfvSmHzvgqyF6So2rs455ptxdjbOzEZA8hIjGFPWS0lZ9yrVSXGhvPEbYlYYsOptzv5Z1ktG/5m4yeZ1zMhKpRVWw9iNMCTmddza3KsWpP8QMV5ntpxlPjRoSiKWxvv6u4mYoRJ1arvmj6OW5Nj1TEQwnRR+nie2nGU5+dP40xDK6/8/QTPLZjGqNAgHt56kPGjQ/nZd65nwx4buYvT+GtpDS8UWNm0bAaRZhM5BVYczk4euDmBp98v4dm7UpiZMFp1DwhrBOCzMI74LGuDS/rNUL7w+zK3+jvD9Ocl+XVB+9L9Ol23L3p7NvTbvJmZteZrsU9/xlfs01sdcW/HaPvgTZsH1NWtvKVmCSH+2+/P8sgPFm1rg5xEWpEwx9fbnWzYY1MDztZmJnnkXNfbnSx9/ROWvfYJgIegXjE7npwCKwWlZ3lpcRoJMWZO1jtocLjUXGohqETJ0rumj+PVveUsnxXPxBgz10aOAFAXwVi3vYQXdllp7+gmZ5eVz8800XphuckXCo7x0JbPaHC4eGjLZ/z0j0eJiwihua2Djq5uvjhnZ+EMdynS1RkWls+KZ937bvN0vd2Jvb2TvL3lrJozka37K+nuVmhu62D9h1/wH9+axMyE0TS2dhAQAN+bFU/e3nIczk7+WlrDf3/4BddFhxJpNqk55eZgIzMTRvPsXSk886fP1XzzdfOS1YDB+97Y72ER0SLzrCVXHIOpdfur+Vxp9EdrlAwMX5YKvUAVRUH0x2pXwdIuG9nb+fSreokVrLTHiudalA31JrCBHn30polr88FFXjTgcU79OHxwpJpRoUHMtkRTaKvj8fwiXlqc5hEJLc7xwZFq3jt4GvgquEwEp2XvLKWjqxtFgSduS2TDHhutrk4Uxb1v1ruHyb33Bj4/00TOLitr70hiT1ktR6saeSozmdf+Wc45ezvjR4VS1dhOfFQo86bF8fwHVn54q4W/H69FUeBEnYNJ0WZe+LfpPPn7Izz8L5PUCPjVGRZ1YgAQaTbx4/cOuzVxg4ETtS2MiwghOjyEu6aP44UCKwEG+I9vTeKbiTEe+ewfHKlWc8kLbXWqn1p7H7Lyi7zeMy0yz1pyxXApgpwuhUDr7SV/se32NpkZzOsa7oK/v/3rz/56E7j2e0G93amagvWpOCKvtj/ljL3tq12OUuwnhJ0vxERBW+pSCEutMBfpW5bYcNYvTFVN3PprEWb3jMQYflFwjOui3MIvb28510WZiTSbehRyqbc7VR93Ra2DddtLMBjwyE3OKbCqvuzVGRae+8sxzja6V+YSBWVmW6KZes1IZlui+WZiDBW1Dl79xwlO1jmIGzWCUJNRTbOqtzuZcug0xWeaWHNHkrtoCd1U1reqwXHrdpSQPT+FhBizulTn6fOtTIgKJdRkJMgYSEVtC5GhJtqcXQQZA+jo6ub9I1X8/O5pNLd18MvdX7CrtEZ1DxTa6sh67zCjQoOINJvYUljZI48+JjxYjSYfKqQZfBjSXzPnlWYWHQwBIV5q3jSPSxE8NxQBJHDpIraHu0ndV/989bc/5mjRjq/AMoGv4icCfbpVX+hf7rmL07xahqLCgjEZvb+atRHm8NXqWkJwa/Oda1vcNb6z8os86nnrS2HmfnSc+anjWL/LSkeXQnm9nQaHS13aUhQ/Efuv2VZMToFVTf/62fajWM8243B2snxWvNo3kf6VNXcyja0dVDe18R/fmsSGPTby9par426JDVejzjfvq8BggGsiR1DV2EZHV7cqqLN3lhIeYlIjsJ+dn8K2h2/hyQulP380N5GXl6SxdX+len5Rw3tUqIl185JZe8cUEqLDaGrr5PkF0/j1A7P40dxEHM5Otu6vpKD0LM/eleLhHphtieY3939D9V/7clHkFFh7fZ4uFmkGH2b010w8WGblK43ervtK1qwvJdqVooYj/gSKab/3xxytRaxA5S1lyt/+DPSea8/lrZ2+2vZ1jB4hpIVfVftZHC/GwVbTwnN/LiXIGEhkaJC6Apa2Upk4j1ZL/+BINa/uLedkvZ3JMeGsvCWBrfsr1cCrddtLOF7bwjUj3ZqyqPIl2hXBYI2tHWzeVwG4K6CVVjfz0zuT+GZiDE/vKEFRoNXViTnYyI/mJqq+9Kx3D/PQNxM4cKqRjMQYXig4hmVMuBr8pq3OlvvRcdX/LlbvysovwlrdzIalM7ya+8U1e3NP6E3h3o7VcjFmcCmshyFDaf67mvi6XvdgcLkmeQO9Z958zP5EVvfWnvb6rdXNalSzN23Xn/Hytz/ixQ9u7c+X39vbZKqv6xSCV7uutcBblLv2ukXt7pcuFFFZ/fYhOrsVUq4Zqfq5hUB6ZOtBTtY7ePauFLVcaYPDxYu7yzBdMC0/e2F960ffOujhu14+K56ZCaNZs62YRenj3Wbv8w4MigHLmDBW3pJAc1sHz31wDKMBxkWGUt3YxiPfmsTGv52gW+kmISach+dMJCHGTEWtg2f+9DkPfTOB//1HOWMjQhgZGqSuQCbqdWtLgd73xv4eNcHvnB7nUedbX4PdW7yAtyyD3p4TGQ1+ldHfl9nXVWB9Xa97MOiPuf1izXp9uQv6al97nFYb1OYYD+Q3ow32yv3ouMcKUb3t31cfvV2nXusS5muRfy3KhApEcJgoLao/h7fzi2Pq7U6Pa9EvmSm+F9ctVtCabYnmt9+fpfqSNyydQco1I1mdYVELu2TlF6kFQZ69K0XNPwZ3AFdYiHs5SnOwUV032xxsJHtBiroa17od7qjthtYOfvLHI3R0K7yyNJ2f3z2NJ25L5KkdR8nZZWX9PdN59NsWxoQH88i3JnHgVCObls3ghXtSOXGuhR//roh78woBtw/8wKlGXl6Sxq9X3uih/Ta1uiPIRT+T4iL4z9umsGGPTbUSPLXjKIW2Og/NW+9a6SvLQHznzUw+GEhhLZF8jfDHVKfffyC+bW8CRhuYpd2vLz+ft9Qr8VIFBux71wZ1icIl2vb0bfZmdtb2UT8R8DaGYr/aFqeHT1gQFRbMlpU3evTH14RBtC+OiQoLVkuS6v3LovqW8LeLutjZO0t79EWsKS3qgzc4XBw769bEXZ3dJMS4V7laPite9YcLob82MwlbTQvZO0vV/Ot6u5NIs4ns+e6CLGZTIKNCTVQ3tam1vgE2LpnB2w/dxKjQINZ/+AWWGDOv/bOCjMQYtQRqV3c3zi4FZ0cnT/6h2N3uhUIvok63tbqZp3eUcKy6mc4utwVZlA/N+dBKaVWTas5Xut3bs+ZOxhIbrqa39VWv3du96O/a5v4ihbXkqmO4Bk1dbgYieAcS8OZNQGuPH4hw1WsvoooUDM6qRnrB3Vc/+xpLIYi1FcP0fSy01bFmWzH1dqeHtiuOAzzWphbjqQ8Qg6/GQEw4hLBZvzBVrUomtD7h6wV3NTShdQoN3FrdTKGtrsc58vaWs/Z2d9CWyRig5mq/d/A0q+ZMZNWciarp+Me/K+YHWw9w5MtGKmodZOUXkb2zlFVzJrJ5XwU5BVYyEmOoamxj7e1JJMSY6VYUcgqs5O0tJyrMvXDGhMgRbDt4hoe+mcAvd3/BB0eq+dn2owQEBLDy5usINhq5IIfVPPGlr32iaskP3JxA+nWR/HJRKtkLUjAZA7DEhvP2gzexaVm6eo2WMeFs2GNTJzkmYwC2mpYez512EuaLoXItSWEtuaoY7lHO/cWbhjdQBmr6vhgTs/54b9v6ypX3ZjYXFbUG0j9/+t/bWHmbhIjnTl/7Wxu5rcVa3czqtw/R2Ory0IKFr1n4TLX1vNdtL1FXeRLmce0xWkzGAFVrFJpebYtTNbtv2GPDVtPC+oWpPDv/q+jnrLmT3Wty//pTXv/7CbV9UWikoPQs6+Ylq4uDVNQ6qGpo5cXdZTx+IVDrQMV5rNXNRJqDwQCb91XQ1NqBw9kJwIk6O5nJY9lXXs+a26eQOmEUAK8sTSfSbFIDwurtTs62tOPs6uKayFCujRxBQoyZ5xZMIyAASqtbeCzDQvCFdLGkuAjefvAmNi6doUahiyhxsX3VnIlqVbQNe2wsyfuE7J2lPHFbohqdHxUWzKL08WS9e9hryVVv91r7/VAhA8z8QAYyXVlcLfdLG4h0KYu/+Bt8dqmi7n1FgEPPNaD7astX9PXF9ke8uEVusTDX+vJ31rZ8VRRFWxZUIILAtAVPRDvawDNvkyrRF+1x8FV+NsDi1woJMBh4+8Gb1PWvtfu/VXiSdz47reZpiz6JaxP+3IOVDSjAD2+1MGVsBDMTRvPQmwcoPt1I4hgzESNMLJxxLb8oOIYCvHD3dDbvq8BkDKCptYNTDQ4wgDEggLcfvEktLbqjuIoVs+P5/puf0d7RzfVxEZxpaCUxNpxn56fw5O+PsDYzSbUSiPEWAXPi9/LBkWry9p7g9Pk2/u/tU8j50Ep3t0L+qtk0OFxs2GNjdYZFXbNbXCfAovTxzEwYrY6t9t77KkTT17Mlo8GHkMsVNSuRgO8qWpfivH0J6kv1u+hNyPoreEV/+1N1zFf7+v5Yq5vV6OL/+aiM8loHWx901+3ubYx89V1M0rSR4toUs96uDb6q6Q14HFdoqyNvb7k6CWhwuFQhJ9oBsNW0kPXuYZ757lRmJoz2mASIWAFh2WhwuPj8TBOb/nGCbsUdKPbi7jJa2jqICg9WBWFGYgzvfHaKSLOJRenjGRUaxIu7y2hzdfHUv16vpoi9VXiSV/5RTu6iG0iIMbMk7xPGhJvImjuFUaFB5O0t55aJUWz6xwnW3p6k1gIXZOUXAaiR4IvzClEU+Omd17OnrJaMxBjeP1Lltg5oxlb7GxO/OeGbNxkDPArCDDQDAaSwHnKuFk1NcuXRm2Z5uZ/JS9mHwZgcaIWrP1qRVmh6K88p+gOopSaBHi9+b+foTePWCgWtBcFbOpFAe03CzJuVX0RHVzcbl6V7CB+hzXu7tkffOkhQYICaXqWtlgZuQS4EtX4isGGPjXXzktXqa6szLB5auAhGe/r9Eq6LMtPR1c3J8w7V/P3kH45y+HQjWbdayLp9itpuToGV0+dbeeuhmyg+1cjP3i9h3MgQzjS18+TtU9hTVuseowvnXp1hUYX/I1sPAnxVcW5nqZq+Ja4pK78IkzGAzOSx3Joc6yGM9VXffN1Pb9u8IVO3hpjL/VKUfH3x5jsdLn75S/m7GEigm7c24KtlK/saU1tNC67ObjWtylvgnIg8FqlC2iAv7Tm157BWN/eoniZ80PoUNdGmSO8Sx+rvvTZyWQghh7OTspoWDlScV1PTVmdYyN5ZqvqgtRXN6u1ObOfsNLW51CpgK2bHk72zlKz8Ih7ZetBdEe2CBi+KiYC7CpnIxV6dYWF1hoW8veXq9hN1dlZnWLhzehwvLU5j0/J01mYmMTnmq8Cuh+dMJG38SJbNvk4NcLPEhhMUGMCkMWEAbDv0JVPjIrg9OZYQYwAvX6g5Dm7/OcCLu8tY+vonamCfKI7S4HBRVtNCRa2DFZs/5UDFecDt30+9ZiRP/vEoD715wMPCIKLcvUX1az9fit+kFNYSyTBHL6AGQ3ANFf68rAbyQhtsLb6vMbVWN5P17mFWZ1hUE6h+H1E7XKxsJfqp7bO3cyTFRXisUa3Nj+7rvjY4XOq5tecRflbxf5HffF2UmfcOnmbF7Hh3dPguK8fONtPgcGEyBrBqzkRVYEeFBbNx6Qy1vrdYThPcWnJYiFFNw8reWcrnVU1k7yzFWt3MI1sPklNg5YMj1TyeX8SLu8tobHWpWvak6DC1rGje3nIOVJxX/cS5i9NYm5nE1v2V/OKe6RyoOM/9v/mM1/9+Qr1GESR2st7BN66L5PV/niTKbCIxNpw1d7gnIc/86XNWZ1hYeUsCk6Ldwl1bYz3SbOKlxWncOT2OZ747lXU7StScdGuNnRfunsYL90xT70nWu4dZlD7e5/3Xfr4Uv0kprCWSK5DhKqj70i68aSf9aXewNRdfUe+iLvhsS7TPsdbXDu9L09JrzFoTa+69N6jpVd6i30Xxki2FlayaM7FHLq9IvRJtRoW5tf3XVnyDRenjVQF5+nwbz8+fhiU2HJMxgEizCYezk+ydparA/7KhjeUXlo0U2rjInRZ9zF2cxivL0r+KCq9zkJk8lh3FVby0OI2VtyRgDHBXMgPUVChbTQsOZyc/+eMR5qeOA76aeJTVtNDgcGv137tpAus//IIdh76kvNbOhj02osKCeWlxGqcb2nnqziTGhIfwxG2J6sIaW1beSKTZxLodJXR0K+688OpmKmod6qREFEJJiDEzZWw4UWHBqqXl1uRYdVzFPdlRXNXr86PPdBhKpLCWDHsut7lX4h/e0pl620dogX3dX3EMDLwAijd8TRzEv76WxtSeX7+PVtPS5kfrr1VfoUwsbOHtHDHhwWrEc/aCFDUtSbQthF32ztIetbDr7U7W7SihobWD9w6eJnt+CndOj1NT5qLCgjEHG9V1mS2x4by0OE2Ngq6odZD17mE+OFLdo8qayHOPCgvm5SVpvH+k6qtCNTtKaO3oQlHc1oBWVyePvHWIH2w9yL+lXYsCbNhznCV5n7Akr5AGh4vffn8WAKVVTXx2soHEMeHsK69nw9IZqp9ZjMHUa0Zyos4OoK7VXVHrICkugpeXpBF5YYWs+KhQntpxlBd3l7FqzkQ1pU2sRa0Xttpx1Y6zuGfentdL9X7yS1gbDIZMg8HwhcFgsBkMhie9bJ9gMBj2GAyGIoPBcMRgMHxn8Lsq+ToyXPyzEv/QCuqs/CKfAluL1qTbW7uDYWoUPlSt31kbMNbb6l3al7m3drU5trUtTo+Slfpr1GrT+nPoq7wJk6wwtwtNW5T/XLe9RM191q7AtWZbsVtTfXAWr31vJmsvrE4lJgViTMUx4E5bEqbvVXMmsqO4iifmJnqUFRXHCt+10Mit1c08/+dj5O0tJ3t+CmZTIB1d3by4uwxjQABPZiYRYIAJUaEkRJkZFWriycwkLGPC1XPmFFiJjw7DHGzkl4tSWZQ+HktsuLsKm+Z5yttbTlxEiDuobXsJ//7qxzzy9iE+OFLNbEu0Wso173vfYOOSGWoxFHGtIn9dXI/IYRfjKp4FbY66CNDzdt+95WMPNn0Ka4PBEAhsBO4EkoElBoNBv3Dnz4D3FEVJAxYDmwa7o1cjUgD1zXD2z0p8U293UlbT0qsgjgkPVtOT/P0t+JumJf7VtitSrAptdT0CuQDVn+zredO/vLXn01YaE2hLVgo/tXYys6WwUn3Ji20isEprThfmdu3qV0LYOJydqoYphC+gVhTLevewui0pLkLVfIWGWGir8yg/KmqK19vd2v6K2fEUlJ5Vo8i1Vc5EMRdw+4OfWzCNs83tLEofT0KMGZFo1NbRicEAqRNGYRkTTqTZRKTZxOoMC+8fqSJ7QQqL0sfT4HBRWt3Mw3Mmkrs4jQaHi8fzD2GraWHVnInquNbbnayaM5ExESHuCPAFKfzu4Zt54e5p3Dk9Tr1ecX+FyV/0VUyexHWIiYe4Xu0901pK1mYm9VhxS6SyDVWJUS3+aNY3AjZFUcoVRXEB+cB83T4KIKaII4HeDf0SqTH2g6+DoL7SnwN9/5PiIvjt92f1mcvcm3AcSB96i7gGSIwNxxIb7rX6mMBX7rMQyEK4adOvtLXFBWJNaiEk9O1mzZ2sRlqDO01pxa/dUcraAh0i+MvbohKRZhMbl8xQzy2CvR57p4hIs8nDp26tbubxCwtxAPy1tIbv/fpTfrD1APNTx6nRz+Lfcy1OLLHhrJozUa1wpq0zDm4TuPChJ8SYyZ7vXoVLBHYZDHCmoV01h4eFGNVjwO2nLj7VyA/fLeJUfStbHriRO6fHUW930tjaQVhwEKfqW9mwx4bD1YWtpoX73tjPhj02Ndgt96PjNDhcFJSe9bCcaMdLTApFEJ+3BVTs7Z28uLtMDdAT4yyeK30lOnHfhWl+qN9TfeZZGwyGhUCmoigPXvh8HzBLUZTVmn3igA+BSMAMzFUU5WBv7V5JedZDxWBHuA7Xc0p6R7xYrlQLwnDov7YP8NVLVvt/fV6x/niBL2ENX0WAi8pevV2v8CeLIiX6QDQhrOGrIh5P/uEokaFBaq1wkQMsPgvtW1shTTvpEGsur86w9OiftbqZ7J2l5C5OU/OlMxJj+H3Rl+6c5zoH8dFhRIYGYYkxs6Wwkl/dm8aO4io1rzorv0gtdCK+W7e9hBWz43lxdxmAqvWLfG9bTQuRZpOqhZ6qb+WXu78gMTZczYn+wdaD2Ns72frgLIpPNbJ+l5VuBRamX8Mfi6qICjNxtqmN/10+U82hFu0C6jKYYSFGjwIm8FWVO+GrFv5/7TORU2DF3t6p5oLvKK7yiJPQPlcXw5AWRfFTWD9xoa3/ZzAYZgNvACmKonTr2loFrAKYMGFCemVl5UD6LBkgw+GlKvHOlT6JGg79760Pu3975AAAIABJREFU4sXsq2yrNv3J2xrQ+rWvvRUV0SP281aBTpQMFZqgEHr6YiP6CYetpoX7f/MZv7n/Gx7Vx7T7wlfFS/Q+eaEV66t3CcvCE7cl8vmZJv57dxnfu2kCT82bSqGtTi05KiYPQqvVBrktfq0QpRvefXi2xzlE0FtFrYNX/3GC0upmsu9KUWuCP/n7I3xe1cRz86cxISqU+3/zGf/3tkR2Hq3m5HkHP7njerYd+pKymhamjA1n47J0VcMODwli07IZauS6t0pv2iA8sfZ17r03qAJbK9hF8RhvhXD0bQ7keR9qYT0beEZRlDsufP4JgKIov9Ds8zlugX76wudy4CZFUc75aldq1peH4fBSlQwvhuKZGEib/rwUL6avfQlzLdqylVr/p3Z/Ue1L78cUAn356/uZGGNm47L0Hseu2VbMovTxvHfwNICH5uyrb0KDBXoIaq3WrNX+RQUxMTEQk4L5qeNIiDGrmmbe3nIWpY9n6/5KPq9u4v6bruOdz07zzHen8tSOo1w/NkKtfAZ4rY1daKvjxd1lajqVVht3dXZzos7OhMhQHv6XSW6TuSYH+q7p49TqYcJyUGir49F3DrFxyQwsseFq3rcYq0ffOsgDNydw5/Q4n8+JENRL8gpRDDA1biR3TR9HQenZHhM3Mc7+TMK8VcDzh6GuYPYZMNlgMCQYDAYT7gCy93X7nAL+z4XOXA+EALUD6ZBkaJGCWqJlKGInBtKmt2O0/md/2x1IWo3WZ+3r9+EtHU2v52gj4EUKkTnY2KMtUT3sqR1HWTVnokfRDW99Exr/itnxPJ7v9kVrg9yEoD52tln1R4sccRFUJ1KvAOanjuPp90vI3lmq1vkWkd/LZ8UTgIHMaXFsWXkjMxNGc/1Yd1Uy4bMVglqkTIl+iEAuUeVMm5O9aXk6G5fMwBxsJCHGrI738lnxqvAU8QVC451tiWbjErfWXG93qlHeIkf92fkp/PrjCq+CWkR3i/MkjxvJK0vTWTcvmYLSs9jbO72OsyiS4iuQ0Fcw4SVBUZQ+/4DvAGXACeCpC989C9x14f/JwD6gGDgM3N5Xm+np6YpEIvHOueb2y3Kuc83tvZ7b337p2xzofseqmpSH3zygbuurrYffPKAcq2ry+CyuSdtOb/0Qn719J9o4VtWkLNy0T/lLcZW637GqJmVm9ofKsaom5VhVU69tfHy8Vlm4aZ/a196uaWleocc5j1U1Kfdv3q/cv3m/8pfiKvWaPz5eqyzNK1SmPfOB8vHxWrVPCzftU5bmFarHPvzmAeUvxVU9+in+xHcCbVvi3OJ8ac/uUhZu2uexj68xFseK4/5nl1WZ+vQHyqSf7FT7I/pw/+b96v///ZV96mfRnxuf26289jebMvmnf1bPrb2P4jpFm9pxFv3QP3tL8wo9zuvr+bmY3yZwQPFD5nr7kwt5XMVIk/eVyeWKLdD7bb2ZpPvbr96O0W/z9bzqI6C1Jk79/noTpT4A62J9j6IvWflFlFQ1YQCmjhupmsKFFWD56/uZMjbcqxldtPHI1oOYjJ5mdG/n0gZBOZydbFyWzoGK84wKDSLr3cM8MTeRe2dNoLbFyV9La/jZjhKmjotQl5AUfmqxdKTwyzqcnZTXOnh5SZq6n9YsLvYVK4pt2GOjo6sbRXH7tjfsseFwdtLZ3c3ZJqfajnYxEW1BEdG2JTac+3/9KZXn7bQ5u5k8xkzu4hmqWXzdvGSPvorFObR+cxEENj91nJqupfXLC3O9GD+gR+qct2cBetZzF98NxvtUrro1jBguAvJKCyYbLuM22AxEGIiX/qVeFlOcH3ybg/3plzezpK82tYLXH6EOX61ApV23uD/XICi01XkEYfV1Hfpt2tKe3iYN2gAsfXCbMJkDXoW19hhxLWJlq+Wz4vnhu0X86t40zjS08to/K8i99wa1sEhm8li2HfpSreXtLVBKG1Clzd8W+dOuzm61lKhYd1tEXHd2dxNqMuLq7FaFtlaY2mpaePSdQ1w/NkL1oeuX1szeWYrD2an6r4VvW4yH6Js2ShvcNcpXv32IDUtneES7a++HNsLeW1aAHm+TKREUONjvUbnq1jBhKPx/A0XkAF4JAnA4jdtg0t/r0vpo+1NkYTDHzZfvVJynr355qwCmLUDh7XziX1+CWrtN/F8b6KTfX5xP73PUUmir4/H8IlbMjvcpqHu7dzHh7iIjwi+rP9ZXnW/t8bmL0zwEta8qWEKICmGcEGNm6rgINu+r4NW95Tzz3amqP3dtpnuNZ23Edl9+fCEkRb/XL0xVBaboZ1KcW/BmL0hhVKhJXdgj0mxSa4yLYiN5e8uZEBmqlgjVpkupE655yUSaTTS3dairgOnHQ9RD37Q8ndUZFvU8k8aEqX5s0e/7N+9n6eufqAud6CuNiTF8ZOtBsvKL1FXERB67iDUQk6jlr+9XC6YMm/foQO3nF/t3tfqsL6Wv8Wriah23/l6XP75Z/f69+WIHm/74jLXffXy81q9+6v2IvR3jzZ8tfLnCV+nteOGf1PuM9f7IgYyp3q/tj59T7Jv+7Ice/nbt/5fmFfbwL398vNbDR6wdfzEGYjzE+H98vFa5f/N+ZeGmfepf2n/tUn3f+ra059OPi9aHrP+svQfacfhLcZVy43O7lWNVTUr+J5WK5ad/Vq5/+s+qX157H7R+Z30sgr5Ny0//rNz+//ao24TvWVz3saomZWleoTLjwrVq+9jb2HvD2zZ/nxUuwmcthbVEchEMh0nGcOiDwFtf/J2A+BL2/p6vN8Gi74dWgGmDmvSBRwNBG5CkDX7yta8QGv/+yj5VwGmDnfSBa6LdG5/b3eMatIJOtK895uE3Dyj5n1SqQWciUEwrXLXjJATfwk37vI7lsaomJe3ZXT2C+v5SXNVj4iSuQwST3b95v5L/SaXHdeuvXYyftyAy7Ti/9jdbD4GvHSPtd+LatW329sxpPx+ralInG/p76M9zczHCWprBJZIBcrWa7y+G3gK4+jIlxoQH9ygB2VdetNbPqE+/0vshtfXA1y9M9TDLiu/WZiZ5NV8LE2lvpnVtn8S1aOt/69F/ryio5T7FWtMx4cFEhQXz2+/PIiosmJwCq2pSFulZogSqSD1as61YHUNhrs9ekEKk2cT81HHkfOhO4VqdYSEqLFitAgbuYKys/CKs1c2qrzkzeSwn6uzU253qKmFiLBscLlxdXT3u4Y7iKjKTx6qBccI3fl2UmYQYs+qLnhAVSlBgAA0Ol8eCJ2szk6i3O3k8v4h3959SFzLR30dxvn3l9XR0davH19vdtdeFi0AQaTZxos6Ow9mprnQGeJRk1a/EpnXh6JdFvZRIYS2RDBC9P+tyCO3hPGHoT9/EPtooXm/bfbXr7V7o99Fu104CtPtpV13SvrCFEMvKL1LzgbXC1tv5osKC1Qhr/RiIJTLr7U41iEwIaJH3LAS9iGa21bRgb+9U12QWAVDZO0v5j7cP0tjqIirMPenQB96JqO5X/3GCSdFhamBYVn4R2TtLVf+2WF5TLLcpFvKYFB1Gg8Ol9llEmL+4u4z2DkX1FYvrnp86jqf/9DkVtQ7s7Z0ekxBwC2OTMYAXd5fh6uxWc7OjwoIxGQOICgtWhfv7R6rUFcpEbW/thCopzh35HhQYQE6BVV09a8XseHWVMXFPo8KCefvBm3htxTe8FkURx2mfE/0E0ttKab4q4w0qA1XJL/bvSjCDDyfzouTS0R9/sfb/l9J37KsfQ93mQH3wvdFXLrV+bPWmWl/n9eZ/7W0/bXvevtf7i4Vp2tu16n2+vq5b7CtMzXoftPC1fif370ras7uU+S/vVeZv+KdHm1rTbm8+d2Hu/vh4rYcrQPuv/jpFO/o8am0Os9bMrL1ukYMu2l+aV6j866/+rprftaZwrfleb3bW5pkLE7Q3P7bez63vk6/cd/0Y6Z+V/pi5+wJpBh98hrPGIunJYN0nf++7fr/LGTU62OfUX5v4t7e1ngfaN1/ajL4NfY1rbT+1Fc7En34VLf290e6njSjXa9zC9CpMrmJ73t5yrosye1gCtMeKc+q/12veom2haYoqY4LsnaUsnxVPdXM7z8+fxsP/Mokvz7d6REKL9LN185L///bePlaz6zrvW0dSNEWgoeNIk4RIJFuGKLMyE4nS2IgQIG0RoqVVQCQQ0pYJu1LiREACB5gkKC1VkC2RAVrJaDqtZNGeOETZAg7tsCiryhSHpWvXNDmUw0AehxLHGVoxY3kGmCsl5h1B4ciMTv+4d1+uu+5ae6/9dT7e9/kBF/fe991nf51z9rPX2l+HPAvBAxB+3v2WNxysvSbaO0bzLX/2OP3Qu95In/615+lbL++5kXlZw+z64IYOs9yDxyDsLMbrPJT7/zq/d/jiT956I/3RN/+Yvvmtl+mrf/Qf6I+++S36xKMX6PWvO0Y/9K430k/931+iZ/7Nv6NTD36RfuyffuHA3R7qiNfXA3/zB4jolRnmpx+/eGinsuDyD14HuYJAO4mNPw98XTq/l5NYzilKVb72B5Y1aEVrq7bUsp6DXulKq1RaLDVxSjyzpq265vniE8Ri9cKfF203q0CwNrXvrTQ0i4xbdNqENj4Bi9f7I+cvjSfvfezAcg4zth85f+lImrIcPG1ZL3yy122feuJgFzK+G5pWT4GQvrTG5S5h4fM773tyfMuHPzfe9unfHB98+oWDfPFyBgs9WM18Qh2fDMhnuod0ZHyyrlP3Td6XnPYkNwxhNjjYdjwuzp5p52xl6Y2zNt0SYgJUU46UK1ETM48bW6ah5VX7jAukJcbcdTqO45GZ3bFGP/x/15lzBz9c0LjAfeD+LxzaUjNcd/M9Zw+E7M77nhzfdc9jR5ZY8bq13ODSRczLEz7nS7usIYkgrG/+0OcORDfMquYdj7CdKJ/JHWaA8xnyvH7u+MyThwSab4361MWd8c77njy05ErWn9UBit2v1L1M4Xn/ZBiINQAC/uJOJdjW57mC2rpn3yPd3PikWMfqS1qDVnhPnXPRlY16WCJkeQt4p+HBp18Y3/qRRw4JjWW5WeWRImRZh+EzubaajxtbedXg48xa/jXr1KrT5y69eGBZy6Vkj5y/NN515tx4531Pjt/3048cCPk7PvboeOd9T6riyssYfsvx+6cu7ozf86HPjTf99KPjzR8/e9DJCB0c2QGyxp0990srd833MgzEGmwtqV5tb6HuJail+a4tb+v6siw9q1PAhSwmHtJKTKWrdRa050Na39zqe/DpF46Uw5N+iOupizvjW/YPnohNqgt/804LF0XtEAqZFv9bTsri8QfBDOuoU6LP74081IQf6sHXcL/jY2cPxR88APJvWe/cQg7xhrI9dXFnfNc9jx3qfHC3v/bsyE4O74BY97C15wpiDbaSHi/TmtKXTJ2fmnQskeKuZz5WboVrmV85dh6sb9lxSJ3kJa1YLrRSFL2dihAPF1YtP2EjEJ5fufkHT+eR85cOdjKT7mytfmQHYhxfGbvmJ5Dx+uEiy0WV/63N9pcub6t+Zbx8Mxn+PGleNk+nD2LdUayX0niC/sx9r+dOX5Lr5qtJp3TCWczCllahDC/jSKWhfZ6y6GNhNeHQ/g5Lu/jSKCkcsnMQOgZ8eZXMDx//lnkK1qgcE+bixYX2tk89Mb7j43vLwfiOZtqEv2Chyy1On7v0YnQsnYs2d3fL+QDymQh55W5yLV7tfkm3P49P21Eu9iy17gBDrBlLs3YAmArLwuv1Lnj3++Z5k3nSLCbNarXKork2Y2H5WLi0lmNud349FzHLwpXiK6+xZmfzCVrvOf3/HVrLLa1xWXdhnJeH52In1xrz/dGtWdXh+nHUZ8fLNLR7Ga69874nD6UnBTtcJ70C0iXO9/qW9aOtCOB5CF6HHIs5JeY5QKwFEGoQ2JZnwRKoFg1SLD2PZS1dkN7GL2ZZh++5y5cLjhY2WFpBEKS7mAuUVo/c0tNc9NKKjOVfc6tzEbnjM0+Ot33qiQPXstV54dZq2Hebj1HH6l12FoIA8jjDRiyyjPxv6TWQ9zLEe9NPfX78ix/7/EH9SvEP5ZYT0MJEtdge6LI8Wj7G8ZUZ8C0mn5Z0hiHWACh4X6ZNEPQcS0G7NraDmBbeCmd9JhvGlMhzMYo1qtKquvM+fScvbVmSbOjDGmY+cUnmSQqVJoCpsWVLRHmYYF1z97RMS4odt4B5mbX888/uOnNuvPnjZ8cHn37hIM0QZ1jrrXkw+LI0bgFL6zjkI4Tj+ZMu9TB0wO+pPNVL6yhK1z2vazkPwbKsS94fWNYAOKkV4pLecW2easNr19eUQYpQasKN9X3qu4Bm1cbyJSc8xcJb4p6yLkO+wkSpVDm0snLr/bZP/+b4zo+fVcUydoqVjI/PjNbuU8z9rJ0qpnVknrv04nj7p584NEnM6ljx9Pk2peGUreDGl+5pXh7uipbIToF1P6UXRQ5jcNHmn9/2qSeiHSWtU9ISiDXYSloJbazx752nFmWosaq12bDW37HPcsJLyyu1WQoXndTs3VAmTydNjmHzvFhCmhpvD+J115lzh3YEk+InBcMzI1nWFf+c50cTsPC5PEYyeBP4JDgrH5rbfxwPL6MKebztU0+ongt+7z1oZeZlkZZy7B7xoQKt3rXyYekWxBo0onXPl8db+qJOaVnX5rP3OlNPg2hZwnL2smYp8d/hb26JWnmSDT3/zsp/rFMkRZOXVxsflX9rlqMWvxQnuQ7bGre3xF6e+aw9CzJt+XmoT+6G1+6BxzuioVm/cr13bJkX/x3boY2XSctni7YGYg22ll5izePumUYLciwViccCrUVrbGNpBGGwZhnLuKS1mHKba2E4llBaHgiPZayNgcty8PTlMAG3SuUsbi5EV3ZfOrR1qbw+hNEsXV6X8toghjxPYWw7LOeSnQY5Hi1d8paQx+DxBbg3Q8YpJwLKTlesc+b5PBeINYgyhaDNQQ831Rxp1OBxC3uJiU3JtTELJxVvamJZuD64Ni1xtkTWijcIZWo9rmalWmXT8sjRrEKrQxPE+Kaf+vyh8Veeb209cQgTJpBJwXru0t4uZG//+KNHDvTg1isX+JP3Pjb+k19//lC6XAyD1c9ni2t1l1Pn4be0rK2xezmOLS3z1AoKWNYQ6wN6i0BPsVmCkE2R9lKF2mup5sRVYlHIMNJyswTTE68HeQqVFY+VFy0+rTwpsY6tEZcCGQjWLF8SFrP6xnE8tN+2tMiD9azV93OX9jZC0TwRYRez2z79m+okOy7c4bqQDj+PmqcX0tSGLmS+rU1VrLkKcre1VMfQ+i4VtvWcGIj1SplK7DbVsl4DU99bSxi9cWnWXczykJ9J0fJc482bzGfII3cZx67X8mWFk1Yg3zksJaYyj1d2j26QEgSGu/t5HJrgS/HU0te2Cw3p804BTyt0GEKc0lrVjqcM5Qgzv7WJa7KeQrzccg8WupYvXo/ynvD8STd3jrWs5de6rgQZN8R6xZQ+DJsgkptQhhilnbHa8CkL1oqfN/Zyj+lYfPL7UhH2lEGbsOX1LHgbYy2+kK41Y1rrnMhx5uBq5pO6uHCnrD3+ecxC1PIfRFa6tkNc2tKwK7svHRxiwmd6yyEKq+Mg/w9CHWZk8/qJnWam1a3sAPA8aGF5+aZYomXFDbHeMkpFYElsQhk8lAhv7dKvXPGWYS0RlPFZFpBXFFMWmBQOaVFpcUsRiuWdi49lFXL42K38XJv9HNLgG4eEsWtuXQbrWtsvXOY95Jnv6sWvsVzpsv6kYGlCFtIKQi3j035bf/N7KD0UfExfllubHCat6LA23HKjy5PKWszzKL0WYr1FWL3uNdKjDEuplxKRzrk21jiWjgXn5Jmn4xFIayxWiqQ2xpkax5WNN98hi+dJSyPmHtbQlv5IV7bMXxDWYNlyd3III/PJrUGtvrU8y86MFCUuhlZHQFqq4XdsPgO3tGW9p8biebiw3lu7X9r9DPcjeCl4pyKgdUyse+x9/j3vmAXEekuoeUg2HdlQzJ0XrYFIhS9tLLRGNJdYgxy7JohKanxbEx0tLvm3FYeVR80Ss3asCuGlZWx1OjTLWgsv/w6Tt4L7N2waol0rT8zS4g1uY+/69HBNEDX5bMqhBd4ZSK1dtuqYj0fzIzLl9eFeBa+D3KLVqldOWNf9zo+fNfd1j/0v8+KhtI2BWG8RcwtRT0rLZvW6p8BKL9fV5hV2mW6rDoplbXmsdM2qSllksXS066zlNikLSRMSLR0pPHKSFhdq7saNzYLn6QfLj4/byhOlnrq4M771I48cuHWtbTbDhCxrqZM1VBDKI7ch5d4ImWfrXsXuAxdp7bAObXZ4uK70uQ6Cb4XnHZ1ek8k8QKzB6qkVnTk6Mak85zQ0rcueElhv+l6rhP/NZ2h7LCPtO25hBvHQ3MaeeuMNtVzuo3VSglUoBU2zFi3h53FpJ0bx2eB8shX/WwohL4c2XGCFl3kL14UyyHXVof6tjWO0jg//7sru4T24tTqJzQvQ0kmReoblbPYcWrYtEGuwEcwhuB5yRKZHGrnXeRqumAjHOh/e8T/ufk3lSbtWumxjY5keuLjxSV3aGLQmuvz7YBG/6x57M5ZxHA8saL4silvMUnS5sElLUBM4/p02Q56XQ4r6Uxd3xrf8d78y3vTTnx9vvufsofHiK7uvnHUd2w1O3lNLFLVnzbKs5QqEnOcm9Z7yuvdS25GWQKzBVlL7AtX22GvibUGORcw/SzVqsfJq7k9rCEI2vl4LOFzLf2vWpXcinSbufJw65gGQVqQlgDJ8KDs/xSqkxZdvSRGXW3ZaLmOeJzmLWpZXxhvC8UlvXMh4XjUPg9ap0Mqv3SeZH8+2o7nvU6zjqeU5J75aINZg49FeulrXcYsee028NVjCm7KKW5RXE2XL6rZcjp77KS0hzZKL5VGbCa2tD7Y6HLxMliXPr03Nvg4u75vvOXtIJHlc0v0fu89hrNlaD8//9tYZz7vWUQp5lLPRZTitsyHTubJ7dBJdLG8e5L3Unqk5J6FCrEE35nqoZR5yZyp74+1Bi3hzhCh8lmqIchq81DWagGrWrna9lk9NCIPlpc2+9uSfiwJfqqXVVaxxD3mx6pxfK/MqZ1mHrT219KS1rU3c08qZOwYbq7dQhjvve/KQm59/d/Lex8bbPvXEoQNDrI5U7J3VxNr7vKTKkYpvLiDWoAtz90JlXnqE7ZmPmjS8Ll4ZvrZBS1kmWv6k4HnKIa04eZBDuPaR85cO7fbFRUyDu1ZlRyJcq03K0uoiVWdyC1LNrStnKGt1xMsrl27F8iqHClJpyO+1svITrLTDQHiZUunIz+S90/63Oku57533uhbvc04cNWL9KgKzs3P12qHfS+HE8WN07+030Ynjx2ZJn9eHNw87V6/RRx9+tnld7ly91i1uiafe+Xc8vKeeeDlkmWRcMh8XLu8e+fzE8WMH8eSUI6R74/XX0ekffgc9cO6FI/k4+eY/Tad/+B105omv0N0Pnaevf8Ou+52r1+gTj16gb7387UNxEBGdfvwiERH95K030unHL9LO1Wv09W8cvZ8yr6GO+P+cP/6P3z6IJxDyeOHyLp36pd8+lGcZP6/DU7fcQO9+yxsOpfGJRy/Qhcu7h+pr5+o1Ovf81+j99/8Wff53LtP77/+tgzA7V6/RqQe/SHc/dF69vztXr9HdD50/FIaX7YFzL+zV0ftuPpIXHubr37h25HnT6k6mIevxk3e8/VAd8OeFX5/TBoUyX7i8e6jOtHCnHvxi1fvsbROatBmlKl/7A8t6D+6iW4oVuwRivWzPtb3yMmceSq/zWDypdIPlGDvqMbd+LEuRh+ETnVJuX8tiDHnnf0srW4bn6fPJUHzTDulWD5+l9i23vBLadqNyD22ep2D5ynFjbY24Vh+x54J7JvichHCtd8lcbAtWzxGoubO3tXJok9zGMX10aW5ase9D+gQ3+LopdfVsOl6X6tR58YRtKe6lZecNe27+ebp8KQ4Xq1g+c8tjfabtpGW55q0dvfh2oFzorPByBnb4+6mLO+M7P3720HeaGKUmTWluX7nZyjgeHh6wlnjx+GT8Vn60Xcz491zc5BnWWhms9GOdJ97ZiD0vte+77LzIe+ZdqVBLiB9ivWIg0H561FVOI+H9LHzuFVlPOE/ZtcbbaghjDb028cpaaqPFW1oe6zNZBu3vmBXGhZlbWlwsONZyJW5Ja+mHa2N1pJUlWHhhC1KZ95AHKZwejxw/PIT/zy12bUcz6X3Q7qm2vptfE8ufXCPunRUu65L/ln/z/MSek9LOcAkQ65USa2BAf2JWmtfyayGyMpwlpKnrZeMYE4xYQ5oj7jmf5ZByT4ff2rpneY20lINAaWuPtfxrImalEVsXrYlbCPfg0y+oS6HkvZR5seqKX887JXI2Oj8Ig+dT65xoz76sD+6FCZ9bE9V4/q12UHuOZQfSmhAZ65Bq6UwBxHqlQKyPUtq7bpFerIee81ltfjwWU0rMZIMur5ENJv+sJL+xjkHsf43g/tWESxt/DO9RrMEPv4MVJ2dye/KlCYJMQy510ixO+ZzddebcePM9Zw9t0ZmqL63DoiHrUAq/tdxM1lEsD7JuHnz6hUNWO+8MxO6jFr+1M5vWKcipl7mAWE9Ejxu/tIdpTnJfsJYv5FJebtmYamhiZoXjbtPYVo5a+T2iEftOxpkzidJjWcvwKdHlYiXr2SuSMm+a+FmWqDzBiv+28i+tVu1z6xrr/moiG6uj1P3icXNxDp9zl7tMQ4uLw8VYdkBTz9Pc77IGxHoCltKYz0FKPHqkVRq+5HpP+aYqe42YWXHGrrHKL8Ultl469j8XodghCjnWm/Z5yhuhCakl1inR5aInZzWHmesy/1ygNJe5VfZg+fLOlta54NdYp4zJsWdNxLU6SlnA8nOPB8e7fj+27jp0cqakth2AWE/Etgr1XEvLSoQ31zL3zJaesqNWk0YXie4nAAAgAElEQVRJpyrWcMpGX0sn1rjy+pWblVgCaOVNxqU14tZyJC3f8thGWU5NzKx4uOv7rjPnDiZ0We8OF7CUZch3NYvNQufXyFPFtLkMmmhbeeOfxQ7oiNV7jns/FS7E51n+ZaVRQot2AGINulIiAi3SLF2ulBvec83SO2olnaoca4l/Zom49b8UQGuSlZaWDGOlGxsa0MQluGmtCUpBeLXORaq8cgyY58HKmxYvdy2n0uVxyYlsqXtldbKkC/oD93/hYFxdmxlvwZ+ZVD3GOkcyvPfdldfVCG5tOwCxBqvG2/CXxtsrfO94cuPydqosi9GTbsyqS6Vn/S+xlgqlsNyv/LjNINDhTGprvfFzl1482Bs7lhfZEbHExrJiY5PVZGciVXa+RCvlZZDpyfxqS/XC/8EtL48I9aSh1Y3WWeDfx2bYp9LM+XwKINZgtZRYhLnx5oRv0UFoMenFI6i58WrWo3a95WYu6VRxS1paalba0u3rKZf8X05sk7/lBiRaPFZ+5YxvzZLV8sTrIhZOzhXwWOVXdl8yDwix6ivWEeH5lWXnB5No8cawnrNU563Ea2SFnXqcmwOxBqtGWietyO0AtOqJW+WwhLImnDe8Fsa6XrM2rbF9T4fiyu4r65qttbE8vWC5yXXHqXLJzzVhsCZ2afHIfIYORDinmteh5jK2ngGr06QJpGZRhrxwSzpcl7JAQ7ryhK9Y/cr/Pc9B6p2xnrNUPnLeRa2z6V1J0QuI9YLIsTrAYbQGs7b+Wlyfa3HHrvFYPiFcTho5FpV1fSxtyxLMySs/rUmu/5YTye74zJPjOz72qGoBe9K3OiDecshr+MSxcBKYNeFLEzQrPe6Kl65yngfN2pZjxpZHRKYpOwIeLC+DFq/3nYk9jy2Rno/YssDeQKwb0bphz+1t1rIJHYOpXuCcvJSkn9NQea+RYVvEkUPMYozFHRpIzWUcCx9+NCs0VQ4pypr4eax2mSdN6LR64UJudUL5eDpPTxNubSexmBBr+fJ05rTvwhal1oQyTyfBg6eTWRIn73TFwqQ6hS2AWDeglTBoL1DL+GPpLnUduFUnJdf2pLSj0KI8uemlOoE96i0m1lbd8WukcKaujy030tKKXc+/C+JnuXNblZ93ULhFx7+XIsK/4/lNdZKsslqdIq3c2h7dIT/yXG6Zbs6Ethy8YpuKIxXOer5aA7FuRG9hWHv8JWjCssROhdXol1xXGrZE9L0ClhN/ruUlxVkKs1doNFerFPjY0iytDKmyeISfh09NDpN/h7F6PkY8juPBrl6ayEpRj9U7D+d171rxWh6HVAezdPa+jNvKq+WNkWVJpZPrmu8BxBosmlLRKIm7VVwlwukN6+np58SdsvTC/55x8pjQxzozXMxytu4M8T5y/lK0QeabYEgXdGpZlZUHrSOpiTcX1CBM2mlTlmUbrFU+G51vySkFM5anWN5zkJ0PK33tOuv/1H3Wwst5BbHvrbJadZTK+xxArMHG4X35eljpufHmiq93GYo1c1mm68mbFt7TMKbCa1aYp0HXBCI2iYm7kmPWr1We2DIeK14Zt5zoJdO16kzLKxd9fr2nM8LjyEXmOzUUIMOXWs/BlZ7qHGnXanFZ93rpQKzBKsgRvx7jxTl4402tAY01QF6Ls8TStcLwfMcOlvCUxdPh0ERTW18b6who1mYsHS2/1jWWxS4J9WWN6XrvuyxHaha5Vg6rDlPw8nqeQc39XNpxlB3PGoH1iPpSgVivhJwHai0Pnxfvy+lpRJaCFJUcsZThNHIs61zRCI22t5MhRTeV91g+w29LnMYxvS5ao8bSjNUxv8+pcWEe3mspxv638sTTSm3lyeGdtFQamrfD23FM5Zv/ln9vMhDrFZBrLa7FrZODt4GYutw16ZUKMf/eO0bosRRTyIbeex2/ptU9CpOvUmVPWe7hd2m+Yh2W1Gz0WHgtn6Voli0X65zlU95OjXa9tk95bpyt3dhraich1gumtPe4lAdwTcJZmt7cHaPcDlzuzmxaHDV5a7H7k1xjbKUVE72Ue9xjbXKxs76X+bbyyr+XeagVozDmq53oZVmqNVawhpzRLuPUlld5O5W1dbOU9jIFxHqhrO1BCrSwVtZEjiWUa0nnWK2p73jDnyOYNR1Gz9rd3DwEUi5WKcbWTl5Wep4jFHPKw9PU6kWWgS+FSm2r6fGayF3L+PIvLQ7rWQxxxfIgCWXmG7jIe+WZIZ9D7ruzhnYKYr1g1vAAceQLtqb81/bOU5NfctygnvCxeGNxtBBcLR3revl/yalb1nh3TGzkJLOcyVEpi1mG9dZvyorl34dtU3mnwRJ6fr211lnWR9ijXJtwFksjXKt1liwRl/fJWqJX2unNfdesPC69vYJYg6Ys/YHXqH1ZPTOOY59b3+c0NpZAl8aphZfCEJtx7okvRwwt6zm1yxYXC8/94ZatV9g9y7xiZbesYfmTWu52Zde/u5rs5KTui/xeljs2vKLlpbZznOrU1jznSwViDbaWUoszFVeLcLlpezoLpePVMq1wfRiHtCYOxdDGnbW0pGtYfl+6fEkLw0/20k750upAiz9VFm6dWnFacVhx8jrIub9aWXJWBmh5aInH4q4R/jUBsQZbyRyur55pehr6mKvSE7dm4ZWOf4/jeGSji1TaUphlnDyMJ05JsBj5j5aGtF69wh2zrK0d2FLELHrPfeWdkli+Y/GXPM+ea6z8tWCO978WiPWKWPqD5X0BpyZm7dTGkRvXnPfQso48Y+nc5Vxiocca/FyxjuU5fF86Nu5Zny7Pftbc4LHOkRVvzfvjFVgZ3ns/c+OP4X1+Qp208AhZ+VgTEOuVsPSeoCd/rcqQ43LLSTMlWLHvS6yicG3Le9rSypEWtWVNxuKSoiDDpCx+zb2v1ZllYVvfx/Lu2ePaskSl9dxiuRv/Lic+q05T9dMir7FrPJ0Y6963olcHoCcQ6xWx9AdrCsu6xGXozZd3cpCVp9yyecqS29DHxmxz6qukQdcaWG6VW2PAsY1FPBadR5xTk8Bk+FhZtTHnWJ2kvtPqKzc+GZe1Lav0kkxBqq6917XKh7fD0Jvc8kGsQROm7EjIBqhVfmoajtLyx4Qht/EOoqUd5uAZH5Zp3nnfk+qkLu1v6zPNGvZeZ01c0kQudla0jMNKS85y5tfLeqht6HmachJd7nI7GVf4/cj5S0fKE9uYpcc7HOsE53oK5LU1+Zjb8CkpO8QaVFPz0vVIt3V+PPH1KntqSYzHSs3ZIzvE+9ylF8d3fvzskbXJ3mVKLQji6TmLWBO3K7u+zU1CWrH1zmH3L41SAeAT2rT4tHJayDzwHcO0+6el08vabv3eaHXiuQexjvEcwLIGszDXS1BiWdf05HMshFaNQ8oqjIWPfZb6LrUFZKm3wVMn3Fq0xDp1LzRPQ25+QzzWEjPNqvXEHfLWan9z7fPYmLUU5xyxLvEqeOvFi9ah8cw1WNs4NQdiDYpY4wNvWYTesuRu/KBtoVhDSWNjpW1ZW7X5S+U1x1KM5d0701l6GGLpxPISW0vMl7HllDmWtqeeSuo41gnyCrV3vN66puezV9qBXAMQa5DNUnqoORak1eDmiEfupBQpOK1mwvPfqbDaeLXMS6vG0tsJyhFHK3xKxGQc1kYk3smKsY6epy6tzlIqzdwwVkfFClNCrmXNrfwez14tS8iDB4j1zKzlQZFMmW/txfY0nJJaV1wroa0lp4NhuWd73L+UgJaEz+3k8PDSkiuxrOV3nk1lUteETkLr54l3KHM6lx7vQk0eZT6WJtRLMDw8QKxnZE0Pylzwl91jucWsiSmXq+RQkqccy9JjbeWkm+tqLOlYedKMdb7kc1Mq1B+4/wuHTouKWYUy3ZBH7TjP2uV6Vl64e9u7Q1zp7mletL3ze7V9rd+lJQGxnpm1PChTEnPt1cS5RLHOFa2c+KQ41jbKfL10TGg8nQRu+VrxaHEGYucjy7+tmd6pmeJXdl86MhNcs/il+EiR1IYhtMl7PN6cNdwyL3w9+1MXd1ydq97vhZXX1mlssvEDsQaLoscLN5XbrTT+lLcgfF4q6i0sa+litdKT4mV5RGKir3WsNPHm1qq2RlrGKUXbM1M81qnQTp+yxJbfg3Bcp1X+2p3PpJWd2i899V1rer6HmyrU4wixXjRrefCW4MqKxdVjtrM3HcuCyonDk35pnLlxyf+lWGmuWUs8Y+VMWbz8Oz55LCXUsQMrUljWfqzzEsu/1oni35WKtZaO9RxYHafYNTJMDrXP4VraxB5ArBfKWlw6a8hnK6HK3RjluUsvjifvfezQxiKedFpTMnvXE0ZalJ5rvXFb4SyrM3XwRsyKTnWOLOFq9Vyljub01KnWEfHmV3ZyYh0Rfo0l8ql8ltbbGtqankCsF8xaHsq15LOWknLGrL0p0s9t4FJWrZYfbxreDo9njbCWD+uzlBVveQNyRTNWJiufMn98VzOPdRso2aY0hLEsbut/fh8skY+lV8O2tDUa3cWaiG4lot8loueJ6ENGmB8ioi8T0ZeI6BdTcW6LWIN1kWNdlqzZrhmz9nYYcsQ6FZcWxhMuNfHMY/HmdlDkdbwevPfVKot1gImWD22cP2cHtpw85j6vVkdA3o9ctlmAc+gq1kT0aiL6PSL6HiJ6LRGdJ6K3iTA3ENEXieg79///M6l4Idabx1pfWNnQew/MyJ1E5BUNS2Q0d2XMgo1ZgSV4T9ZKdWT4LGdr1ntNPmOC5N29jn8eJpN5hUwKX24nrUdYni8rntIjJ3Pzsc30Fut3E9FZ9v+HiejDIswniehv5SQMsd4s1vrCSkus5MCM3HQ8+x9r7lttRnAqDk1YaxpkuYxIilnA6vDIDpHcrztXrFp4DzydixK3sLznsbBWfB6LuQUtO0g54Xp4f5ZMb7G+g4h+gf3/Y0T0aRHm4X3BfpKIniaiW1PxQqw3j7W+SNL66VUOno5nuRH/reXTwjrpilt6OW5P7srVJiTJPap5ZyMVn2esVbs+pJE6VjNVJl6GWOciloZn1rtlucZ2U6vpWJVS0jko6bBq/+dev0aWINafI6L/k4j+BBG9mYj+gIj+lBLXB4noGSJ65k1vetMEVdOWNT8kMXqUa4q6ap3GVPe3xopJiZC1BIqLG/ceWOIrr0uJu5ZWrhXpQXoYNCvUEnJNJLTOTKpsPA7eUYldr91za2e02A5rsXrRrtfKYH2WEkPte+szTz5TYWPXr5UluMF/joj+Bvv/V4no+2Pxrs2y3oRenUaPcqWskZ5ptLIMcvJZKro1u1zFSG3hKePUBIS7bXMmq9V0RLzxe9YTa+VKbZeZGp7QJo1xkbY6CLE4teECj9jJz2ICr3VOct+fVGfEyosV1ya2pR56i/VriOgr+xZzmGD2fSLMrUT0wP7fb9i3rF8fi3dtYj2Oy+/VleZvKsu69UvqsQw8VkDNTGTLSvOQM7s4RwQtSy4nX7H/ZVpWXkuIiYFWJt7pSYlV7CCKILapXcv4HuPa8ala3XuHPGLl1joXnjj49yXPUgjn3ebWu4HQ0tvSXkyxdOs9RPSv92eFf2T/s3uI6L37fw9E9I/3l279KyJ6XyrONYr1kll6b7W3xSXTCX+nrBaPteBJs7T+PZZN7vIwbVOO3LQ9Fphl5abyZ4W11hmnZirLiXgpi9HaZzxmFV/ZPboPufbsyPyWbjvK49G2G/W+T17L2ZunGKld6MAEYt3jB2LdnqW+ILlCVmKlxuJqlS9PfDVolk9pHi0rNJaWNvNcK5cUklhnICZ+WvqpCVexMmt/a+G4JZ6yNC2rOUauoGr542lJr4GnAyPjSuU19ZmX1P7u2w7EGmQz9YvUw+WWG3fOtTlWZku0tErdqDKMx8sQfvP6jwlo7NhKbYtQT/q9CPnK2Vu8tMNUg6wjblVrHgFvXNp3tZvRlKS7zUCsQRZL7/mmLJicxqXEEk5ZgD2RZfOUL2d8PTcfcsIZJzVp67lLL0atv9rOmNfSDWHvOnNuvO1TT2TNVO+xnC9HYFNejh55KXlOgA+INchmzpes1hL2zp6NNXQ5Ip/jAk3lPfV9qxnuLdE29Ah1y7/jwsZdtSX1H8Jo4fg68tTRkTyuOz7z5HjzPWePbMSSus7zWc61sXF+qwPUgh5C32MlSYswSwViDVaD9wUvsYi1cJoLsTSemiVMteXuLdi5HQkp1locqYlfMSG0rFo5iSlY8N66zRFqKw6PpyXW8ZIdSFlHWgeolh7CGuJtGVfqHetVjqmAWIMu9HohSi3MWHjNEpZp1bgScywc3ujmuNAt8fJ4AWoasBwrl+czNcHMui4WNuYJCWibiHjXq7cY0vB2wLyfxzowXktzKRZpqScgXOfpEK9VqMcRYg06MGcPNlcYpTs0tQ1lyQzZ2HfSTZwjUFq+UtZlbp5lnrTPwt+pOpN/t7SErPis9L1ll3Hl5iuWRu7nreHPe3gOa70HLfKSe096zA1YIhBr0ISSXn2PPOROmIpZ1rHrctPXvuNbRsr1tV5kOVpPaNMa0ZJOjpXfVNolYppKv6R+cp5vmV6usNd0KHLhE/kefPqF8a0fecQU7FKrNyds7zTWDMQaVDOnJa3lxROm5Xge/7vWss7ZCEMT515l0sSKdypim1lY1m5qd7MciymWtuwgxTpGpR4VnpbWKYvlMVaWVAewBh53qI9Hzl9Khi2JH9QDsQZNyLEG56K1teLZ/cqTJ826T10j/7bcwKnrte88ZbLC8U6HDMfxjMl769UKIy1+KdBaHjzCqKWj1QH/vPS8Zy29VF5L4055HGD1zgvEOkFOw7mtrKEH3dpC4Y1wiVs1hA/nOZes39XiyhGVWBpWHLFwIe6nLu4cOdAjdr2Wp9yOVcqy1qx5zRvged8tgZez2+XzUTK8EStTjw5yjhehZZogDcQ6QurB7SFSa31w15DvFhaKJVCl5dcs61h+U59bAqhZfqk8pdLUOinh79z1yDKO3M08csPENmyJoQm8tU1mqedF61jw7z5w/xfGOz7zpDmhLhavJ+3YM8nz1+KdX0NHfylArBNM3cPEgzs9XlGIWbXeNLz5KXkWpCBrIuiJQ5tQZm0tGTtAw5O21ongYq11OuT1MXGLURJeCrxW5zJ/PJ8y37G0rPsflr1p4+05Exy1MCHe1Mzs3OcqFgfaOx8Q64Wx1ge39oWdm57uvxKrymMBa3mS4mXFFWuEY+5hrZFOeQVS5U+JssdbkLsu3SJ1nSaQ/MfqzGmbwuQcZCLz5xHRnO94vlKWtbymZPZ6a+t8G4BYg2pKX7zenoSS/PQix/rOyYdlgUmLzjORKlhUd505l9zPO1csvOXP7Sx5RD0VV+q6lFdA1ounQ5OqQ4/oe6h5B3LqoSSPLSzr3m3IkoBYgyaUNtI9hbpUWFqlnxu+1O2dWgI1jrpFqMX11MUddcJbsLqeurjjEpMSCy+kISeBlRATyRCv5sb3CjiPj5fXO06deiatcuec91zTifZ28Kzrc9IqGcLg6WyDUI8jxBp0ZO5eb6zB7NX45MZdk844xsVMs/w86VtucD6pKSVeubvAhet4RyHMKg8dhFw0wQmdAS4QqWcj1fGQ4pw6RjP1TMa8JTkrB1J518LwPHgt61pKlrXN3bbMAcQadKXWxdUzD96GrGQsdIpGxNNgleTbcpFb7nEtDu/kJJkm/wmbdGjju7n3gXciUtap7Ix4Ozkl+bLStb7XJpaVYnVma9aE1+QlN+w2CfU4QqxBR2qFeik9Z+9JRlYj4hHTUnrUjybUYSy7V2fFWqYUfsu/c9zLPHxq3L10o5QccqxtGaZlBzY2+XAJ753GktqFqYFYg24Nfu1LtYQX0mtZh3Bhn29vY9/aFV/jRbCua+kWzXULc1JC6xVWS/B5WUvyXOKpSaXjuS4nnlS43Pe2VNjX3i7MAcR6y+nZU53zpWohLLnX5uw3Lb/zNNQp92dM9GqWNeUKbKpDk3IBj+N46HATfq2sA8/EudxylYhdDzEtua5lJzkVx5Xdo6d2eePfVuu4Bog16PbSzNUBkI1B6uzk3Aa9Nn/aNanGK2eSWMqlXNpQpoTwyu4rE6CsxtsSAl6+sPnII+cvHbLqtWtiu5B5y2qJbk4dpcK3eBdqLebctHKet9zOIIQ6H4g16EKJKHgaBm+jELa7DL1/a7w1Ze1N5cqvbeB4xyS1jWZunrQG2QoXlnel1n5rQwXakq3UblqxmdcewdXucbiuZCMbT3lL8HpXcvKXuqbk3YXV3A+INehG7sueu5GFZQFJwZJhYo1qLL1cejVcWnmkJ6Embh5naqMUqwOl1bG1cYgMr91Pj1VvzRWw4tbyyj+r6WjmdCy9pDpMnrJ6qH1uIdR9gFiDalq9nCWuOssyspbnWA2etcd1+F06I7iHUKeWMtU0sprA1AwjcJ679GLSZaqJujURzCPgMr7YhiXWRiml9BAt6xmUp7fVdhZKO6et4gJHgVhvAT1flil64TmCyC3CnNm+2mYWqcZuLpefZfVZImTFwX/Lz63wpXBBSS2F04TVk09PmWJ/h9n8sTi89TDXM5Hb2WyZfu3mQyDOVor1Nj04U72opdd51paWjn3nWMKpsC1ErLRj4r0uJm5a2FoLMvc67bQoK6/BCg9hUrt2tShTbOewnLiXKFAt8pLTaW6dNthCsV7ii5RDS/fUEsgRsLnKkWuteuPwWCGWNyCWvrcTNI6Hx4NzOx45+QrpeDYdee7Si+PJex87mBQYxNqzdC23HDJ8bAvSnLhb7TImWfo7APqxdWI9jssWrxi1L8xayz2OeQLk/Tw3/dT3OfmLuQ0lpXsnx+IM8fJ1srlppMayQ9p3nTk33nzP2UPiK+PR4pYi2uPZlx6JmAWdI9S9JhaW5muKdwD0ZSvFes2UWg2b0DMucZdPWe6ae5NjtXvT0SxZ/p3cmawk/55DJa7svnRwGIcU4dj9KRVLGT71DGj3ofQ5sjbG8eY1N5wnX55ld2D5QKw3GPkib/qLOcWYWYllH/s+CJ73JKUcl3xqd6maesl5pkKen7q4M77rnseOrHm36qVmR7DcZ19LL7ezkDM0kEo7FtbzmSdPm9CB3yYg1htOzfjd2pnKDTmOaddnyoIsdXHHwkhLsZULWbqOc+LIPY/ZE6aV1Riz+HPqvISWHbWcuDfpfd90INbggE3qaXvH91o0fF6LqqVIpa6XQpOy3nPdv0GYasZ2S9As31yPRu598LwXte+Ot7OxCe8mKANiDQ6xSY2BbNiDaOU0wiVp1cZTuq1kLD8xq4+nmSu+XnFvAb9/OcMBcne3kpn9qU5OLIwnbu/GLyDNVJ3iqakR61cRKGbn6rW5s6By4vix4munLlMqvVCWnavX6KMPP0tf/8bR8PfeflNVmXPzlLr2xPFjdOqWG+j04xfNuDxpnDh+7FC4E8ePmeU8cfwY3Xv7TXTj9dep9RGrH+27VJ1euLybyn6SkOfUvePhdq5eo9OPX6RTt9wQvS48L7L+UuE8z5EWN9HROvOWb6nM1b5Z9VsabmMoVfnan7Vb1pvYa25VppxecU560mXayoKVcZXWgWYBesJ58tSSWLqe8nsOGilN33u9d3zYQ+nBGvxvtAXt028ZbikQ3ODzsKYHZa6xVk/4HHemDNtyPWzJBCorjlQ9eFyvV3bjJ2V58qF9HpvMpW3ZqsWXe/ZxKbF8trrnS91DfO6019S+rQWINYgydS85Jx2PqPG1xNoM5pwxR8/33olcKbzWX2pteW4+rPFTT740i7Glt6HVtS29Da07E94wvTsbENvlAbEGSVq/uC0bh9R1XCxiE5NSAievizWi1nepE6dKSDXmmtDmWu7eNeCePJTGURKPVQdLcDt78uF5VlvkoyRvYHog1g3ZtIe7R3ksy63X9oz8t/xcC++xNkryK93EtVaj53/ZAZHpp+INn5WKdSru3Os9+4Nr16U2O5mLXMt6yjJM0UGfOg9rB2LdiDX0RmtczC178aWWdU3+c65vnRfrmpK61e5L6v9AatvJXi5R77uRsjL5ec3hM08dzt3RqI0v1YlskUZPajq3SyrH3ECsG5L7ME5Fycsergu/a1+c2jhKGnyv9d6zMeeCYn3vseRj6Xk9BzXf5VBSx56xbSnOnkNIenc0ctMsEd2S3eJyr+kNLOt6INYzMGWvsdWL26Ih7G3hpFy2mpC36ERYe13zU61igqrdm5AvOeaeKldvajofsWtKXdwpb03LZ9+6R95OoYwvN31vmFBeKy89nxcIbD8g1jPR8qGucS/WpLk0N1VMrLUGNXV2sYfnLr04vuuex46MRT91cefQTHQZf8x1LfORanhzDgHxfmd1bFKHg/D85liCLcbFY3mpHbeO1f8cYmh1ELRnS17fy+peYpuwSUCsZ6a3m6532lNSKkhaHaWOjswVbPl/akOSkgbeKpv3mErveDWPU/vOc2hJbAmb97OW5Fq/1nXa9z23V9XS0uo/pyMS6/y1zjNoB8R6Rlq9MKVCvaZecG1+cwSiRZ1Y6bW0aCwrKzdPWhxyIldOOuH7GnGrtYJbhSmdGNerE25ZzKVp9GQtbctagFjPzJwPdMu0pyhHrVBP3cBJwbnrzLkjM5pz4+VlqV0Cl7K25f81rupcodfcui0ENrcTUNK5mroTvkRRXJsxMCfeOoJYg2qW/GLGXIdW+FRcHvG3XMvaGLb3tCtP+i2tUI+17Ym7xO0s0/Z0LFJ5489CjtXsHWaI/V9DLO7e715NvJtiiPQk5/5BrEETerwcuS7dVNgciy4WJiYe3BLzNODW+DYXFiv+nliWu/WdpGS3thyrWF7j7Yx5ZtfzuD1iXSuYuZ0++Vz0FOqldsJjrC3fsKyBi6U+0ClLquRlzLHsUvmyZnmn9ga34tKwJhLxyV85wpaDFrfXhVwjKCX59lrWOWnwZ6zFcyPD5HR8vJ6Y3Px4WGr7kGKt+Y4BsV4Zrd1rta7h1obpHnAAACAASURBVHnyxhtzh1rhW425xtzWuZZviXs1uNNja7hrlipZnYTSHbRqOlcl17Syqlp0ePjf3uVVsbg81yzdslxqvpYOxHpF1LyEpRaYxzW5hG0QU/kI4ubpAPDfWuPKv+N/T23teC3rnHsUs/ZzO0gc6YnwPHc5XoqSPPUk1WHK7dDluPpz4+8ZhxbnkjsSSwZivTJKhbrXmJr8PiUgc0yGiQmQFib85mJhWa/eMdCeZW/deOd0vDwWYhDesNNbjkdnikZ9Ds9QaVxTidzczys4CsR6S5iq0UtZQy3OEm7pWdDCeCxXLXwqzR7i1LIjlptfHibXszGnCJd6HVrmIfXdElh6/rYNiDUoxnKL9rKsc6yyufFanTy8Zx9x61rPZ7E8avkt2eO75vuWWPnXPm/RgZRpxPKQ+g4ADYj1htK7EShtbEotKyksuenNQUg7Z423R1w86caWXVlpasvEPGnlMLVgpzoyrUUzdLo8zzmEGuRQI9avInDAztVrc2fhgJ2r1+ijDz/bNU8njh+je2+/qejakvyF9E4cP0Ynjh8rSufC5d2i/JZy4vgx2rl6jU4/fpFO3XJDMt9a2Xi5c9Ll14R6uHB5V6338N3pxy8e+i6Vpvc+7ly9dvCjhQ//W/HUPMdaerxcJfWbQyzekjSX1M6AFVGq8rU/S7Osl+jSmmpMMLXzlvzbmrDVM4/juGc1/sA/+n+KXJ6xcd3c63tQMh7v/S6VTuxej+PRY0Itz0HLg1VieZ5zrLz2uiW2M2A6CG7wNmzbCxRzq8bGQXsdhajlTVIq1Lw8Mv9z3/fWYmZ9n0pHu+98Zr3HHRyLuwVLFrvY0IUMt01sW3ljQKyBiadhTl03tWWjdRBq0pVjunI8ssWmMrXUlC1nDX1OOWvrXYuzBUtu/HuOpcfSWipL7lzNAcR6gSyhgasR5Jo0W4STYpqzmYR1Pf87lZcpG90aPMMROfnuIaxLrbuetOroxOJfS72uIY9TAbFeGC3cmr22W7SEqWSWdiye2nA1Fp6M37PpidwDu2arz6mw6nEJz12L/Cw9rVgephDSXsMmoB8Q6wWyBMtaizO2ZrRFI+MVjpRQT5WPcdQnrk051ti6nDXbWc5hhS9tPLtHJ3kprMki30Qg1gtliS/ElGOzNQ3D1FZDauJabllKvQA511rhvUK9BO9PbEx9yucmXLsNYrbJZVs6EOsFcmW33azppb9cXnd2yfc518Ya/tq45WepMufc+9T4eC8vRAuhLfGcWGHlcMyU5Wo1FARAjBqxxqYoC0ZuQrHEzRTkJhmxzStS19akG9IKm2O0jjvEb31fc29iG3ykylGzIUiLTUSsDVJK6v7E8WMHG8+Ulqsm7Z4bqwBQTanK1/5sumU9jvWWHe/p507K6pXHmMVZYg21tn7niLv3hLRcN3frZ6QkLa+F2sqa9uTJe+2mu8HBfBDc4O1Y0qSZWCNdM7Go9JrcDsNUk7RKJ1NNnYcW+Ujdg5gLPnf5W0nevPmMXTc3S8gD2ExqxBpucEar/bhbxaPtMW3F32L/6Rg7V6+5wqdcxbF9pT150D6TwwQpt2zr4YRQN55wtc+FdPXn5NG7v3kJsmw5z5YcBpgb7PcNFkmpytf+wLJedvwyrRKLTJth7fUI5HgO5IYnsfhKLb5YmBazxHO9EJoFnZpYN+czOYU1PxdwnQMvBDc4sJir81EjikGIvDuNyVm8tWPZueOnPVzbue7uWPi53cy9xKxVR6lVXiDWIAXEGqh4G7OlWT1Xdl8a7zpzzr38qWX5NPFvFbc3ntJOh6czM5cFaNWn9VmrjhcPp5W95GCYnPgB4ECsgUmNe7lXHrzX5Iqs9bncerQ0rlTc1rU57uFaC3mJlnVI1+M9CB6D4Flp+WxqQl165Kon/iWzprxuEhBr4MI7Pmx91jLNlnhcxuNoN84lLn7r7xx3du79SFnIOfG1pMYNnWtZt35WWwl1L3rcO3gB5gNiDdx4LcuW5yu3sJBbXacJNT+Jy+N2je2SVmJZey3vEsu6d8M8ZcOf2xlaOz3Lton1tQYg1gtjqS9CcDF6xKFGNEsn/fRonDxxPXVx59BMcs8+4ePYZt1yieVdkob2d+611ndTPu89vUBLZJPLto3UiDXWWTemdi3xnPC88/XSOeSu3ZZrc611wC23DZVhHjj3Ap265Qa68frr6NQtN9Dpxy9GrwlrnFusW07VV4stML1bl0pi4bVnxRtnDVpaS1ib3YtNLhvIpFTla3+2ybJuaTG2tLJS30sXcas0Uum1rD/PNdrEI0/YOcfha+KtCV9rpa/VZb3GPIPlQbCsl4W281gLC6nVDlje74Olm7I0a/IYO8Qi9XlO/ClLORAs5pQ16Y1bXu89kKXHwRIpK/jC5d3oQSxW+b0s+bCMlPelxY6EANQw7Il9ItAw3EpE/zMRvZqIfmEcx//BCPfXieghIvr+cRyficV58uTJ8ZlnokGAgmxwUw1njpvSClvi6lxSg7xz9Rrd/dB5+uQdb8/aWlX7TKv/jz78bFKEQh6+9fK36bWveZU7L60I+QzufsmFy7v0o7/wBfreP3ecTr/v5ibPUyt6p+m5h0t7psE6GYbhX47jeLLo4pTpTXsC/XtE9D1E9FoiOk9Eb1PCHSei3yCip4noZCreTXaDTwVfk1o7QWkuF6V3JnRtGtqOaDnXe5aGeeJJzf72xFGah9SEuLBt61T58cQ51XAA3Nw2qJt2UM/Z4ET0biI6y/7/MBF9WAl3moj+ayL69U0T6yW/2DlLf3Liqll/mrOMKjUTutU6WJ5WicC0FNjWM+1TM8pbpN0qPyVxtu4Q8DSW9C4vkTXPM1givcX6DtpzfYf/f4yIPi3CvJOI/o/9vzdKrOXDuskPbyjbUxd3ind28ja2lhjzsCkxj/2vfRcaZ62h7mnBtXx+coRrime1t2UdC1Nbj8HjsonvcktQP+2YVayJ6FX7Av3dY0KsieiDRPQMET3zpje9qX/NNGLJlnVrUpZ17uzqXKsvJvSW4KXS0OLUPu/lTZjz+eF1tGnkeo20z0rFehPrE/RnVjc4EX0HEX2NiH5//+clIrqUsq7XYlmDVyi1ZmobVS3tEss69nlr123u9S3qKBa+932bkpbln+N+g+2lt1i/hoi+QkRvZhPMvi8SfqPc4JtAS+uqt3uz9HpZxhJrdopxeu262CRBLfwUwttbkFqMN7dKD5Y1mIoasU6usx7H8WUi+gkiOktEzxHRL4/j+KVhGO4ZhuG9qevBvIRlKRcu7zZZKxrbXSwWd4v0tSVr4W9eRp5W+NHSvnB591AcOevJW3Hi+DH65B1vdy/l4muVvWu2w3W5+eq1Jrpm3XJpvmJLskrygmVcYHJKVb72B5b1dMgJVq3jDhPFUkvIvEuDUmG0yWmhbKnJZHxMXk6i67W0qwe5FvnSsOYlzMHc6YPtgbCD2TrIsYT4NbH/PXAroNVOTHwzlntvvymZ/r2330Svf90x117dqTAnjh+j97/7u45Ywh99+NlDYbgVFizREPeN119HD/zNHzjYIKTGsp5jZy7NIl/TDlul+5X3zAsAi6ZU5Wt/ts2yDpbQXWfOuXvyrZf9hDhqsfLlPX6zNoyVXm3ca7GwtPH4nGdjSeXs4e0BYKkQLOvlc+L4MfrJW2+k177GX+XSYmthwdVcGzwDVr60bSxL0vfsX66llxt3bB/spSIt0fA/ke+ErpQlW3q6WQk870tmTR4LsLlArCfkxuuvy94TWjvUYg7C3tZ3P3Re3Se5V76shnIJh6KEeHqEtw4SiXXgcieoybhL6mSOyWJTsgQ3fQ1rzTc4CsR6YqY+vKHVNbmzlmNx8bH7uU47aiEUufnzzojX4o2dH10zM5qLNFH++dm19bhkoSZaR4fCYu0dDXAYiPWEWNZSr7RaW0le6y0WF7fQU+KlNZQekfdS2wDnNORhAtupW25wu/k9x4eWYol0zTGkczCFEK1RqInW3dEAR3EdkdmDbTsiUzuGz3u8Ygib+9JNdQ2/lujwTN/YumztyMlU/OGYx9OPX1xdQ7SU4yX5c0e0XjHKeX8AWAI1R2RCrBtjnXvMv0t9psW59EYpWMxE1PWs5lj98u97UppGbd5S18vvY8/NXGVozdLyA0CMGrGGG7whcictz2zjmklBS8I7pp1yY6fcmnxilXZtqP8cWg4VxD6vGT+MXW9NDos9N6VCvbQx0CW/EwC0BGLdEL6kKLVRSEncgakaSznBKUVqzFPrzFiTqEo4cfzYgYs8Z9Z1mOEeC8PTsAQwFleLiViWhZyaHNbqeVlDpxGATQVi3RjekPWwQnIFjVuyOddw4WllUWmdGR5vENsaMQhxe+P4+jfyZ2bXznyu6Yxon1ljz3wyX82SsVQeAMhhSZ6ZVVG6m0rtzzbsYDb3iUVy3+7Y3t3WNbUndnl2I5NpT3WUY2rnNa3sqdO8vLuvtXw2UkdAlu6YB0Brtv0Zo55HZPb62QaxXgKpQzy0l6fVkZo525DKtFOfyTRadyaseuGfPXfpxey0e22vWXO8J2fORnRbG/BtY5vvc41Yww2+4fAJWTE3qlzT22KWbckYsjUmm7MWOzePsTFmK62cddMBPr7ckpCXJaw9L2WJk9dAHzCUUgaWbgF1fXTLpWJe4efhrL9b5yG1vClWD1OvY58i3jmXQmEZFth0sHQLmKQsFTkJKTSYNULtWbKmXcNniPO/Wwi1ZbWlljfF6qHVbl+11mRLoZ7TuoVQA2ADsd5gPI0vXx9N9MrsbGupmEf8PWdWy//5THDugm45C71EdFtu72l9nltfudd76bU0q9VMdAC2mY0Q6017yadeFxsEUgsvrVxtGZB3HbKMj/9/4fLuoXFXKz+lzGm1yTrk5NaXpLXA9hDq0sNLAACvsPox69bjq3MTynPqlhvo9a8rO1ihR57CpKq7Hzp/aJeykvrXLPcWk9pyrs9Nq0XeiKhoL/jW4/ct42mZFsaswaaz1WPWa9xVKeZWDu7gTzx6IWszi5w0c74LeQq/5XaiJfUvw/L4S/HsRMbD5m4sU2v15XgKrDH7Vtbn1Fas974u7R2GlQ+WxOrFmmh5L3kMayIV58brrzuyz3bM9exJkwsZv/bc8187lJ+SBqp3/Xvz9K2Xv+0Kl9vBmNodb43Zt8rHGju4UwO3PFgaGyHWU9JyslNqJjJPUxvnLckLv/bC5V069Uu/Te9/93cRESW3ppyjActJ87Wv8T/OuUI1tbBZz8dSx6Y3DXRowNJY/Zj1lEw5Pi7TssZ5PfHI6/nfFy7v0o3XX3fwOVF8U5Q5xjo9afK8AwDAEtnqMespmbK3LdMqFWptKVYQQCI6EOrwefguti45ll4rrLzHwqYO5Vgy2hCF9j1Ig7oCmwjEWuCdbNU7HSutHLew1bnosRyotYtc5iEWb5iUl3s05lLgy9e0OsT4qR/UFdhU4AZnTOXmrk2nhSu6hzu7xxKjEJenvrhLPxYX0StLqIiW4TpPufynGn7YhOVTm1AGsJnADd6IWje3tzdfm45mKc8RhxVnLys7xs7V9GEWIV9E1HSHtBaklq9NJdRLqY8aINRgE4FYC2qEOqeha2111jSwvV3Yrah13cuZ+D3nIKxR8DADGoDlAjd4QzT32xQuuR5u8SW6EpeWp5jLepN21QPrY2nvCtgDbvAFYAl1qx2nYrTerENu3DIVU03u85DKS2rGPIQazMWmDGeAw0CsG2C9HC0a7dYvXs4scqKjrudeDUCqnKmlTTV5K5l9nbq3EGowF+gsbiYbL9ZT9C69O5G1jjuX3GVf2vKpmp3TUulZ5UwtbZJ5y8mfViZvnaMxXC7bblXi2dw8Nlqsp3JDE/leDk88uRuReNMIbvraWejegyjk/577ELNS7739Jrrx+uuinaKSGd5Wmfj/Fy7vuuKamm0XJAu4gcEmstFivSQ3tCeeWBiv0Kc21ajd6MS7m1iJpRojtbQpfOdZ5mXFrXHh8i69//7fWpxgx7wM2w7cwGAT2ejZ4LUzIltvVOEJH5uoZu0T7kmjtC5K8lxT761mtstzt2vi+vo3riU3W5mS8DycuuWG5vnCLGIA+rHVs8Fjbt8ayyNljZbE72kEYy7eINSp9cYhf960UxOpYpRY3zlxleI9LtOTn9e/blnixYcFWpJb/7DqwRLYludw1WLdavlMyfVTu9q4GziVbk6jWyuQLeuhZVw5x2VOkZ/W9MhT7jsDNzyYm216DlfvBq912124vEunH7/YfZ/u1u7pVvnqmYc52ZQyLbkcPYaBAMhlTc/VVrvBa8ekTz9+kU7dckOxUHt6dZ6JX/LzVHwpLHd4LKyH3LyWUhvvWl7eGEu3GmonKwLQgk141z2sXqxrqBn7y1kKpYWzrk81ajkzxls0kHzdsowvTORq3QBvSsNeulQvsGQ3fC6bVBYA5mCrxZqorFdWshTKEmRtfW/JWHlqyVSJ8AUxDoJ84vixYi9EDlM27D09AzVL9QKtNsNZAhBqAMpZ/Zj1XNSOCfcYZ4mNi5cuZeJLl/gSMiJKLiNbOnJJXI/4S5bqtc4DDhUBYBls9Zj1XOQItbVveCtC3LXj9xbhnGi+4Qi3ttdKbwu+dKle6zxAqAFYPxDrzvRuLL2uVG5V54xty/wvsdGvcfMusTyt2YYyArDpQKwnoHRc3PO9ZxyZW8DW2LaMg2+vqY2rt9gdrAWbMhkNAABiQKwXRph97Z0RHpafaWEvXN49Epc1A53HEfbDPvf818x8TinUS5kxXTpJDwAAaoFYL4ggrEQUncXNBYqPI3OC4H79G9eOiFlqBvqN119Hp3/4HfTAuRdmF5upZky3yEeLawAAQAOzwQVTTppKzRL3zuS1wl24vFu1f/TUu67l5mNqSvKxlLwDAOYHs8EdeI447GkJeSd1yYbds67ZcgWXHkARm13e21q0PAm1cbSgRHRzVg0AAIDFVoi190ziluOfvPFNbVhiXX/3Q+fp3s99uWjL0FJRTV0X25SlllY7rk3lem6VBtzlAIAUW+MG7+UStsJKt3TJBhnnnv8anXniK8Uzr0tdsLnXtdx4o4XbeArXc+vNRuAuB2DzgRvcQa1Q51g+2lIoj1DLfbcfOPcC/eStNxY34lMKfMtjMpcQhyeNlrPQIdQgBTwv283WiHUNuQ1zbDmVN43wf00nI5eaGc/ys20AAgumAkMlYCvc4Clrccp9updO7YznqfaiXmv9tgb1sD3gXq8fuMEj5Gww0pK5Xqracnjc9fJ/6e6fQqhhZaAetg0I9Xaz8WKdEo+1HXQQa5hD4+1ZppaKKxY/H1fvfUiJRsk920RBQz0AsD1svFgTpcWj1zre1g2jZ1nVqVtucI2Xe62y2HKzOcXCk2aqU7EJlMza38R6AGDT2QqxroU3bhcu77pFztsw5jSeKXF8/et8AsqFNmeIQNuq1MvUa6BDWmvznvQC9QDAeoFYK1gbmoRZ3jW7iklyxT8V5u6HzkfDyDzGBLRkFnwqvanEQvMCANQDAGsFYi0Igse33JSHZniXU3kma7UWfx63N4+pMX1vep5OB5813puphQnuZQBALyDWDnI3N/F+13ot9Ynje+dME1H2Ji4t0vZ2JjZx7HQTywQAWA4Qa0EQvNS6bOtvazZ27czpHMt1rrFJb3pz5a+nkGI8GADQE4i1Qkqo+Rg2F9DYbGxtC9LcPOWIQYv9tXsyh1D3tnwh1ACAXkCsM9HGsHkjfeP115mnUqWWVC1lvHdpLt0W+fB0dpZSXgAAkECsK9EE1BKE1JGYrZeElbIkl27L8no9JgAAsDQg1gzvmmjZqHu2NE0tqfIKZG8h5S79JTBVx6FnOugAAABqgVjvkzOBSzbqrRr6qcajLZZqXU7Vcegl1EusUwDAutiKU7ck1uk18vSo0sZbu/bC5d3qM7WnEC2c7NMe1CkAgAinbmWR2rErFSbFhcu7hzZVCfHlnm/tzXNriw2i0h7UKQCglq0Ta4/LutStvXP1Gn3i0Qv0rZe/3SS+1PW5nQq4YgEAYJ1spRu8JzkTtErdo+G63LQ++vCzdOqWG5rtmCbzAwBYN3iX+wI3+III669TlLra+S5psYM9rE1ZatzxsfzAagdg3eBdXjawrGcktxfLLWr+Wwv30YefNV3nrXvOvXrj6OUDMC145/oCy7qCmklftdSeBR07KcsaI+/xIvI4W/XKl9bLX0o+AOgJhHq5bLVYewTBmoE9tZAENzaR70StOV661ruNbeIuagAAUMLWu8Fjbp+p3ckxeF6IltsD3lQ32qaWCwAwHTVu8K0X6xRLaqSXlJdNJtWB85xpjvsEAJBgzLojPRvdXLeqRyRapr2Nbt/UBjSeYRO4zAEArXGJ9TAMtw7D8LvDMDw/DMOHlO//wTAMXx6G4XeGYfjVYRi+q31WN4vWu5KlROLC5V13WG+YTSQ1Oa/XhjpgO9m29wuUkxTrYRheTUQ/S0Q/SERvI6IfGYbhbSLYF4no5DiOf4mIHiKiT7bO6KbRaleyVHxEe0L9/vt/60CwITpxUvVScz0AgW3tEIMykmPWwzC8m4g+No7jf7X//4eJiMZx/O+N8DcT0afHcfwrsXjnGrNew3hijzxqB4msoS4A2GTwDm4Xvces/zwR/QH7/6v7n1n8OBF9viQzvendk20Vb4+XVxPq1BncrdgUy2FTygGWA4QaeGk6wWwYhh8lopNE9DPG9x8chuGZYRie2dnZaZm0ixLXbs4hGWtyacXqomVZ1lYvFptSDgDAOvGI9R8S0RvZ/39h/7NDDMNwCxF9hIjeO46j2qKN43hmHMeT4ziePHHiREl+q6ndNYx/x3+HTUss8VsTLcereVxrqwfONo/hAwDmxyPW/4KIbhiG4c3DMLyWiN5HRJ/lAfbHqX+e9oT6Svts9sUSEa2B3rl67chhGuEzfkgG/x3CLomUpdhSlIJQr90yhVADAOYiKdbjOL5MRD9BRGeJ6Dki+uVxHL80DMM9wzC8dz/YzxDR64jonw/D8NvDMHzWiG52pFjkiFYIS0R07+030Y3XX3cg5tKCDHHy065KBbuHwE1pKYZ6gGUKAABlbMUOZvyUKr59aOr0qlhcueEuXN6l049fLBozt7Y8XQNrzz8AALQC241GiAn01CJSukxj7cs71p5/AABoAcQ6AZ8EJj9vKSIyPogUAACAAPYGd6CNS7cUUj7ZjMgeC1/zBCsAAADzsBVi3XtyU5gJzpduWTPJ1z4juobccm9rPQEAgGQrxJroFSu6lwCE2eFamvz/cB71tpHbUdn2jg0AAHC2RqyJ/KdN5XzHl3N5aXna1lrweDd4+bHUCwAAXmGrxDolACVnGVvu7tw8bIMlmRJqWX4INQAA7LERs8Fbzrq24rJmlGvh7n7oPH3yjrdn52nbZ49ve/kBAJvNVs8Gb22Rxg62qMGTv20Xqm0vPwAAWKxerHPd0BxvuJzx0xPHjx2xqrfBxQ0AAKAfqxdrIn3/7pQw5gpojtVnzQKH5QgAAKCEjRizlpTu390LjMUCAADY6jFrDa8wTiXUcIEDAACoYSPFWtJKKEvigQscAABALRsv1q0s25p4INQAAABq2Mgxa0mrMeMpxp4xvg0AAJsJxqwTtBK/KYQa49sAAAAkWyHWS8MSY4xvAwAA0Nh6se5hxaYOA4lZzxBqAAAAkq0W6x5uZxmn5+APAAAAIMZWi3UP4eRxxk7qAgAAALxstVgT9RHOECesaAAAAC3YerHuDYQaAABALRBrAAAAYOFArAEAAICFA7EGAAAAFs7GiHXvXb+wqxgAAIC52Aix7r1NJ7YBBQAAMCcbc5BH7wMwcMAGAACAGnCQB/VfIgWhBgAAMBcbI9YAAADApgKxBgAAABYOxBoAAABYOBBrAAAAYOFArAEAAICFA7FuANZfAwAA6AnEuhJsmAIAAKA3EOtKcGY1AACA3kCsGwChBgAA0BOIdQab4OrehDIAAMC2AbF2sglj05tQBgAA2EY25iCPKdiEwzw2oQwAALBGcJDHRGyCyG1CGQAAYNuAWAMAAAALB2INAAAALByINWGGNAAAgGWz9WKNGdIAAACWztaLNXYgAwAAsHS2XqyJMEMaAADAsoFYAwAAAAsHYg0AAAAsHIg1AAAAsHAg1gAAAMDCgVgDAAAAC2e1Yo110QAAALaFVYo1NjIBAACwTaxSrLGRCQAAgG1ilWJNhI1MAAAAbA+rFWsAAABgW4BYAwAAAAsHYg0AAAAsHIg1AAAAsHAg1gAAAMDCgVgDAAAACwdiDQAAACwciDUAAACwcCDWAAAAwMKBWAMAAAALB2INAAAALByINQAAALBwtk6scawmAACAtbFVYo1zsAEAAKyRrRJrnIMNAABgjWyVWBPhHGwAAADrY+vEGgAAAFgbEGsAAABg4UCsAQAAgIUDsQYAAAAWjkush2G4dRiG3x2G4flhGD6kfH9sGIZf2v/+C8MwfHfrjAIAAADbSlKsh2F4NRH9LBH9IBG9jYh+ZBiGt4lgP05E/34cx7cQ0f9ERJ9onVEAAABgW/FY1j9ARM+P4/iVcRy/RUQPEtFtIsxtRPTA/t8PEdFfG4ZhaJdNAAAAYHvxiPWfJ6I/YP9/df8zNcw4ji8T0YtE9PoWGQQAAAC2nddMmdgwDB8kog/u/3ttGIZnp0x/C3kDEX1t7kxsAajn/qCO+4M67s/3ll7oEes/JKI3sv//wv5nWpivDsPwGiL6DiL6uoxoHMczRHSGiGgYhmfGcTxZkmngA3U8Dajn/qCO+4M67s8wDM+UXutxg/8LIrphGIY3D8PwWiJ6HxF9VoT5LBG9f//vO4jo/x3HcSzNFAAAAABeIWlZj+P48jAMP0FEZ4no1UR0/ziOXxqG4R4iemYcx88S0T8lov99GIbniejf0Z6gAwAAAKABrjHrcRwfIaJHxGc/xf5+iYjuHrBtQwAAA6lJREFUzEz7TGZ4kA/qeBpQz/1BHfcHddyf4joe4K0GAAAAlg22GwUAAAAWTnexxlal/XHU8T8YhuHLwzD8zjAMvzoMw3fNkc81k6pjFu6vD8MwDsOAWbUFeOp5GIYf2n+evzQMwy9Once142gv3jQMw68Nw/DF/TbjPXPkc80Mw3D/MAxXrOXJwx7/y/49+J1hGN6ZjHQcx24/tDch7feI6HuI6LVEdJ6I3ibC/F0i+rn9v99HRL/UM0+b9uOs4/+CiP7k/t9/B3Xcvo73wx0not8goqeJ6OTc+V7bj/NZvoGIvkhE37n//5+ZO99r+nHW8Rki+jv7f7+NiH5/7nyv7YeI/ioRvZOInjW+fw8RfZ6IBiL6y0T0hVScvS1rbFXan2Qdj+P4a+M4fnP/36dpb6088ON5jomI7qW9ffFfmjJzG4Snnv82Ef3sOI7/nohoHMcrE+dx7XjqeCSi6/b//g4iujRh/jaCcRx/g/ZWRlncRkT/27jH00T0p4ZhuD4WZ2+xxlal/fHUMefHaa9HB/wk63jfjfXGcRx/ZcqMbRieZ/mtRPTWYRieHIbh6WEYbp0sd5uBp44/RkQ/OgzDV2lvFdDfmyZrW0Vuuz3tdqNgXoZh+FEiOklE/9ncedkkhmF4FRH9YyL6wMxZ2QZeQ3uu8P+c9jxEvzEMw18cx/GPZs3VZvEjRPS/juP4Pw7D8G7a20PjpnEcvz13xraZ3pZ1zlalFNuqFJh46piGYbiFiD5CRO8dx/HaRHnbFFJ1fJyIbiKiXx+G4fdpbwzqs5hklo3nWf4qEX12HMc/Hsfx3xDRv6Y98QY+PHX840T0y0RE4zieI6L/hPb2DQftcLXbnN5ija1K+5Os42EYbiain6c9ocYYXz7ROh7H8cVxHN8wjuN3j+P43bQ3L+C94zgW7wO8pXjai4dpz6qmYRjeQHtu8a9MmcmV46njf0tEf42IaBiG/5T2xHpn0lxuPp8lov9mf1b4XyaiF8dxvBy7oKsbfMRWpd1x1vHPENHriOif78/d+7fjOL53tkyvDGcdg0qc9XyWiP7LYRi+TET/kYj+23Ec4Ylz4qzjf0hE/2QYhr9Pe5PNPgADKo9hGP4Z7XUq37A/9v/TRPQniIjGcfw52psL8B4iep6IvklEfyMZJ+4BAAAAsGywgxkAAACwcCDWAAAAwMKBWAMAAAALB2INAAAALByINQAAALBwINYAAADAwoFYAwAAAAsHYg0AAAAsnP8fpIk81ttsd6IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf-TNxQhogw_"
      },
      "source": [
        "**LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqFv0xMbozc6"
      },
      "source": [
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from scipy import stats\n",
        "\n",
        "def get_model_name(k):\n",
        "    return 'model_'+str(k)+'.h5'\n",
        "\n",
        "def LSTM_model(word_model):\n",
        "  pretrained_weights = word_model.wv.syn0\n",
        "  vocab_size, emdedding_size = pretrained_weights.shape\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, \n",
        "                      weights=[pretrained_weights]))\n",
        "  model.add(LSTM(units=emdedding_size,return_sequences = True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(units = emdedding_size, return_sequences=False))\n",
        "  model.add(Dropout(0.2))  \n",
        "  model.add(Dense(1,activation = 'sigmoid'))\n",
        "  return model\n",
        "#word_model = return_vectors_word2vec(train_df,1)\n",
        "#test_model = LSTM_model(word_model)\n",
        "#print(test_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJltjn1M3vQf"
      },
      "source": [
        "def word2idx(word, word_model):\n",
        "  return word_model.wv.vocab[word].index\n",
        "def idx2word(idx, word_model):\n",
        "  return word_model.wv.index2word[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxR2lzbH5i4n",
        "outputId": "d8cf4d76-2742-4865-a7b6-db010957c3e1"
      },
      "source": [
        "#word_model, vectors_returned = return_vectors_word2vec(train_df)\n",
        "word_model = Word2Vec.load('word2vec_model_rnn')\n",
        "sentences = splitkmer(train_df)\n",
        "#print(len(sentences[0]))\n",
        "max_sentence_len = len(sentences[0])\n",
        "train_x = np.zeros([len(sentences), max_sentence_len], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, word in enumerate(sentence):\n",
        "    train_x[i, t] = word2idx(word, word_model)\n",
        "print(train_x.shape)\n",
        "print(train_x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 45846/45846 [00:00<00:00, 141566.41it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(45846, 10)\n",
            "[[10  1 14 ...  1  4 48]\n",
            " [ 4  6 32 ... 31 54 12]\n",
            " [52  5 10 ... 52 52 34]\n",
            " ...\n",
            " [18 60 63 ...  6 13 12]\n",
            " [27 54  9 ... 19 44 26]\n",
            " [10 32  3 ... 30 38  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO5G_tMYwPD1",
        "outputId": "921aa8b5-1a6c-4a82-a1cc-b48f8aef685b"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "\n",
        "target_type = 3\n",
        "target_col = ''\n",
        "if target_type == 1:\n",
        "  target_col = 'Wt_Efficiency'\n",
        "elif target_type == 2:\n",
        "  target_col = 'eSpCas 9_Efficiency'\n",
        "else:\n",
        "  target_col = 'SpCas9-HF1_Efficiency'\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "X = train_x\n",
        "#X = np.array(X)\n",
        "\n",
        "\n",
        "\n",
        "Y = train_data[[target_col]]\n",
        "#Y = Y[indices]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "#print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45846, 10)\n",
            "(45846, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6d2wgpan-E4",
        "outputId": "dc46730c-f9ab-4bdb-e0ba-38985f471046"
      },
      "source": [
        "kf = KFold(n_splits = 5, shuffle=True, random_state=0)\n",
        "\n",
        "\n",
        "VALIDATION_CORR = []\n",
        "VALIDATION_LOSS = []\n",
        "save_dir_primary = 'Type' + str(target_type) + '/'\n",
        "save_dir = save_dir_primary + 'lstm/'\n",
        "'''\n",
        "try:\n",
        "    os.mkdir(save_dir_primary)\n",
        "except:\n",
        "    pass\n",
        "'''\n",
        "\n",
        "os.chdir(save_dir_primary)\n",
        "\n",
        "try:\n",
        "    os.mkdir('lstm/')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "os.chdir('lstm/')\n",
        "save_dir_2 = 'saved_models/'\n",
        "try:\n",
        "    os.mkdir(save_dir_2)\n",
        "except:\n",
        "    pass\n",
        "os.chdir('..')\n",
        "os.chdir('..')\n",
        "\n",
        "fold_var = 1\n",
        "\n",
        "for train_index, val_index in kf.split(X,Y):\n",
        "    X_train = X[train_index]\n",
        "    Y_train = Y.iloc[train_index]\n",
        "    X_val = X[val_index]\n",
        "    Y_val = Y.iloc[val_index]\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(Y_train.shape)\n",
        "    print(X_val.shape)\n",
        "    print(Y_val.shape)\n",
        "    \n",
        "    # CREATE NEW MODEL\n",
        "    model = LSTM_model(word_model)\n",
        "    # COMPILE NEW MODEL\n",
        "    model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "    \n",
        "    # CREATE CALLBACKS\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+save_dir_2+get_model_name(fold_var), \n",
        "                            monitor='val_loss', verbose=1, \n",
        "                            save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint]\n",
        "    # There can be other callbacks, but just showing one because it involves the model name\n",
        "    # This saves the best model\n",
        "    # FIT THE MODEL\n",
        "    history = model.fit(X_train,Y_train,\n",
        "                epochs=50,\n",
        "                batch_size=64,\n",
        "                callbacks=callbacks_list,\n",
        "                validation_data=(X_val, Y_val))\n",
        "    #PLOT HISTORY\n",
        "    #       :\n",
        "    #       :\n",
        "    \n",
        "    # LOAD BEST MODEL to evaluate the performance of the model\n",
        "    model.load_weights(save_dir + \"saved_models/model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "    results = model.evaluate(X_val, Y_val)\n",
        "    results = dict(zip(model.metrics_names,results))\n",
        "    \n",
        "    Y_pred = model.predict(X_val)\n",
        "    Y_val = np.array(Y_val).reshape(len(Y_val),1)\n",
        "    spearmancorr = (stats.spearmanr(Y_pred,Y_val))\n",
        "\n",
        "    VALIDATION_CORR.append(spearmancorr)\n",
        "    VALIDATION_LOSS.append(results['loss'])\n",
        "    \n",
        "    tf.keras.backend.clear_session()\n",
        "    \n",
        "    fold_var += 1\n",
        "\n",
        "print(VALIDATION_LOSS)\n",
        "print(np.mean(VALIDATION_LOSS))\n",
        "print(VALIDATION_CORR)\n",
        "print(np.mean(VALIDATION_CORR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36676, 10)\n",
            "(36676, 1)\n",
            "(9170, 10)\n",
            "(9170, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0289 - mean_squared_error: 0.0289\n",
            "Epoch 00001: val_loss improved from inf to 0.02205, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0289 - mean_squared_error: 0.0289 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
            "Epoch 2/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0202\n",
            "Epoch 00002: val_loss improved from 0.02205 to 0.01756, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
            "Epoch 3/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0184\n",
            "Epoch 00003: val_loss improved from 0.01756 to 0.01619, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
            "Epoch 4/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0172\n",
            "Epoch 00004: val_loss improved from 0.01619 to 0.01570, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 5/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0164\n",
            "Epoch 00005: val_loss improved from 0.01570 to 0.01520, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 6/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0159\n",
            "Epoch 00006: val_loss improved from 0.01520 to 0.01470, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 7/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0154\n",
            "Epoch 00007: val_loss improved from 0.01470 to 0.01412, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
            "Epoch 8/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0150\n",
            "Epoch 00008: val_loss did not improve from 0.01412\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 9/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0145\n",
            "Epoch 00009: val_loss improved from 0.01412 to 0.01337, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "Epoch 10/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141\n",
            "Epoch 00010: val_loss improved from 0.01337 to 0.01286, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "Epoch 11/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 00011: val_loss improved from 0.01286 to 0.01260, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 12/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00012: val_loss improved from 0.01260 to 0.01235, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 13/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 00013: val_loss did not improve from 0.01235\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00014: val_loss improved from 0.01235 to 0.01211, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 15/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126\n",
            "Epoch 00015: val_loss did not improve from 0.01211\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "Epoch 16/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 00016: val_loss did not improve from 0.01211\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 17/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 00017: val_loss improved from 0.01211 to 0.01207, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 18/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 00018: val_loss did not improve from 0.01207\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 19/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 00019: val_loss improved from 0.01207 to 0.01197, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0119\n",
            "Epoch 00020: val_loss improved from 0.01197 to 0.01185, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118\n",
            "Epoch 00021: val_loss improved from 0.01185 to 0.01153, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 22/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0117\n",
            "Epoch 00022: val_loss improved from 0.01153 to 0.01151, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 23/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0116\n",
            "Epoch 00023: val_loss improved from 0.01151 to 0.01140, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 24/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0115\n",
            "Epoch 00024: val_loss did not improve from 0.01140\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 25/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0113\n",
            "Epoch 00025: val_loss did not improve from 0.01140\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 26/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0113\n",
            "Epoch 00026: val_loss improved from 0.01140 to 0.01137, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 27/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0112\n",
            "Epoch 00027: val_loss improved from 0.01137 to 0.01129, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 28/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "Epoch 00028: val_loss did not improve from 0.01129\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 29/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "Epoch 00029: val_loss improved from 0.01129 to 0.01124, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 30/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "Epoch 00030: val_loss did not improve from 0.01124\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 31/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "Epoch 00031: val_loss did not improve from 0.01124\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 32/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0108\n",
            "Epoch 00032: val_loss did not improve from 0.01124\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 33/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0107\n",
            "Epoch 00033: val_loss improved from 0.01124 to 0.01107, saving model to Type2/lstm/saved_models/model_1.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0107\n",
            "Epoch 00034: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 35/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0106\n",
            "Epoch 00035: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 36/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0105\n",
            "Epoch 00036: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 37/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0104\n",
            "Epoch 00037: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 38/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
            "Epoch 00038: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 39/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
            "Epoch 00039: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 40/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0102\n",
            "Epoch 00040: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 41/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00041: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00042: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 43/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00043: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 44/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100\n",
            "Epoch 00044: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 45/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100\n",
            "Epoch 00045: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 46/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099\n",
            "Epoch 00046: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 47/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099\n",
            "Epoch 00047: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 48/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 00048: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 49/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 00049: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 50/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
            "Epoch 00050: val_loss did not improve from 0.01107\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0288\n",
            "Epoch 00001: val_loss improved from inf to 0.02065, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
            "Epoch 2/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0196 - mean_squared_error: 0.0196\n",
            "Epoch 00002: val_loss improved from 0.02065 to 0.01744, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 13ms/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
            "Epoch 3/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0176 - mean_squared_error: 0.0176\n",
            "Epoch 00003: val_loss improved from 0.01744 to 0.01641, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 13ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "Epoch 4/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0168\n",
            "Epoch 00004: val_loss improved from 0.01641 to 0.01565, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 13ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 5/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0162\n",
            "Epoch 00005: val_loss improved from 0.01565 to 0.01553, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 13ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0155\n",
            "Epoch 00006: val_loss improved from 0.01553 to 0.01474, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 00007: val_loss improved from 0.01474 to 0.01405, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 13ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
            "Epoch 8/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 00008: val_loss improved from 0.01405 to 0.01343, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "Epoch 9/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00009: val_loss improved from 0.01343 to 0.01306, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "Epoch 10/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 00010: val_loss improved from 0.01306 to 0.01278, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 13ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 11/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 00011: val_loss improved from 0.01278 to 0.01268, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "Epoch 12/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00012: val_loss improved from 0.01268 to 0.01262, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 00013: val_loss improved from 0.01262 to 0.01238, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 14/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 00014: val_loss improved from 0.01238 to 0.01218, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 00015: val_loss improved from 0.01218 to 0.01207, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 00016: val_loss did not improve from 0.01207\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 17/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0119\n",
            "Epoch 00017: val_loss improved from 0.01207 to 0.01204, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 18/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0119\n",
            "Epoch 00018: val_loss improved from 0.01204 to 0.01190, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 19/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0117\n",
            "Epoch 00019: val_loss improved from 0.01190 to 0.01166, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 20/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0115\n",
            "Epoch 00020: val_loss did not improve from 0.01166\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0114\n",
            "Epoch 00021: val_loss did not improve from 0.01166\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 22/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0113\n",
            "Epoch 00022: val_loss improved from 0.01166 to 0.01149, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 23/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0112\n",
            "Epoch 00023: val_loss did not improve from 0.01149\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 24/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "Epoch 00024: val_loss did not improve from 0.01149\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 25/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0110\n",
            "Epoch 00025: val_loss improved from 0.01149 to 0.01147, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0110\n",
            "Epoch 00026: val_loss improved from 0.01147 to 0.01139, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 27/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "Epoch 00027: val_loss improved from 0.01139 to 0.01129, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0108\n",
            "Epoch 00028: val_loss did not improve from 0.01129\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 29/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0107\n",
            "Epoch 00029: val_loss did not improve from 0.01129\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 30/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0106\n",
            "Epoch 00030: val_loss improved from 0.01129 to 0.01128, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 31/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0106\n",
            "Epoch 00031: val_loss did not improve from 0.01128\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 32/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0105\n",
            "Epoch 00032: val_loss improved from 0.01128 to 0.01123, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 33/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0104\n",
            "Epoch 00033: val_loss did not improve from 0.01123\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 34/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
            "Epoch 00034: val_loss did not improve from 0.01123\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 35/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
            "Epoch 00035: val_loss did not improve from 0.01123\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 36/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0102\n",
            "Epoch 00036: val_loss improved from 0.01123 to 0.01118, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 37/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0102\n",
            "Epoch 00037: val_loss did not improve from 0.01118\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 38/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00038: val_loss did not improve from 0.01118\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 39/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100\n",
            "Epoch 00039: val_loss did not improve from 0.01118\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 40/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099\n",
            "Epoch 00040: val_loss improved from 0.01118 to 0.01113, saving model to Type2/lstm/saved_models/model_2.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 41/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099\n",
            "Epoch 00041: val_loss did not improve from 0.01113\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 42/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 00042: val_loss did not improve from 0.01113\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 43/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 00043: val_loss did not improve from 0.01113\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 44/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 00044: val_loss did not improve from 0.01113\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 45/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096\n",
            "Epoch 00045: val_loss did not improve from 0.01113\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 46/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
            "Epoch 00046: val_loss did not improve from 0.01113\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 47/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096\n",
            "Epoch 00047: val_loss did not improve from 0.01113\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 48/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00048: val_loss did not improve from 0.01113\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 49/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00049: val_loss did not improve from 0.01113\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 50/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00050: val_loss did not improve from 0.01113\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0293 - mean_squared_error: 0.0293\n",
            "Epoch 00001: val_loss improved from inf to 0.02316, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
            "Epoch 2/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0198 - mean_squared_error: 0.0198\n",
            "Epoch 00002: val_loss improved from 0.02316 to 0.01735, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
            "Epoch 3/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0174\n",
            "Epoch 00003: val_loss improved from 0.01735 to 0.01693, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
            "Epoch 4/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0165\n",
            "Epoch 00004: val_loss improved from 0.01693 to 0.01601, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
            "Epoch 5/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0159\n",
            "Epoch 00005: val_loss improved from 0.01601 to 0.01530, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 6/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0154\n",
            "Epoch 00006: val_loss improved from 0.01530 to 0.01494, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 7/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0150\n",
            "Epoch 00007: val_loss improved from 0.01494 to 0.01425, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
            "Epoch 8/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 00008: val_loss improved from 0.01425 to 0.01375, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138\n",
            "Epoch 00009: val_loss improved from 0.01375 to 0.01336, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "Epoch 10/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0134 - mean_squared_error: 0.0134\n",
            "Epoch 00010: val_loss improved from 0.01336 to 0.01289, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "Epoch 11/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0131\n",
            "Epoch 00011: val_loss did not improve from 0.01289\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "Epoch 12/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00012: val_loss improved from 0.01289 to 0.01285, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 13/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127\n",
            "Epoch 00013: val_loss did not improve from 0.01285\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "Epoch 14/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 00014: val_loss improved from 0.01285 to 0.01256, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 15/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 00015: val_loss improved from 0.01256 to 0.01237, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 16/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 00016: val_loss did not improve from 0.01237\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 00017: val_loss did not improve from 0.01237\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 18/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 00018: val_loss improved from 0.01237 to 0.01214, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 19/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118\n",
            "Epoch 00019: val_loss improved from 0.01214 to 0.01206, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 20/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0117\n",
            "Epoch 00020: val_loss improved from 0.01206 to 0.01206, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 21/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0115\n",
            "Epoch 00021: val_loss improved from 0.01206 to 0.01186, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 22/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0114\n",
            "Epoch 00022: val_loss improved from 0.01186 to 0.01185, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 23/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0113\n",
            "Epoch 00023: val_loss did not improve from 0.01185\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0112\n",
            "Epoch 00024: val_loss improved from 0.01185 to 0.01174, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "Epoch 00025: val_loss improved from 0.01174 to 0.01159, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 26/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0110\n",
            "Epoch 00026: val_loss improved from 0.01159 to 0.01158, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 27/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "Epoch 00027: val_loss did not improve from 0.01158\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 28/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "Epoch 00028: val_loss did not improve from 0.01158\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0107\n",
            "Epoch 00029: val_loss improved from 0.01158 to 0.01146, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 30/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0106\n",
            "Epoch 00030: val_loss did not improve from 0.01146\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 31/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0105\n",
            "Epoch 00031: val_loss improved from 0.01146 to 0.01145, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 32/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0105\n",
            "Epoch 00032: val_loss did not improve from 0.01145\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
            "Epoch 00033: val_loss improved from 0.01145 to 0.01134, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 34/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
            "Epoch 00034: val_loss did not improve from 0.01134\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 35/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0102\n",
            "Epoch 00035: val_loss improved from 0.01134 to 0.01131, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 36/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0102\n",
            "Epoch 00036: val_loss did not improve from 0.01131\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 37/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00037: val_loss did not improve from 0.01131\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 38/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00038: val_loss did not improve from 0.01131\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099\n",
            "Epoch 00039: val_loss did not improve from 0.01131\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099\n",
            "Epoch 00040: val_loss did not improve from 0.01131\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 41/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 00041: val_loss did not improve from 0.01131\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 00042: val_loss did not improve from 0.01131\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 43/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
            "Epoch 00043: val_loss did not improve from 0.01131\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 44/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096\n",
            "Epoch 00044: val_loss improved from 0.01131 to 0.01126, saving model to Type2/lstm/saved_models/model_3.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 45/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096\n",
            "Epoch 00045: val_loss did not improve from 0.01126\n",
            "574/574 [==============================] - 10s 17ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 46/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00046: val_loss did not improve from 0.01126\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 47/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00047: val_loss did not improve from 0.01126\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 48/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00048: val_loss did not improve from 0.01126\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0094\n",
            "Epoch 00049: val_loss did not improve from 0.01126\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0094\n",
            "Epoch 00050: val_loss did not improve from 0.01126\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0113 - mean_squared_error: 0.0113\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0287 - mean_squared_error: 0.0287\n",
            "Epoch 00001: val_loss improved from inf to 0.02265, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.0226 - val_mean_squared_error: 0.0226\n",
            "Epoch 2/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0198 - mean_squared_error: 0.0198\n",
            "Epoch 00002: val_loss improved from 0.02265 to 0.01814, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
            "Epoch 3/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0177\n",
            "Epoch 00003: val_loss improved from 0.01814 to 0.01684, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
            "Epoch 4/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0166\n",
            "Epoch 00004: val_loss improved from 0.01684 to 0.01610, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
            "Epoch 5/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0159\n",
            "Epoch 00005: val_loss improved from 0.01610 to 0.01566, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 6/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0153\n",
            "Epoch 00006: val_loss improved from 0.01566 to 0.01503, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0148\n",
            "Epoch 00007: val_loss improved from 0.01503 to 0.01457, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 8/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 00008: val_loss did not improve from 0.01457\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 9/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
            "Epoch 00009: val_loss improved from 0.01457 to 0.01384, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "Epoch 10/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
            "Epoch 00010: val_loss improved from 0.01384 to 0.01322, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 00011: val_loss did not improve from 0.01322\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "Epoch 12/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 00012: val_loss improved from 0.01322 to 0.01299, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 00013: val_loss did not improve from 0.01299\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0123\n",
            "Epoch 00014: val_loss improved from 0.01299 to 0.01293, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "Epoch 15/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0121\n",
            "Epoch 00015: val_loss improved from 0.01293 to 0.01260, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 16/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0119\n",
            "Epoch 00016: val_loss improved from 0.01260 to 0.01246, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 17/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0117\n",
            "Epoch 00017: val_loss did not improve from 0.01246\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "Epoch 18/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0117\n",
            "Epoch 00018: val_loss improved from 0.01246 to 0.01232, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 19/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0115 - mean_squared_error: 0.0115\n",
            "Epoch 00019: val_loss improved from 0.01232 to 0.01200, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 20/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0114\n",
            "Epoch 00020: val_loss did not improve from 0.01200\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 21/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0112\n",
            "Epoch 00021: val_loss did not improve from 0.01200\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 22/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "Epoch 00022: val_loss improved from 0.01200 to 0.01198, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 23/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0110\n",
            "Epoch 00023: val_loss did not improve from 0.01198\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 24/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "Epoch 00024: val_loss improved from 0.01198 to 0.01186, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 25/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0108 - mean_squared_error: 0.0108\n",
            "Epoch 00025: val_loss did not improve from 0.01186\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 26/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0107\n",
            "Epoch 00026: val_loss improved from 0.01186 to 0.01169, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0106\n",
            "Epoch 00027: val_loss did not improve from 0.01169\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 28/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0105\n",
            "Epoch 00028: val_loss improved from 0.01169 to 0.01157, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 29/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0104\n",
            "Epoch 00029: val_loss did not improve from 0.01157\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 30/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0104\n",
            "Epoch 00030: val_loss did not improve from 0.01157\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 31/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0104\n",
            "Epoch 00031: val_loss improved from 0.01157 to 0.01154, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 32/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0102\n",
            "Epoch 00032: val_loss improved from 0.01154 to 0.01151, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 33/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00033: val_loss did not improve from 0.01151\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00034: val_loss did not improve from 0.01151\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 35/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100\n",
            "Epoch 00035: val_loss did not improve from 0.01151\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099\n",
            "Epoch 00036: val_loss did not improve from 0.01151\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 37/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099\n",
            "Epoch 00037: val_loss did not improve from 0.01151\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 38/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 00038: val_loss improved from 0.01151 to 0.01147, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
            "Epoch 00039: val_loss improved from 0.01147 to 0.01138, saving model to Type2/lstm/saved_models/model_4.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 40/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
            "Epoch 00040: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 41/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
            "Epoch 00041: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096\n",
            "Epoch 00042: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 43/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00043: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 44/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00044: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 45/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00045: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 46/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0093\n",
            "Epoch 00046: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 47/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0093\n",
            "Epoch 00047: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 48/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0092 - mean_squared_error: 0.0092\n",
            "Epoch 00048: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 49/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0092 - mean_squared_error: 0.0092\n",
            "Epoch 00049: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 50/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0091\n",
            "Epoch 00050: val_loss did not improve from 0.01138\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0287 - mean_squared_error: 0.0287\n",
            "Epoch 00001: val_loss improved from inf to 0.02161, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
            "Epoch 2/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.0195\n",
            "Epoch 00002: val_loss improved from 0.02161 to 0.01695, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 13ms/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0173\n",
            "Epoch 00003: val_loss improved from 0.01695 to 0.01601, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 13ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
            "Epoch 4/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0164\n",
            "Epoch 00004: val_loss improved from 0.01601 to 0.01542, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 5/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0156\n",
            "Epoch 00005: val_loss improved from 0.01542 to 0.01504, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 13ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 6/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0153\n",
            "Epoch 00006: val_loss improved from 0.01504 to 0.01476, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 7/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0147\n",
            "Epoch 00007: val_loss improved from 0.01476 to 0.01393, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "Epoch 8/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142\n",
            "Epoch 00008: val_loss improved from 0.01393 to 0.01344, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "Epoch 9/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0136\n",
            "Epoch 00009: val_loss improved from 0.01344 to 0.01314, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "Epoch 10/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 00010: val_loss improved from 0.01314 to 0.01279, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 11/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
            "Epoch 00011: val_loss improved from 0.01279 to 0.01250, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 12/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128\n",
            "Epoch 00012: val_loss did not improve from 0.01250\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125\n",
            "Epoch 00013: val_loss did not improve from 0.01250\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 14/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0124\n",
            "Epoch 00014: val_loss did not improve from 0.01250\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 15/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0122\n",
            "Epoch 00015: val_loss improved from 0.01250 to 0.01227, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 16/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0120\n",
            "Epoch 00016: val_loss improved from 0.01227 to 0.01205, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 17/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118\n",
            "Epoch 00017: val_loss did not improve from 0.01205\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 18/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0117\n",
            "Epoch 00018: val_loss improved from 0.01205 to 0.01180, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 19/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0116\n",
            "Epoch 00019: val_loss did not improve from 0.01180\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 20/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0114\n",
            "Epoch 00020: val_loss did not improve from 0.01180\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 21/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0113 - mean_squared_error: 0.0113\n",
            "Epoch 00021: val_loss improved from 0.01180 to 0.01164, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 22/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0112\n",
            "Epoch 00022: val_loss improved from 0.01164 to 0.01157, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 23/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "Epoch 00023: val_loss improved from 0.01157 to 0.01149, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 24/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "Epoch 00024: val_loss improved from 0.01149 to 0.01140, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 25/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "Epoch 00025: val_loss did not improve from 0.01140\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "Epoch 00026: val_loss did not improve from 0.01140\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 27/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "Epoch 00027: val_loss did not improve from 0.01140\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 28/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0107\n",
            "Epoch 00028: val_loss did not improve from 0.01140\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 29/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0106 - mean_squared_error: 0.0106\n",
            "Epoch 00029: val_loss improved from 0.01140 to 0.01128, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 30/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0105\n",
            "Epoch 00030: val_loss did not improve from 0.01128\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0105\n",
            "Epoch 00031: val_loss did not improve from 0.01128\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 32/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0104\n",
            "Epoch 00032: val_loss did not improve from 0.01128\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 33/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
            "Epoch 00033: val_loss did not improve from 0.01128\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0102\n",
            "Epoch 00034: val_loss did not improve from 0.01128\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 35/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00035: val_loss improved from 0.01128 to 0.01125, saving model to Type2/lstm/saved_models/model_5.h5\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 36/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00036: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0101 - mean_squared_error: 0.0101\n",
            "Epoch 00037: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100\n",
            "Epoch 00038: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 39/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099\n",
            "Epoch 00039: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 40/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 00040: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 41/50\n",
            "572/574 [============================>.] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
            "Epoch 00041: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 42/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096\n",
            "Epoch 00042: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096\n",
            "Epoch 00043: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 44/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00044: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 45/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096\n",
            "Epoch 00045: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 46/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0094\n",
            "Epoch 00046: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 47/50\n",
            "570/574 [============================>.] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
            "Epoch 00047: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 48/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0094\n",
            "Epoch 00048: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 8s 15ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 49/50\n",
            "573/574 [============================>.] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0093\n",
            "Epoch 00049: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 8s 14ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 50/50\n",
            "571/574 [============================>.] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0093\n",
            "Epoch 00050: val_loss did not improve from 0.01125\n",
            "574/574 [==============================] - 9s 15ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0112 - mean_squared_error: 0.0112\n",
            "[0.011074326001107693, 0.011131477542221546, 0.011257453821599483, 0.011381170712411404, 0.011247189715504646]\n",
            "0.011218323558568954\n",
            "[SpearmanrResult(correlation=0.8264045722670605, pvalue=0.0), SpearmanrResult(correlation=0.8300845036683472, pvalue=0.0), SpearmanrResult(correlation=0.8306026611592916, pvalue=0.0), SpearmanrResult(correlation=0.8278860241260154, pvalue=0.0), SpearmanrResult(correlation=0.8210074908210777, pvalue=0.0)]\n",
            "0.4135985252041793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN6K6sIZcmj-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "065e29ee-2519-4eb8-bec3-b7d71bbaab23"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "save_dir_primary = 'Type' + str(target_type) + '/'\n",
        "save_dir = save_dir_primary + 'lstm/'\n",
        "model = LSTM_model(word_model)\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "\n",
        "\n",
        "fold_var = 3\n",
        "model.load_weights(save_dir + \"saved_models/model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "\n",
        "sentences_test = splitkmer(test_data)\n",
        "max_sentence_len = len(sentences_test[0])\n",
        "test_x = np.zeros([len(sentences_test), max_sentence_len], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  for t, word in enumerate(sentence):\n",
        "    test_x[i, t] = word2idx(word, word_model)\n",
        "print(test_x.shape)\n",
        "print(test_x)\n",
        "\n",
        "X_ = test_x\n",
        "\n",
        "Y_ = test_data[[target_col]] # Y dataframe with single column; use iloc\n",
        "\n",
        "Y_pred = model.predict(X_)\n",
        "Y_ = np.array(Y_).reshape(len(Y_),1)\n",
        "spearmancorr = (stats.spearmanr(Y_pred,Y_))\n",
        "\n",
        "print(spearmancorr)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(Y_, Y_pred, s=0.1)\n",
        "plt.ylim((0,1))\n",
        "plt.xlim((0,1))\n",
        "savefigstring = 'lstm' + str(target_type) + '.png'\n",
        "plt.savefig(savefigstring)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "100%|██████████| 8091/8091 [00:00<00:00, 136378.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(8091, 10)\n",
            "[[36 51  8 ... 62 48 33]\n",
            " [42  4 10 ... 41 33 46]\n",
            " [11 34  1 ... 38 29 25]\n",
            " ...\n",
            " [27 37 35 ...  3 10 13]\n",
            " [18 41 25 ...  7  3 23]\n",
            " [ 4  0 39 ... 11 34  1]]\n",
            "SpearmanrResult(correlation=0.8290643983170092, pvalue=0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzYl84l8wwwt"
      },
      "source": [
        "**GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st0uz8XBwz0P"
      },
      "source": [
        "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from scipy import stats\n",
        "\n",
        "def get_model_name(k):\n",
        "    return 'model_'+str(k)+'.h5'\n",
        "\n",
        "def GRU_model(word_model):\n",
        "  pretrained_weights = word_model.wv.syn0\n",
        "  vocab_size, emdedding_size = pretrained_weights.shape\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, \n",
        "                      weights=[pretrained_weights]))\n",
        "  model.add(GRU(units=emdedding_size,return_sequences = True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(SimpleRNN(units = emdedding_size, return_sequences=False))\n",
        "  model.add(Dropout(0.2))  \n",
        "  model.add(Dense(1,activation = 'sigmoid'))\n",
        "  return model\n",
        "#word_model = return_vectors_word2vec(train_df,1)\n",
        "#test_model = LSTM_model(word_model)\n",
        "#print(test_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn5PczIhC877"
      },
      "source": [
        "def word2idx(word, word_model):\n",
        "  return word_model.wv.vocab[word].index\n",
        "def idx2word(idx, word_model):\n",
        "  return word_model.wv.index2word[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaC-9kP5zYAu",
        "outputId": "7f3cdba2-2fc2-4823-c395-b036c673a005"
      },
      "source": [
        "#word_model, vectors_returned = return_vectors_word2vec(train_df)\n",
        "word_model = Word2Vec.load('word2vec_model_rnn')\n",
        "sentences = splitkmer(train_df)\n",
        "#print(len(sentences[0]))\n",
        "max_sentence_len = len(sentences[0])\n",
        "train_x = np.zeros([len(sentences), max_sentence_len], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, word in enumerate(sentence):\n",
        "    train_x[i, t] = word2idx(word, word_model)\n",
        "print(train_x.shape)\n",
        "print(train_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 45846/45846 [00:00<00:00, 79983.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(45846, 10)\n",
            "[[10  1 14 ...  1  4 48]\n",
            " [ 4  6 32 ... 31 54 12]\n",
            " [52  5 10 ... 52 52 34]\n",
            " ...\n",
            " [18 60 63 ...  6 13 12]\n",
            " [27 54  9 ... 19 44 26]\n",
            " [10 32  3 ... 30 38  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rcIl_vAzy41",
        "outputId": "6dc040cf-cf8c-424c-d620-7617d08aaf78"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "\n",
        "target_type = 3\n",
        "target_col = ''\n",
        "if target_type == 1:\n",
        "  target_col = 'Wt_Efficiency'\n",
        "elif target_type == 2:\n",
        "  target_col = 'eSpCas 9_Efficiency'\n",
        "else:\n",
        "  target_col = 'SpCas9-HF1_Efficiency'\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "X = train_x\n",
        "#X = np.array(X)\n",
        "\n",
        "\n",
        "\n",
        "Y = train_data[[target_col]]\n",
        "#Y = Y[indices]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "#print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45846, 10)\n",
            "(45846, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApmNPOfn0LTg",
        "outputId": "00839e60-71ca-4241-a084-6fb04ec063c9"
      },
      "source": [
        "kf = KFold(n_splits = 5, shuffle=True, random_state=0)\n",
        "\n",
        "\n",
        "VALIDATION_CORR = []\n",
        "VALIDATION_LOSS = []\n",
        "save_dir_primary = 'Type' + str(target_type) + '/'\n",
        "save_dir = save_dir_primary + 'gru/'\n",
        "\n",
        "'''\n",
        "try:\n",
        "    os.mkdir(save_dir_primary)\n",
        "except:\n",
        "    pass\n",
        "'''\n",
        "\n",
        "os.chdir(save_dir_primary)\n",
        "try:\n",
        "    os.mkdir('gru/')\n",
        "except:\n",
        "    pass\n",
        "os.chdir('gru/')\n",
        "save_dir_2 = 'saved_models/'\n",
        "try:\n",
        "    os.mkdir(save_dir_2)\n",
        "except:\n",
        "    pass\n",
        "os.chdir('..')\n",
        "os.chdir('..')\n",
        "\n",
        "fold_var = 1\n",
        "\n",
        "for train_index, val_index in kf.split(X,Y):\n",
        "    X_train = X[train_index]\n",
        "    Y_train = Y.iloc[train_index]\n",
        "    X_val = X[val_index]\n",
        "    Y_val = Y.iloc[val_index]\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(Y_train.shape)\n",
        "    print(X_val.shape)\n",
        "    print(Y_val.shape)\n",
        "    \n",
        "    # CREATE NEW MODEL\n",
        "    model = GRU_model(word_model)\n",
        "    # COMPILE NEW MODEL\n",
        "    model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "    \n",
        "    # CREATE CALLBACKS\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+save_dir_2+get_model_name(fold_var), \n",
        "                            monitor='val_loss', verbose=1, \n",
        "                            save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint]\n",
        "    # There can be other callbacks, but just showing one because it involves the model name\n",
        "    # This saves the best model\n",
        "    # FIT THE MODEL\n",
        "    history = model.fit(X_train,Y_train,\n",
        "                epochs=50,\n",
        "                batch_size=64,\n",
        "                callbacks=callbacks_list,\n",
        "                validation_data=(X_val, Y_val))\n",
        "    #PLOT HISTORY\n",
        "    #       :\n",
        "    #       :\n",
        "    \n",
        "    # LOAD BEST MODEL to evaluate the performance of the model\n",
        "    model.load_weights(save_dir + \"saved_models/model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "    results = model.evaluate(X_val, Y_val)\n",
        "    results = dict(zip(model.metrics_names,results))\n",
        "    \n",
        "    Y_pred = model.predict(X_val)\n",
        "    Y_val = np.array(Y_val).reshape(len(Y_val),1)\n",
        "    spearmancorr = (stats.spearmanr(Y_pred,Y_val))\n",
        "\n",
        "    VALIDATION_CORR.append(spearmancorr)\n",
        "    VALIDATION_LOSS.append(results['loss'])\n",
        "    \n",
        "    tf.keras.backend.clear_session()\n",
        "    \n",
        "    fold_var += 1\n",
        "\n",
        "print(VALIDATION_LOSS)\n",
        "print(np.mean(VALIDATION_LOSS))\n",
        "print(VALIDATION_CORR)\n",
        "print(np.mean(VALIDATION_CORR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36676, 10)\n",
            "(36676, 1)\n",
            "(9170, 10)\n",
            "(9170, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - 7s 9ms/step - loss: 0.0304 - mean_squared_error: 0.0304 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01512, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 2/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01512 to 0.01431, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01431 to 0.01395, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 4/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01395 to 0.01352, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 5/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01352 to 0.01293, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01293 to 0.01265, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01265 to 0.01257, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01257 to 0.01227, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01227\n",
            "Epoch 10/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01227 to 0.01211, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01211 to 0.01199, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 12/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01199 to 0.01192, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01192 to 0.01170, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01170 to 0.01157, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01157\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01157 to 0.01155, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01155\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.01155 to 0.01142, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 19/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01142\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01142 to 0.01135, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01135 to 0.01133, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 22/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01133 to 0.01129, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 23/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01129\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01129\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01129\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.01129 to 0.01123, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01123\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01123\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.01123 to 0.01104, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.01104 to 0.01092, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01092\n",
            "Epoch 32/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.01092 to 0.01088, saving model to Type2/gru/saved_models/model_1.h5\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01088\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01088\n",
            "Epoch 35/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01088\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01088\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01088\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01088\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01088\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01088\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01088\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01088\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01088\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01088\n",
            "Epoch 45/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01088\n",
            "Epoch 46/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01088\n",
            "Epoch 47/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01088\n",
            "Epoch 48/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01088\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01088\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01088\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - 7s 8ms/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01584, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 2/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01584 to 0.01579, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01579 to 0.01406, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 4/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01406 to 0.01378, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 5/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01378 to 0.01378, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01378 to 0.01377, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01377 to 0.01290, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01290 to 0.01277, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01277\n",
            "Epoch 10/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01277 to 0.01267, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01267 to 0.01239, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 12/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01239 to 0.01232, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01232\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01232 to 0.01227, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01227\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01227 to 0.01211, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01211 to 0.01197, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01197\n",
            "Epoch 19/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01197 to 0.01194, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01194 to 0.01169, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01169\n",
            "Epoch 22/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01169\n",
            "Epoch 23/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01169 to 0.01158, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.01158 to 0.01152, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01152\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01152\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01152\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.01152 to 0.01147, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.01147 to 0.01145, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.01145 to 0.01143, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01143\n",
            "Epoch 32/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01143\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.01143 to 0.01137, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.01137 to 0.01124, saving model to Type2/gru/saved_models/model_2.h5\n",
            "Epoch 35/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01124\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01124\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01124\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01124\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01124\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01124\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01124\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01124\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01124\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01124\n",
            "Epoch 45/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01124\n",
            "Epoch 46/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01124\n",
            "Epoch 47/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01124\n",
            "Epoch 48/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01124\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01124\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01124\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.0112 - mean_squared_error: 0.0112\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - 7s 8ms/step - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01533, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 2/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01533 to 0.01451, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01451 to 0.01383, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 4/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01383 to 0.01356, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 5/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01356 to 0.01343, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01343 to 0.01312, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01312 to 0.01309, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01309\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01309 to 0.01289, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 10/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01289 to 0.01263, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01263\n",
            "Epoch 12/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01263 to 0.01256, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01256\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01256 to 0.01222, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01222\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01222 to 0.01214, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01214\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01214\n",
            "Epoch 19/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01214 to 0.01202, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01202 to 0.01190, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01190 to 0.01190, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 22/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01190\n",
            "Epoch 23/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01190\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.01190 to 0.01173, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01173\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01173\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01173\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01173\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01173\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.01173 to 0.01160, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01160\n",
            "Epoch 32/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01160\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.01160 to 0.01157, saving model to Type2/gru/saved_models/model_3.h5\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01157\n",
            "Epoch 35/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01157\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01157\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01157\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01157\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01157\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01157\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01157\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01157\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01157\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01157\n",
            "Epoch 45/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01157\n",
            "Epoch 46/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01157\n",
            "Epoch 47/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01157\n",
            "Epoch 48/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01157\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01157\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01157\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.0116 - mean_squared_error: 0.0116\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - 7s 8ms/step - loss: 0.0300 - mean_squared_error: 0.0300 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01693, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 2/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01693 to 0.01634, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01634 to 0.01444, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 4/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01444 to 0.01410, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 5/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01410 to 0.01370, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01370 to 0.01343, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01343 to 0.01336, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01336 to 0.01309, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01309 to 0.01294, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 10/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01294 to 0.01291, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01291 to 0.01284, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 12/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01284 to 0.01282, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01282 to 0.01262, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01262 to 0.01249, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01249 to 0.01245, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01245\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01245 to 0.01232, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01232\n",
            "Epoch 19/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01232 to 0.01229, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01229 to 0.01206, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01206\n",
            "Epoch 22/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01206\n",
            "Epoch 23/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01206 to 0.01202, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.01202 to 0.01202, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.01202 to 0.01199, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01199\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.01199 to 0.01186, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.01186 to 0.01185, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01185\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01185\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01185\n",
            "Epoch 32/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01185\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01185\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01185\n",
            "Epoch 35/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01185\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01185\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01185\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01185\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01185\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.01185 to 0.01167, saving model to Type2/gru/saved_models/model_4.h5\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01167\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01167\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01167\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01167\n",
            "Epoch 45/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01167\n",
            "Epoch 46/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01167\n",
            "Epoch 47/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01167\n",
            "Epoch 48/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01167\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01167\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01167\n",
            "  1/287 [..............................] - ETA: 4s - loss: 0.0102 - mean_squared_error: 0.0102(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - 7s 8ms/step - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01561, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 2/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01561 to 0.01469, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01469 to 0.01359, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 4/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01359 to 0.01325, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 5/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01325 to 0.01304, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01304 to 0.01276, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01276 to 0.01259, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01259 to 0.01242, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01242\n",
            "Epoch 10/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01242\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01242\n",
            "Epoch 12/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01242 to 0.01240, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01240 to 0.01217, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01217\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01217\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01217 to 0.01196, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01196\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01196\n",
            "Epoch 19/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01196 to 0.01187, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01187 to 0.01170, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01170\n",
            "Epoch 22/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01170 to 0.01166, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 23/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01166\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01166\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01166\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.01166 to 0.01162, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - 4s 8ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01162\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01162\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01162\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.01162 to 0.01152, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01152\n",
            "Epoch 32/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01152\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.01152 to 0.01145, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01145\n",
            "Epoch 35/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01145\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01145\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01145\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.01145 to 0.01140, saving model to Type2/gru/saved_models/model_5.h5\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01140\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01140\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01140\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01140\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01140\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01140\n",
            "Epoch 45/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01140\n",
            "Epoch 46/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01140\n",
            "Epoch 47/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01140\n",
            "Epoch 48/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01140\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01140\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01140\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
            "[0.010882575064897537, 0.011238827370107174, 0.011571399867534637, 0.01166907511651516, 0.01140265166759491]\n",
            "0.011352905817329884\n",
            "[SpearmanrResult(correlation=0.8297205845706136, pvalue=0.0), SpearmanrResult(correlation=0.8279561746016579, pvalue=0.0), SpearmanrResult(correlation=0.8251516845812216, pvalue=0.0), SpearmanrResult(correlation=0.8231897710631415, pvalue=0.0), SpearmanrResult(correlation=0.8165454432101512, pvalue=0.0)]\n",
            "0.41225636580267855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "CbbtPHfi73Ip",
        "outputId": "686b2e81-6369-496a-9f86-cda596669266"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "save_dir_primary = 'Type' + str(target_type) + '/'\n",
        "save_dir = save_dir_primary + 'gru/'\n",
        "model = GRU_model(word_model)\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "fold_var = 3\n",
        "model.load_weights(save_dir + \"saved_models/model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "\n",
        "sentences_test = splitkmer(test_data)\n",
        "max_sentence_len = len(sentences_test[0])\n",
        "test_x = np.zeros([len(sentences_test), max_sentence_len], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  for t, word in enumerate(sentence):\n",
        "    test_x[i, t] = word2idx(word, word_model)\n",
        "print(test_x.shape)\n",
        "print(test_x)\n",
        "\n",
        "X_ = test_x\n",
        "\n",
        "Y_ = test_data[[target_col]] # Y dataframe with single column; use iloc\n",
        "\n",
        "Y_pred = model.predict(X_)\n",
        "Y_ = np.array(Y_).reshape(len(Y_),1)\n",
        "spearmancorr = (stats.spearmanr(Y_pred,Y_))\n",
        "\n",
        "print(spearmancorr)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(Y_, Y_pred, s=0.1)\n",
        "plt.ylim((0,1))\n",
        "plt.xlim((0,1))\n",
        "savefigstring = 'gru' + str(target_type) + '.png'\n",
        "plt.savefig(savefigstring)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "100%|██████████| 8091/8091 [00:00<00:00, 126710.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(8091, 10)\n",
            "[[36 51  8 ... 62 48 33]\n",
            " [42  4 10 ... 41 33 46]\n",
            " [11 34  1 ... 38 29 25]\n",
            " ...\n",
            " [27 37 35 ...  3 10 13]\n",
            " [18 41 25 ...  7  3 23]\n",
            " [ 4  0 39 ... 11 34  1]]\n",
            "SpearmanrResult(correlation=0.8239278644233466, pvalue=0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6z2qrqaFAiu"
      },
      "source": [
        "**Bi-LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtbBERx_ixQo",
        "outputId": "f15b20c2-9b73-4067-8144-71d2e015195a"
      },
      "source": [
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, SpatialDropout1D, Bidirectional, Flatten\n",
        "from scipy import stats\n",
        "\n",
        "def get_model_name(k):\n",
        "    return 'model_'+str(k)+'.h5'\n",
        "\n",
        "def BiLSTM_model(word_model):\n",
        "  pretrained_weights = word_model.wv.syn0\n",
        "  vocab_size, emdedding_size = pretrained_weights.shape\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, \n",
        "                      weights=[pretrained_weights], input_shape = (10,)))\n",
        "  model.add(SpatialDropout1D(0.2))\n",
        "  model.add(Bidirectional(LSTM(units=emdedding_size,return_sequences = True)))\n",
        "  #model.add(Dense(64,activation = 'relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1,activation = 'linear'))\n",
        "  return model\n",
        "#word_model = return_vectors_word2vec(train_df,1)\n",
        "test_model = BiLSTM_model(word_model)\n",
        "print(test_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 10, 32)            2048      \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 10, 32)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 64)            16640     \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 641       \n",
            "=================================================================\n",
            "Total params: 19,329\n",
            "Trainable params: 19,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5Ar36l9DAcw"
      },
      "source": [
        "def word2idx(word, word_model):\n",
        "  return word_model.wv.vocab[word].index\n",
        "def idx2word(idx, word_model):\n",
        "  return word_model.wv.index2word[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67_lVoErLAHs",
        "outputId": "66918e16-a556-414e-84c2-e90e7ee1cd6a"
      },
      "source": [
        "#word_model, vectors_returned = return_vectors_word2vec(train_df)\n",
        "word_model = Word2Vec.load('word2vec_model_rnn')\n",
        "sentences = splitkmer(train_df)\n",
        "#print(len(sentences[0]))\n",
        "max_sentence_len = len(sentences[0])\n",
        "train_x = np.zeros([len(sentences), max_sentence_len], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, word in enumerate(sentence):\n",
        "    train_x[i, t] = word2idx(word, word_model)\n",
        "print(train_x.shape)\n",
        "print(train_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 45846/45846 [00:00<00:00, 135258.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(45846, 10)\n",
            "[[10  1 14 ...  1  4 48]\n",
            " [ 4  6 32 ... 31 54 12]\n",
            " [52  5 10 ... 52 52 34]\n",
            " ...\n",
            " [18 60 63 ...  6 13 12]\n",
            " [27 54  9 ... 19 44 26]\n",
            " [10 32  3 ... 30 38  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVTRmeMaLEfu",
        "outputId": "523daf5a-a32d-4901-a980-32b72fbcde4f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "\n",
        "target_type = 3\n",
        "target_col = ''\n",
        "if target_type == 1:\n",
        "  target_col = 'Wt_Efficiency'\n",
        "elif target_type == 2:\n",
        "  target_col = 'eSpCas 9_Efficiency'\n",
        "else:\n",
        "  target_col = 'SpCas9-HF1_Efficiency'\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "X = train_x\n",
        "#X = np.array(X)\n",
        "\n",
        "\n",
        "\n",
        "Y = train_data[[target_col]]\n",
        "#Y = Y[indices]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "#print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45846, 10)\n",
            "(45846, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVarOh8YLHBD",
        "outputId": "99fa1f46-0a28-49eb-e4e9-cc1dc01ac9fc"
      },
      "source": [
        "kf = KFold(n_splits = 5, shuffle=True, random_state=0)\n",
        "\n",
        "\n",
        "VALIDATION_CORR = []\n",
        "VALIDATION_LOSS = []\n",
        "save_dir_primary = 'Type' + str(target_type) + '/'\n",
        "save_dir = save_dir_primary + 'bilstm/'\n",
        "\n",
        "'''\n",
        "try:\n",
        "    os.mkdir(save_dir_primary)\n",
        "except:\n",
        "    pass\n",
        "'''\n",
        "\n",
        "os.chdir(save_dir_primary)\n",
        "\n",
        "try:\n",
        "    os.mkdir('bilstm')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "os.chdir('bilstm/')\n",
        "save_dir_2 = 'saved_models/'\n",
        "try:\n",
        "    \n",
        "    os.mkdir(save_dir_2)\n",
        "except:\n",
        "    pass\n",
        "os.chdir('..')\n",
        "os.chdir('..')\n",
        "\n",
        "fold_var = 1\n",
        "\n",
        "for train_index, val_index in kf.split(X,Y):\n",
        "    X_train = X[train_index]\n",
        "    Y_train = Y.iloc[train_index]\n",
        "    X_val = X[val_index]\n",
        "    Y_val = Y.iloc[val_index]\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(Y_train.shape)\n",
        "    print(X_val.shape)\n",
        "    print(Y_val.shape)\n",
        "    \n",
        "    # CREATE NEW MODEL\n",
        "    model = BiLSTM_model(word_model)\n",
        "    # COMPILE NEW MODEL\n",
        "    model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "    \n",
        "    # CREATE CALLBACKS\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+save_dir_2+get_model_name(fold_var), \n",
        "                            monitor='val_loss', verbose=1, \n",
        "                            save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint]\n",
        "    # There can be other callbacks, but just showing one because it involves the model name\n",
        "    # This saves the best model\n",
        "    # FIT THE MODEL\n",
        "    history = model.fit(X_train,Y_train,\n",
        "                epochs=50,\n",
        "                batch_size=64,\n",
        "                callbacks=callbacks_list,\n",
        "                validation_data=(X_val, Y_val))\n",
        "    #PLOT HISTORY\n",
        "    #       :\n",
        "    #       :\n",
        "    \n",
        "    # LOAD BEST MODEL to evaluate the performance of the model\n",
        "    model.load_weights(save_dir + \"saved_models/model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "    results = model.evaluate(X_val, Y_val)\n",
        "    results = dict(zip(model.metrics_names,results))\n",
        "    \n",
        "    Y_pred = model.predict(X_val)\n",
        "    Y_val = np.array(Y_val).reshape(len(Y_val),1)\n",
        "    spearmancorr = (stats.spearmanr(Y_pred,Y_val))\n",
        "\n",
        "    VALIDATION_CORR.append(spearmancorr)\n",
        "    VALIDATION_LOSS.append(results['loss'])\n",
        "    \n",
        "    tf.keras.backend.clear_session()\n",
        "    \n",
        "    fold_var += 1\n",
        "\n",
        "print(VALIDATION_LOSS)\n",
        "print(np.mean(VALIDATION_LOSS))\n",
        "print(VALIDATION_CORR)\n",
        "print(np.mean(VALIDATION_CORR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36676, 10)\n",
            "(36676, 1)\n",
            "(9170, 10)\n",
            "(9170, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - 8s 9ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01529, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 2/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01529 to 0.01446, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01446 to 0.01403, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 4/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01403 to 0.01301, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 5/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.01301\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01301\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01301 to 0.01225, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01225 to 0.01197, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01197\n",
            "Epoch 10/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01197 to 0.01191, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01191 to 0.01166, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 12/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01166\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01166\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01166\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01166 to 0.01141, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01141\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01141 to 0.01132, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01132\n",
            "Epoch 19/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01132 to 0.01115, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01115 to 0.01107, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01107\n",
            "Epoch 22/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01107\n",
            "Epoch 23/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01107 to 0.01101, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01101\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.01101 to 0.01100, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.01100 to 0.01096, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01096\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.01096 to 0.01092, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01092\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01092\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01092\n",
            "Epoch 32/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01092\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.01092 to 0.01091, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01091\n",
            "Epoch 35/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.01091 to 0.01076, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01076\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01076\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01076\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01076\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.01076 to 0.01074, saving model to Type2/bilstm/saved_models/model_1.h5\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01074\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01074\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01074\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01074\n",
            "Epoch 45/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01074\n",
            "Epoch 46/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01074\n",
            "Epoch 47/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01074\n",
            "Epoch 48/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01074\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01074\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01074\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - 8s 9ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01649, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 2/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01649 to 0.01605, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01605 to 0.01476, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 4/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01476 to 0.01395, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 5/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01395 to 0.01351, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01351 to 0.01338, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01338 to 0.01291, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01291\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01291 to 0.01267, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 10/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01267 to 0.01236, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01236 to 0.01218, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 12/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01218 to 0.01209, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01209 to 0.01184, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01184 to 0.01181, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01181 to 0.01174, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01174\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01174 to 0.01157, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01157\n",
            "Epoch 19/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01157\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01157 to 0.01142, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01142\n",
            "Epoch 22/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01142 to 0.01127, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 23/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01127\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01127\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01127\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.01127 to 0.01121, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01121\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.01121 to 0.01100, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01100\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01100\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01100\n",
            "Epoch 32/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.01100 to 0.01095, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01095\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01095\n",
            "Epoch 35/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01095\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01095\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.01095 to 0.01092, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01092\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01092\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01092\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01092\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01092\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.01092 to 0.01087, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01087\n",
            "Epoch 45/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01087\n",
            "Epoch 46/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01087\n",
            "Epoch 47/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.01087 to 0.01085, saving model to Type2/bilstm/saved_models/model_2.h5\n",
            "Epoch 48/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01085\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01085\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01085\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.0108 - mean_squared_error: 0.0108\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - 8s 9ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01644, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 2/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01644 to 0.01521, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01521 to 0.01431, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 4/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01431 to 0.01396, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 5/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01396 to 0.01335, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01335 to 0.01302, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01302 to 0.01277, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01277 to 0.01245, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01245\n",
            "Epoch 10/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01245\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01245 to 0.01215, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 12/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01215\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - 5s 9ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01215 to 0.01193, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01193 to 0.01193, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01193\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01193\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01193 to 0.01191, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.01191 to 0.01169, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 19/50\n",
            "574/574 [==============================] - 5s 8ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01169 to 0.01145, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - 9s 16ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01145\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01145 to 0.01140, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 22/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01140 to 0.01135, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 23/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01135 to 0.01134, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01134\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01134\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01134\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01134\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.01134 to 0.01117, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01117\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01117\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01117\n",
            "Epoch 32/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01117\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01117\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01117\n",
            "Epoch 35/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01117\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01117\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01117\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01117\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01117\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01117\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01117\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01117\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01117\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.01117 to 0.01105, saving model to Type2/bilstm/saved_models/model_3.h5\n",
            "Epoch 45/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01105\n",
            "Epoch 46/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01105\n",
            "Epoch 47/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01105\n",
            "Epoch 48/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01105\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01105\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01105\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - 10s 13ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01608, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 2/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01608 to 0.01498, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01498 to 0.01487, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 4/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.01487\n",
            "Epoch 5/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01487 to 0.01362, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01362\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01362 to 0.01304, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01304\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01304 to 0.01262, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 10/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01262\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01262 to 0.01254, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 12/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01254 to 0.01235, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01235\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01235 to 0.01212, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01212\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01212\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01212 to 0.01209, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01209\n",
            "Epoch 19/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01209 to 0.01197, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01197 to 0.01197, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01197\n",
            "Epoch 22/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01197 to 0.01196, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 23/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01196 to 0.01188, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01188\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01188\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01188\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.01188 to 0.01165, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01165\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.01165 to 0.01158, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01158\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.01158 to 0.01152, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 32/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.01152 to 0.01144, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01144\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01144\n",
            "Epoch 35/50\n",
            "574/574 [==============================] - 10s 17ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01144\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01144\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01144\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01144\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.01144 to 0.01136, saving model to Type2/bilstm/saved_models/model_4.h5\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01136\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01136\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01136\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01136\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01136\n",
            "Epoch 45/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01136\n",
            "Epoch 46/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01136\n",
            "Epoch 47/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01136\n",
            "Epoch 48/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01136\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01136\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01136\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
            "(36677, 10)\n",
            "(36677, 1)\n",
            "(9169, 10)\n",
            "(9169, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "574/574 [==============================] - 10s 12ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01555, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 2/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01555 to 0.01464, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 3/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01464 to 0.01444, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 4/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01444 to 0.01391, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 5/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01391 to 0.01314, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 6/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01314 to 0.01313, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 7/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01313 to 0.01274, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 8/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01274 to 0.01232, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 9/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01232\n",
            "Epoch 10/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01232 to 0.01211, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 11/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01211\n",
            "Epoch 12/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01211\n",
            "Epoch 13/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01211 to 0.01208, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 14/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01208 to 0.01167, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 15/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01167 to 0.01164, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 16/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01164\n",
            "Epoch 17/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01164\n",
            "Epoch 18/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01164\n",
            "Epoch 19/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01164 to 0.01143, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 20/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01143\n",
            "Epoch 21/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01143 to 0.01135, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 22/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01135 to 0.01132, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 23/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01132\n",
            "Epoch 24/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01132\n",
            "Epoch 25/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.01132 to 0.01129, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 26/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.01129 to 0.01120, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 27/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.01120 to 0.01117, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 28/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01117\n",
            "Epoch 29/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.01117 to 0.01111, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 30/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01111\n",
            "Epoch 31/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01111\n",
            "Epoch 32/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.01111 to 0.01105, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 33/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01105\n",
            "Epoch 34/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01105\n",
            "Epoch 35/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01105\n",
            "Epoch 36/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01105\n",
            "Epoch 37/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01105\n",
            "Epoch 38/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01105\n",
            "Epoch 39/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01105\n",
            "Epoch 40/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01105\n",
            "Epoch 41/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01105\n",
            "Epoch 42/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01105\n",
            "Epoch 43/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.01105 to 0.01090, saving model to Type2/bilstm/saved_models/model_5.h5\n",
            "Epoch 44/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01090\n",
            "Epoch 45/50\n",
            "574/574 [==============================] - 6s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01090\n",
            "Epoch 46/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.01090\n",
            "Epoch 47/50\n",
            "574/574 [==============================] - 7s 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.01090\n",
            "Epoch 48/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.01090\n",
            "Epoch 49/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.01090\n",
            "Epoch 50/50\n",
            "574/574 [==============================] - 7s 12ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.01090\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0109 - mean_squared_error: 0.0109\n",
            "[0.01074465923011303, 0.010847917757928371, 0.011050335131585598, 0.01136242225766182, 0.010899140499532223]\n",
            "0.010980894975364208\n",
            "[SpearmanrResult(correlation=0.8368832286718074, pvalue=0.0), SpearmanrResult(correlation=0.8396945615808119, pvalue=0.0), SpearmanrResult(correlation=0.8391675897175671, pvalue=0.0), SpearmanrResult(correlation=0.8321282790665848, pvalue=0.0), SpearmanrResult(correlation=0.8287145415845948, pvalue=0.0)]\n",
            "0.4176588200621366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "cmVVt5ZBIP8f",
        "outputId": "f907a958-2404-4804-f34d-ea0577faa765"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "save_dir_primary = 'Type' + str(target_type) + '/'\n",
        "save_dir = save_dir_primary + 'bilstm/'\n",
        "model = model = BiLSTM_model(word_model)\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "fold_var = 3\n",
        "model.load_weights(save_dir + \"saved_models/model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "\n",
        "sentences_test = splitkmer(test_data)\n",
        "max_sentence_len = len(sentences_test[0])\n",
        "test_x = np.zeros([len(sentences_test), max_sentence_len], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  for t, word in enumerate(sentence):\n",
        "    test_x[i, t] = word2idx(word, word_model)\n",
        "print(test_x.shape)\n",
        "print(test_x)\n",
        "\n",
        "X_ = test_x\n",
        "\n",
        "Y_ = test_data[[target_col]] # Y dataframe with single column; use iloc\n",
        "\n",
        "Y_pred = model.predict(X_)\n",
        "Y_ = np.array(Y_).reshape(len(Y_),1)\n",
        "spearmancorr = (stats.spearmanr(Y_pred,Y_))\n",
        "\n",
        "print(spearmancorr)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(Y_, Y_pred, s=0.1)\n",
        "plt.ylim((0,1))\n",
        "plt.xlim((0,1))\n",
        "savefigstring = 'bilstm' + str(target_type) + '.png'\n",
        "plt.savefig(savefigstring)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "100%|██████████| 8091/8091 [00:00<00:00, 145293.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(8091, 10)\n",
            "[[36 51  8 ... 62 48 33]\n",
            " [42  4 10 ... 41 33 46]\n",
            " [11 34  1 ... 38 29 25]\n",
            " ...\n",
            " [27 37 35 ...  3 10 13]\n",
            " [18 41 25 ...  7  3 23]\n",
            " [ 4  0 39 ... 11 34  1]]\n",
            "SpearmanrResult(correlation=0.830329784439046, pvalue=0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f71_nBzSh5ZQ"
      },
      "source": [
        "**Bi-LSTM with Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPpYrdKfh4xz"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, GRU, Dropout\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import initializers, regularizers, constraints\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "\n",
        "def get_model_name(k):\n",
        "    return 'att_bilstm_model_'+str(k)+'.h5'\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        \"\"\"\n",
        "        Keras Layer that implements an Attention mechanism for temporal data.\n",
        "        Supports Masking.\n",
        "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
        "        # Input shape\n",
        "            3D tensor with shape: `(samples, steps, features)`.\n",
        "        # Output shape\n",
        "            2D tensor with shape: `(samples, features)`.\n",
        "        :param kwargs:\n",
        "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "        The dimensions are inferred based on the output shape of the RNN.\n",
        "        Example:\n",
        "            # 1\n",
        "            model.add(LSTM(64, return_sequences=True))\n",
        "            model.add(Attention())\n",
        "            # next add a Dense layer (for classification/regression) or whatever...\n",
        "            # 2\n",
        "            hidden = LSTM(64, return_sequences=True)(words)\n",
        "            sentence = Attention()(hidden)\n",
        "            # next add a Dense layer (for classification/regression) or whatever...\n",
        "        \"\"\"\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(name='{}_W'.format(self.name),\n",
        "                                 shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(name='{}_b'.format(self.name),\n",
        "                                     shape=(input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        e = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))  # e = K.dot(x, self.W)\n",
        "        if self.bias:\n",
        "            e += self.b\n",
        "        e = K.tanh(e)\n",
        "\n",
        "        a = K.exp(e)\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "        a = K.expand_dims(a)\n",
        "\n",
        "        c = K.sum(a * x, axis=1)\n",
        "        return c\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], self.features_dim\n",
        "\n",
        "class TextAttBiRNN(Model):\n",
        "    def __init__(self,\n",
        "                 maxlen,\n",
        "                 max_features,\n",
        "                 embedding_dims,\n",
        "                 class_num=1,\n",
        "                 last_activation='linear'):\n",
        "        super(TextAttBiRNN, self).__init__()\n",
        "        self.maxlen = maxlen\n",
        "        self.max_features = max_features\n",
        "        self.embedding_dims = embedding_dims\n",
        "        self.class_num = class_num\n",
        "        self.last_activation = last_activation\n",
        "        self.embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen)\n",
        "        self.bi_rnn = Bidirectional(LSTM(128, return_sequences=True))  # LSTM or GRU\n",
        "        self.attention = Attention(self.maxlen)\n",
        "        self.internal = Dense(64, activation='relu')\n",
        "        self.dropout = Dropout(0.25)\n",
        "        self.classifier = Dense(self.class_num, activation=self.last_activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if len(inputs.get_shape()) != 2:\n",
        "            raise ValueError('The rank of inputs of TextAttBiRNN must be 2, but now is %d' % len(inputs.get_shape()))\n",
        "        if inputs.get_shape()[1] != self.maxlen:\n",
        "            raise ValueError('The maxlen of inputs of TextAttBiRNN must be %d, but now is %d' % (self.maxlen, inputs.get_shape()[1]))\n",
        "        embedding = self.embedding(inputs)\n",
        "        x = self.bi_rnn(embedding)\n",
        "        x = self.attention(x)\n",
        "        x = self.internal(x)\n",
        "        x = self.dropout(x)\n",
        "        output = self.classifier(x)\n",
        "        return output\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30ub91h9iqf-"
      },
      "source": [
        "def word2idx(word, word_model):\n",
        "  return word_model.wv.vocab[word].index\n",
        "def idx2word(idx, word_model):\n",
        "  return word_model.wv.index2word[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDXtVqCJivHy",
        "outputId": "f7c7e9d8-b940-4d1b-ab3a-f2a3868d7755"
      },
      "source": [
        "word_model = Word2Vec.load('word2vec_model_rnn')\n",
        "sentences = splitkmer(train_df)\n",
        "#print(len(sentences[0]))\n",
        "max_sentence_len = len(sentences[0])\n",
        "train_x = np.zeros([len(sentences), max_sentence_len], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, word in enumerate(sentence):\n",
        "    train_x[i, t] = word2idx(word, word_model)\n",
        "print(train_x.shape)\n",
        "print(train_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 45846/45846 [00:00<00:00, 84568.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(45846, 10)\n",
            "[[10  1 14 ...  1  4 48]\n",
            " [ 4  6 32 ... 31 54 12]\n",
            " [52  5 10 ... 52 52 34]\n",
            " ...\n",
            " [18 60 63 ...  6 13 12]\n",
            " [27 54  9 ... 19 44 26]\n",
            " [10 32  3 ... 30 38  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcMbDMa4ibe-",
        "outputId": "154939e8-0244-400a-fa11-53a4176b6b16"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "\n",
        "target_type = 3\n",
        "target_col = ''\n",
        "if target_type == 1:\n",
        "  target_col = 'Wt_Efficiency'\n",
        "elif target_type == 2:\n",
        "  target_col = 'eSpCas 9_Efficiency'\n",
        "else:\n",
        "  target_col = 'SpCas9-HF1_Efficiency'\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "X = train_x\n",
        "#X = np.array(X)\n",
        "\n",
        "\n",
        "\n",
        "Y = train_data[[target_col]]\n",
        "#Y = Y[indices]\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "#print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45846, 10)\n",
            "(45846, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUGs-mOSiegV",
        "outputId": "b72de3bd-3109-49c7-e5f0-ffe7838431a6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from scipy import stats\n",
        "\n",
        "max_features = 64\n",
        "maxlen = 10\n",
        "batch_size = 64\n",
        "\n",
        "embedding_dims = 32\n",
        "\n",
        "\n",
        "kf = KFold(n_splits = 5, shuffle=True, random_state=0)\n",
        "\n",
        "\n",
        "VALIDATION_CORR = []\n",
        "VALIDATION_LOSS = []\n",
        "\n",
        "save_dir_primary = 'Type' + str(target_type) + '/'\n",
        "save_dir = save_dir_primary + 'attention/'\n",
        "\n",
        "'''\n",
        "try:\n",
        "    os.mkdir(save_dir_primary)\n",
        "except:\n",
        "    pass\n",
        "'''\n",
        "\n",
        "os.chdir(save_dir_primary)\n",
        "\n",
        "try:\n",
        "    os.mkdir('attention')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "os.chdir('attention/')\n",
        "save_dir_2 = 'saved_models/'\n",
        "try:\n",
        "    \n",
        "    os.mkdir(save_dir_2)\n",
        "except:\n",
        "    pass\n",
        "os.chdir('..')\n",
        "os.chdir('..')\n",
        "\n",
        "fold_var = 1\n",
        "\n",
        "for train_index, val_index in kf.split(X,Y):\n",
        "    X_train = X[train_index]\n",
        "    Y_train = Y.iloc[train_index]\n",
        "    X_val = X[val_index]\n",
        "    Y_val = Y.iloc[val_index]\n",
        "    \n",
        "\n",
        "    model = TextAttBiRNN(maxlen, max_features, embedding_dims)\n",
        "    model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "    \n",
        "\n",
        "    # CREATE CALLBACKS\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir + save_dir_2 +get_model_name(fold_var), \n",
        "                            monitor='val_loss', verbose=1, \n",
        "                            save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint, es]\n",
        "    # There can be other callbacks, but just showing one because it involves the model name\n",
        "    # This saves the best model\n",
        "    # FIT THE MODEL\n",
        "    history = model.fit(X_train,Y_train,\n",
        "                epochs=100,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=callbacks_list,\n",
        "                validation_data=(X_val, Y_val))\n",
        "    #PLOT HISTORY\n",
        "    #       :\n",
        "    #       :\n",
        "    \n",
        "    # LOAD BEST MODEL to evaluate the performance of the model\n",
        "    model.load_weights(save_dir + \"saved_models/att_bilstm_model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "    results = model.evaluate(X_val, Y_val)\n",
        "    results = dict(zip(model.metrics_names,results))\n",
        "    \n",
        "    Y_pred = model.predict(X_val)\n",
        "    Y_val = np.array(Y_val).reshape(len(Y_val),1)\n",
        "    spearmancorr = (stats.spearmanr(Y_pred,Y_val))\n",
        "\n",
        "    with open(save_dir + \"saved_models/att_bilstm_spcorr_val_\"+str(fold_var)+\".txt\", \"w\") as f:\n",
        "        f.write(str(spearmancorr))\n",
        "\n",
        "    VALIDATION_CORR.append(spearmancorr)\n",
        "    VALIDATION_LOSS.append(results['loss'])\n",
        "    \n",
        "    tf.keras.backend.clear_session()\n",
        "    \n",
        "    fold_var += 1\n",
        "\n",
        "print(VALIDATION_LOSS)\n",
        "print(np.mean(VALIDATION_LOSS))\n",
        "print(VALIDATION_CORR)\n",
        "print(np.mean(VALIDATION_CORR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "574/574 [==============================] - 24s 35ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02155, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 2/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02155 to 0.01790, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 3/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01790 to 0.01603, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 4/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01603 to 0.01462, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 5/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.01462\n",
            "Epoch 6/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01462 to 0.01378, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 7/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01378 to 0.01359, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 8/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01359 to 0.01311, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 9/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01311 to 0.01304, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 10/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01304\n",
            "Epoch 11/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01304 to 0.01251, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 12/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01251\n",
            "Epoch 13/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01251 to 0.01234, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 14/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01234 to 0.01218, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 15/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01218 to 0.01188, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 16/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01188\n",
            "Epoch 17/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01188\n",
            "Epoch 18/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.01188 to 0.01178, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 19/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01178 to 0.01159, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 20/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01159 to 0.01125, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 21/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01125\n",
            "Epoch 22/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01125 to 0.01120, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 23/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01120\n",
            "Epoch 24/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.01120 to 0.01107, saving model to Type2/attention/saved_models/att_bilstm_model_1.h5\n",
            "Epoch 25/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01107\n",
            "Epoch 26/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01107\n",
            "Epoch 27/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01107\n",
            "Epoch 28/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01107\n",
            "Epoch 29/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01107\n",
            "Epoch 30/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01107\n",
            "Epoch 31/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01107\n",
            "Epoch 32/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01107\n",
            "Epoch 33/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01107\n",
            "Epoch 34/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01107\n",
            "Epoch 35/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01107\n",
            "Epoch 36/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01107\n",
            "Epoch 37/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01107\n",
            "Epoch 38/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01107\n",
            "Epoch 39/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01107\n",
            "Epoch 40/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01107\n",
            "Epoch 41/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01107\n",
            "Epoch 42/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01107\n",
            "Epoch 43/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01107\n",
            "Epoch 44/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01107\n",
            "Epoch 00044: early stopping\n",
            "287/287 [==============================] - 2s 5ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "Epoch 1/100\n",
            "574/574 [==============================] - 23s 35ms/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02096, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 2/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0191 - val_mean_squared_error: 0.0191\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02096 to 0.01914, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 3/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01914 to 0.01695, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 4/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01695 to 0.01642, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 5/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01642 to 0.01554, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 6/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01554\n",
            "Epoch 7/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01554 to 0.01431, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 8/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01431\n",
            "Epoch 9/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01431 to 0.01347, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 10/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01347\n",
            "Epoch 11/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01347 to 0.01295, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 12/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01295\n",
            "Epoch 13/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01295\n",
            "Epoch 14/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01295 to 0.01253, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 15/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01253 to 0.01222, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 16/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01222 to 0.01222, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 17/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01222 to 0.01217, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 18/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.01217 to 0.01164, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 19/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01164 to 0.01143, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 20/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01143\n",
            "Epoch 21/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01143 to 0.01141, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 22/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01141 to 0.01114, saving model to Type2/attention/saved_models/att_bilstm_model_2.h5\n",
            "Epoch 23/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01114\n",
            "Epoch 24/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01114\n",
            "Epoch 25/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01114\n",
            "Epoch 26/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01114\n",
            "Epoch 27/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01114\n",
            "Epoch 28/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01114\n",
            "Epoch 29/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01114\n",
            "Epoch 30/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01114\n",
            "Epoch 31/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01114\n",
            "Epoch 32/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01114\n",
            "Epoch 33/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01114\n",
            "Epoch 34/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01114\n",
            "Epoch 35/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01114\n",
            "Epoch 36/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01114\n",
            "Epoch 37/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01114\n",
            "Epoch 38/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01114\n",
            "Epoch 39/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01114\n",
            "Epoch 40/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01114\n",
            "Epoch 41/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01114\n",
            "Epoch 42/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01114\n",
            "Epoch 00042: early stopping\n",
            "287/287 [==============================] - 2s 5ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "Epoch 1/100\n",
            "574/574 [==============================] - 24s 36ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0244 - val_mean_squared_error: 0.0244\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02436, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 2/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02436 to 0.01864, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 3/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01864 to 0.01748, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 4/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01748 to 0.01652, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 5/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01652 to 0.01599, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 6/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01599 to 0.01476, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 7/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01476 to 0.01459, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 8/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01459 to 0.01400, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 9/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01400 to 0.01330, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 10/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01330 to 0.01327, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 11/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01327 to 0.01300, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 12/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01300\n",
            "Epoch 13/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01300 to 0.01269, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 14/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01269 to 0.01246, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 15/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01246 to 0.01220, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 16/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01220\n",
            "Epoch 17/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01220 to 0.01220, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 18/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.01220 to 0.01192, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 19/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01192 to 0.01179, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 20/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01179 to 0.01164, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 21/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01164 to 0.01147, saving model to Type2/attention/saved_models/att_bilstm_model_3.h5\n",
            "Epoch 22/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01147\n",
            "Epoch 23/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01147\n",
            "Epoch 24/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01147\n",
            "Epoch 25/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01147\n",
            "Epoch 26/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01147\n",
            "Epoch 27/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01147\n",
            "Epoch 28/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01147\n",
            "Epoch 29/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01147\n",
            "Epoch 30/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01147\n",
            "Epoch 31/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01147\n",
            "Epoch 32/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01147\n",
            "Epoch 33/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01147\n",
            "Epoch 34/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01147\n",
            "Epoch 35/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01147\n",
            "Epoch 36/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01147\n",
            "Epoch 37/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01147\n",
            "Epoch 38/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01147\n",
            "Epoch 39/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01147\n",
            "Epoch 40/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01147\n",
            "Epoch 41/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01147\n",
            "Epoch 00041: early stopping\n",
            "287/287 [==============================] - 2s 6ms/step - loss: 0.0115 - mean_squared_error: 0.0115\n",
            "Epoch 1/100\n",
            "574/574 [==============================] - 24s 36ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02104, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 2/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02104 to 0.01859, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 3/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01859 to 0.01702, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 4/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01702 to 0.01625, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 5/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01625 to 0.01589, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 6/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01589 to 0.01502, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 7/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01502\n",
            "Epoch 8/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01502 to 0.01448, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 9/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01448 to 0.01417, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 10/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01417 to 0.01402, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 11/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01402 to 0.01364, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 12/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01364 to 0.01358, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 13/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01358 to 0.01341, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 14/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01341 to 0.01275, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 15/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01275 to 0.01235, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 16/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01235\n",
            "Epoch 17/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01235\n",
            "Epoch 18/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.01235 to 0.01196, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 19/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01196\n",
            "Epoch 20/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01196 to 0.01185, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 21/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01185 to 0.01158, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 22/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01158 to 0.01152, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 23/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01152\n",
            "Epoch 24/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.01152 to 0.01142, saving model to Type2/attention/saved_models/att_bilstm_model_4.h5\n",
            "Epoch 25/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01142\n",
            "Epoch 26/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01142\n",
            "Epoch 27/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01142\n",
            "Epoch 28/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01142\n",
            "Epoch 29/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01142\n",
            "Epoch 30/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01142\n",
            "Epoch 31/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01142\n",
            "Epoch 32/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01142\n",
            "Epoch 33/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01142\n",
            "Epoch 34/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01142\n",
            "Epoch 35/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01142\n",
            "Epoch 36/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01142\n",
            "Epoch 37/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01142\n",
            "Epoch 38/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01142\n",
            "Epoch 39/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01142\n",
            "Epoch 40/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01142\n",
            "Epoch 41/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01142\n",
            "Epoch 42/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01142\n",
            "Epoch 43/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01142\n",
            "Epoch 44/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01142\n",
            "Epoch 00044: early stopping\n",
            "287/287 [==============================] - 2s 6ms/step - loss: 0.0114 - mean_squared_error: 0.0114\n",
            "Epoch 1/100\n",
            "574/574 [==============================] - 25s 37ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02105, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 2/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02105 to 0.01814, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 3/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01814 to 0.01665, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 4/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01665 to 0.01631, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 5/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01631 to 0.01497, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 6/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01497\n",
            "Epoch 7/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01497 to 0.01405, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 8/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01405 to 0.01371, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 9/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01371\n",
            "Epoch 10/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01371 to 0.01329, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 11/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01329 to 0.01305, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 12/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01305 to 0.01284, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 13/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01284 to 0.01263, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 14/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01263 to 0.01251, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 15/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01251 to 0.01217, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 16/100\n",
            "574/574 [==============================] - 21s 36ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01217 to 0.01209, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 17/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01209\n",
            "Epoch 18/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.01209 to 0.01202, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 19/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01202 to 0.01175, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 20/100\n",
            "574/574 [==============================] - 21s 36ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01175\n",
            "Epoch 21/100\n",
            "574/574 [==============================] - 20s 35ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01175 to 0.01169, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 22/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.01169 to 0.01151, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 23/100\n",
            "574/574 [==============================] - 20s 36ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01151 to 0.01144, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 24/100\n",
            "574/574 [==============================] - 21s 36ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.01144 to 0.01141, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 25/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.01141 to 0.01120, saving model to Type2/attention/saved_models/att_bilstm_model_5.h5\n",
            "Epoch 26/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01120\n",
            "Epoch 27/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01120\n",
            "Epoch 28/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01120\n",
            "Epoch 29/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01120\n",
            "Epoch 30/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01120\n",
            "Epoch 31/100\n",
            "574/574 [==============================] - 20s 34ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01120\n",
            "Epoch 32/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01120\n",
            "Epoch 33/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01120\n",
            "Epoch 34/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01120\n",
            "Epoch 35/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01120\n",
            "Epoch 36/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01120\n",
            "Epoch 37/100\n",
            "574/574 [==============================] - 19s 34ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01120\n",
            "Epoch 38/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01120\n",
            "Epoch 39/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01120\n",
            "Epoch 40/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.01120\n",
            "Epoch 41/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.01120\n",
            "Epoch 42/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.01120\n",
            "Epoch 43/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.01120\n",
            "Epoch 44/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.01120\n",
            "Epoch 45/100\n",
            "574/574 [==============================] - 19s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.01120\n",
            "Epoch 00045: early stopping\n",
            "287/287 [==============================] - 2s 5ms/step - loss: 0.0112 - mean_squared_error: 0.0112\n",
            "[0.011068715713918209, 0.011137815192341805, 0.01146883238106966, 0.01142259780317545, 0.011195509694516659]\n",
            "0.011258694157004357\n",
            "[SpearmanrResult(correlation=0.827915193337267, pvalue=0.0), SpearmanrResult(correlation=0.8315546192918151, pvalue=0.0), SpearmanrResult(correlation=0.8279054642301668, pvalue=0.0), SpearmanrResult(correlation=0.8284487475229082, pvalue=0.0), SpearmanrResult(correlation=0.821841839987453, pvalue=0.0)]\n",
            "0.41376658643696096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "JT8u7zt864dX",
        "outputId": "78565b4b-2671-443e-aeb1-6c05ab7789cc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "save_dir_primary = 'Type' + str(target_type) + '/'\n",
        "save_dir = save_dir_primary + 'attention/'\n",
        "model = TextAttBiRNN(10, 64, 32)\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mean_squared_error'])\n",
        "model.fit(X[0].reshape(1,10),Y.iloc[0],epochs=1,batch_size=1)\n",
        "fold_var = 3\n",
        "model.load_weights(save_dir + \"saved_models/att_bilstm_model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "\n",
        "sentences_test = splitkmer(test_data)\n",
        "max_sentence_len = len(sentences_test[0])\n",
        "test_x = np.zeros([len(sentences_test), max_sentence_len], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences_test):\n",
        "  for t, word in enumerate(sentence):\n",
        "    test_x[i, t] = word2idx(word, word_model)\n",
        "print(test_x.shape)\n",
        "print(test_x)\n",
        "\n",
        "X_ = test_x\n",
        "\n",
        "Y_ = test_data[[target_col]] # Y dataframe with single column; use iloc\n",
        "\n",
        "Y_pred = model.predict(X_)\n",
        "Y_ = np.array(Y_).reshape(len(Y_),1)\n",
        "spearmancorr = (stats.spearmanr(Y_pred,Y_))\n",
        "\n",
        "print(spearmancorr)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(Y_, Y_pred, s=0.1)\n",
        "plt.ylim((0,1))\n",
        "plt.xlim((0,1))\n",
        "savefigstring = 'attention' + str(target_type) + '.png'\n",
        "plt.savefig(savefigstring)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 3s 3s/step - loss: 0.2589 - mean_squared_error: 0.2589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8091/8091 [00:00<00:00, 145904.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(8091, 10)\n",
            "[[36 51  8 ... 62 48 33]\n",
            " [42  4 10 ... 41 33 46]\n",
            " [11 34  1 ... 38 29 25]\n",
            " ...\n",
            " [27 37 35 ...  3 10 13]\n",
            " [18 41 25 ...  7  3 23]\n",
            " [ 4  0 39 ... 11 34  1]]\n",
            "SpearmanrResult(correlation=0.8333928341090534, pvalue=0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}